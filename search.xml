<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[忽略所有 Web性能基准测试]]></title>
    <url>%2F2020%2F05%2F27%2F%E5%BF%BD%E7%95%A5%E6%89%80%E6%9C%89%20Web%E6%80%A7%E8%83%BD%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%EF%BC%8C%E5%8C%85%E6%8B%AC%E8%BF%99%E4%B8%AA.html</url>
    <content type="text"><![CDATA[忽略所有 Web性能基准测试，包括这个几个月前，有一篇名为 Async Python is Not Faster 的文章在社交媒体上广为流传。在这篇文章中，作者 Cal Paterson 指出，与普遍的看法相反，异步 web 框架不仅“不比传统的同步框架快” ，而且还更慢。他通过展示他实施的相当完整的基准测试的结果来支持这一点。 我希望一切都像作者在他的博客文章中所说的那样简单，但是事实是，衡量Web应用程序的性能异常复杂，并且他在实施基准和对结果的解释上都犯了一些错误。 在本文中，你可以看到我在理解和修复此基准，重新运行该基准以及最终得出令人震惊的发现所做的努力。 基准测试结果在深入研究详细细节之前，我假设你急于查看基准测试的结果。 这些是我解决了其中发现的所有问题后，在运行此基准测试时所获得的结果。 我还添加了一些我特别感兴趣的框架： Framework Web Server Type Wrk Tput P50 P99 #DB Bottle Meinheld Async / Greenlet 6 1.38 85 1136 100 Falcon Meinheld Async / Greenlet 6 1.38 84 1134 99 Sanic Sanic Async / Coroutine 6 1.24 95 1155 83 Flask Meinheld Async / Greenlet 6 1.23 88 1124 97 Starlette Uvicorn Async / Coroutine 6 1.23 102 1146 82 Bottle Gevent Async / Greenlet 6 1.21 89 1162 95 Aiohttp Aiohttp Async / Coroutine 6 1.20 95 1153 80 Flask Gevent Async / Greenlet 6 1.16 103 1165 97 Sanic Uvicorn Async / Coroutine 6 1.14 95 1179 83 Tornado Tornado Async / Coroutine 6 1.12 91 1170 82 Falcon Gevent Async / Greenlet 6 1.12 82 1144 96 FastAPI Uvicorn Async / Coroutine 6 1.08 88 1197 77 Aioflask Uvicorn Async / Coroutine 6 1.08 116 1167 83 Falcon uWSGI Sync 19 1.07 152 183 19 Quart Uvicorn Async / Coroutine 6 1.05 116 1167 74 Bottle uWSGI Sync 19 1.05 154 193 19 Bottle Gunicorn Sync 19 1.02 159 187 19 Flask Gunicorn Sync 19 1.00 163 192 19 Flask uWSGI Sync 19 0.94 157 1166 19 Falcon Gunicorn Sync 19 0.91 159 1183 19 Quart Hypercorn Async / Coroutine 6 0.90 150 1216 64 关于这些结果的说明: 此基准测试显示了在100个客户端的恒定负载下的性能 有三种类型的测试: Sync、 Async/Coroutine 和 Async/Greenlet。如果您需要了解这些类型之间的区别，请查看我的 Sync vs. Async Python 这篇文章 我使用了两种不同的 worker 配置。对于异步测试，我使用了6个 workers (每个 CPU 一个)。对于同步测试，我使用了19个 workers 。我通过测试不同的配置来最大化性能，从而得出这些数字 所有 asyncio 测试都使用 uvloop 以获得最佳性能 我使用 Flask + Gunicorn 测试作为基准，而不是将吞吐量报告为每秒处理的请求数，并将每个测试的吞吐量报告为该基准的倍数。 例如，吞吐量为 2.0 意味着“快于 Flask + Gunicorn 的两倍”，吞吐量为 0.5 意味着“快于Flask + Gunicorn的一半（或慢了两倍）” P50 是 50％（中位数）的请求的处理时间小于这个时间，以毫秒为单位。 换句话说，测试期间发送的请求中有 50％的请求在改时间内完成 P99 是 99％的请求的处理时间小于这个时间，以毫秒为单位。 你可以将这个数字看作是移除异常值后处理请求所需的最长时间 #DB 列显示每个测试使用的最大数据库会话数。每个配置有100个可用会话。 同步测试显然被限制为每个 worker 一个会话基准测试是做什么的？ 基准测试包括在负载下运行 Web 应用程序并评估性能。 对 Web服务器和 Web 框架的许多不同配置进行重复测试，以确定所有这些工具在相同条件下的性能。 下面你可以看到一个测试的示意图。在这个图中，灰色框是常量，而红色框代表系统中插入了要评估的不同实现的部分。 负载生成器 是生成客户端连接的进程。这是通过 Apache Bench (ab) 完成的。 反向代理 是唯一的公共接口，它接收请求。 Nginx 服务器提供了此功能。 Web服务器 和 负载平衡器接受来自反向代理的请求，并将其分派给几个 Web应用程序的 worker 之一。 应用程序 组件是处理请求的地方。 数据库池 是一个管理数据库连接池的服务。 在此测试中，此任务由 pgbouncer 完成。 数据库 是实际的存储服务，它是一个PostgresSQL实例。 最初的基准测试有各种各样的Web服务器。 我添加了一些对我来说很有趣的东西。 我测试的Web服务器的完整列表如下所示 Server Type Language Gunicorn Sync Python uWSGI Sync C Gevent Async / Greenlet Python Meinheld Async / Greenlet C Tornado Async / Coroutine Python Uvicorn Async / Coroutine Python Aiohttp Async / Coroutine Python Sanic Async / Coroutine Python Hypercorn Async / Coroutine Python 对于应用程序组件，使用小型微服务，该微服务执行数据库查询并以JSON响应的形式返回结果。 为了让你更好地了解测试涉及的内容，下面可以看到此服务的 Flask 和 Aiohttp实现： 12345678import flaskimport jsonfrom sync_db import get_rowapp = flask.Flask("python-web-perf")@app.route("/test")def test(): a, b = get_row() return json.dumps(&#123;"a": str(a).zfill(10), "b": b&#125;) 12345678import jsonfrom aiohttp import webfrom async_db import get_rowasync def handle(request): a, b = await get_row() return web.Response(text=json.dumps(&#123;"a": str(a).zfill(10), "b": b&#125;))app = web.Application()app.add_routes([web.get('/test', handle)]) 该函数在装载有随机数据的数据库上运行查询。 此功能有两种实现，一种使用标准 Python 的 psycopg2 软件包，另一种使用 aiopg 进行 asyncio 测试。 对于 greenlet 测试，请对 psycopg2 进行适当的修补以确保其不会阻塞异步循环（这是原始基准测试中的重要疏忽）。 我测试的该应用程序的实现基于以下Web框架： Framework Platform Gateway interface Flask Standard Python WSGI Bottle Standard Pyhon WSGI Falcon Standard Pyhon WSGI Aiohttp asyncio Custom Sanic asyncio Custom or ASGI Quart asyncio ASGI Starlette asyncio ASGI Tornado asyncio Custom FastAPI asyncio ASGI Aioflask asyncio ASGI 我没有测试过 Web服务器和应用程序的所有可能配对，主要是因为某些组合不能一起工作，而且还因为我不想浪费测试时间在那些奇怪的，不常见或不感兴趣的组合上。 如果您熟悉原始基准测试，以下是我自己设置中的差异列表： 我已经在真实的硬件上执行了所有测试。 原始的基准测试使用的是云服务器，这不是一个好主意，因为虚拟化服务器中的CPU性能一直在变化，并且依赖于位于同一物理主机上的其他服务器的使用情况。 我使用 Docker 容器来托管测试中的所有组件。这只是为了方便起见，我不知道在原始的基准测试中是如何设置的 我已经在应用程序层删除了会话池，因为 pgbouncer 已经提供了会话池。 这解决了一个间接问题，即用于同步和异步测试的应用程序池配置不同。 在我的测试中，有100个会话可以分配给所有的应用程序 worker 原始基准测试中发出的数据库查询是通过主键进行的简单搜索。 为了使测试更加真实，我通过向其添加短暂延迟来使查询稍微慢一些。 我知道这是一个非常主观的领域，许多人会反对这种更改，但是我观察到，这样快速的查询没有多少机会可以实现并发 上面我提到过，我将 psycopg2 修补为与greenlet框架一起使用时可以异步工作。 原始基准测试中忽略了这一点。 原始基准测试中的 aiohttp 测试使用 asyncio 中的标准循环，而不是 uvloop 中的标准循环。这些结果意味着什么？ 从我获得的结果中可以得出一些结论，但是我鼓励你对数据进行自己的分析，并对一切提出质疑。与大多数基准测试作者不同，我没有待办事项，我只对事实感兴趣。如果发现任何错误，请与我们联系。 我敢打赌，你们中的大多数人都会感到惊讶，即使是性能最好的测试，也不会比标准的 Flask/Gunicorn 部署提高40% 的性能。不同的服务器和框架之间当然存在性能差异，但是它们并没有那么大，对吧？下次查看 asyncio 框架作者发布的太好了以至于不真实的基准时，请记住这一点！ 异步解决方案（Hypercorn服务器除外，它看起来非常慢）在此测试中的性能明显优于同步解决方案。你可以看到，总体而言，同步测试在吞吐量方面都位于列表的底部，并且都非常接近 Flask/Gunicorn 基线。请注意，于某种奇怪的原因，原始基准测试的作者将 greenlet 测试称为同步，与实现并发的方法相比，更加重视应用程序的编码风格。 如果您查看 original benchmark results 并将它们与我的结果进行比较，你可能会认为这些不是来自同一基准测试。 虽然结果并非完全相反，但在原始结果中，同步测试的效果要比我的好得多。 我认为原因是原始基准中发出的数据库查询非常简单，以至于并行运行多个查询几乎没有收益。 这使异步测试处于不利地位，因为当任务受 I/O 限制并且可以重叠时，异步测试的性能最好。 如上所述，我的基准测试版本使用了较慢的查询，以使其成为更真实的场景。 这两个基准测试的一个共同点是，Meinheld 测试在两个方面都表现得很好。你能猜到为什么吗？Meinheld 是用 C 编写的，而其他的异步服务器都是用 Python 编写的。这很重要。 Gevent 测试在我的基准测试中表现相当不错，在原始的基准测试中表现得很糟糕。这是因为作者忘记 patch the psycopg2 package，以使其在 greenlets 下变为非阻塞。 相反，uWSGI 测试在原始基准测试中表现良好，在我的测试中仅为平均水平。 这很奇怪，因为 uWSGI 也是 C 服务器，所以它应该做得更好。 我相信使用更长的数据库查询对此有直接影响。 当应用程序执行更多工作时，Web服务器使用的时间对整体的影响较小。 对于异步测试，像 Meinheld 这样的 C 服务器非常重要，因为它使用自己的循环并执行所有上下文切换工作。 在由操作系统进行上下文切换的同步服务器中，可以使用 C 进行优化的工作较少。 在我的结果中，P50 和 P99的数字要高得多，部分原因是我的测试系统可能比较慢，还因为我发出的数据库查询需要更长的时间才能完成，这意味着处理请求的时间更长。原始基准测试只是通过其主键查询了行，这种方法非常快，根本不能代表实际的数据库使用情况。对于较长的查询，在大多数测试中，P99 的数值在1100毫秒内是相当一致的，只有少数几个测试做得更好。对于比 P99 数值慢的原因，有时会在外部条件（可能在数据库服务器或连接池中），这些条件时常“打嗝” ，导致大多数测试有一些缓慢的请求。如果幸运的话，一个测试能够避免这些问题，那么它的 P99数字看起来会好很多。 通过查看自己的基准，我得出了一些其他结论: 从三个同步框架来看，Falcon 和 Bottle 看起来比 Flask 稍微快一点，但在我看来，这确实不足以保证切换框架 Greenlets 太棒了！它们不仅拥有性能最好的异步 web 服务器，而且还允许你使用熟悉的框架在标准Python中编写代码，比如 Flask，Django，Bottle 等等 我很高兴发现我的 Aioflask experiment 比标准的Flask表现更好，并且甚至比 Quart 还好。 我想我必须完成它。基准是不可靠的 我觉得奇怪的是，由于一些错误和解释错误，这个基准让原作者相信同步 Python 比异步更快。我想知道他在创建基准之前是否已经有了这种信念，以及是否正是这种信念导致他犯了这些无意识的错误，从而使基准结果朝着他想要的方向发展。 如果我们承认这是可能的，难道我们不应该担心这也发生在我身上吗？我修改这个基准不是为了正确性和准确性，而是为了让它更符合我的观点，而不是他的观点吗？我所做的一些修复确实是错误的。例如，在使用 greenlet 服务器时不打补丁不能作为一种选择来捍卫，这是即使基准测试作者也无法证明的明确漏洞。但是我在灰色地带所做的其他更改，比如数据库查询应该持续多长时间，又该如何处理呢？ 作为一个有趣的练习，我决定看看是否可以重新配置这个基准以显示完全不同的结果，同时显然保持其正确性。下表总结了我必须使用的选项，你可以看到基准测试的原始版本和我自己的版本中使用的配置，以及我想向异步或同步倾斜所做的更改 Option Original My Benchmark Better Async Better Sync Workers Variable Sync: 19 Async: 6 | Sync: 19Async: 6 | Sync: 19Async: 6 || Max database sessions | 4 per worker | 100 total | 100 total | 19 total || Database query delay | None | 20ms | 40ms | 10ms || Client connections | 100 | 100 | 400 | 19 | 让我来解释一下这四个配置变量的变化是如何影响测试的: 我决定保持 workers 的数量不变，因为通过实验，我已经确定这些数字对于我的测试系统的性能是最好的。对我来说，如果我把这些数字改成不那么理想的值，我会觉得不诚实 同步测试每个 worker 使用一个数据库会话，因此任何等于或高于 worker 的会话数量都会导致类似的性能。对于异步测试，更多的会话允许更多的请求并行发出它们的查询，因此减少这个数量肯定会影响它们的性能 请求执行的 I/O 数量决定了基准测试的 I/O 和 CPU 绑定特征之间的平衡。当有更多的 I/O 时，异步服务器由于其高并发性仍然可以有很好的 CPU 利用率。对于同步服务器，另一方面，慢速 I/O 意味着请求必须在队列中等待更长时间，直到 worker 释放 异步测试可以自由地扩展到大量并发任务，而同步测试有一个固定的并发性，这个并发性是由 worker 的数量决定的。客客户端连接数量增加，对同步服务器的影响远大于对异步服务器的损害，因此这是一种偏爱彼此的简单方法 你准备好大吃一惊了吗？下面你可以看到一个表，它比较了我在本文开头分享的吞吐量结果和我为刚才讨论的两个场景重新配置基准所获得的数字。 Framework Web Server Type My Results Better Async Better Sync Bottle Meinheld Async / Greenlet 1.38 5.56 1.13 Falcon Meinheld Async / Greenlet 1.38 5.17 1.12 Sanic Sanic Async / Coroutine 1.24 4.58 1.09 Flask Meinheld Async / Greenlet 1.23 5.27 1.06 Starlette Uvicorn Async / Coroutine 1.23 4.36 1.13 Bottle Gevent Async / Greenlet 1.21 4.59 1.18 Aiohttp Aiohttp Async / Coroutine 1.20 4.79 1.27 Flask Gevent Async / Greenlet 1.16 4.54 1.01 Sanic Uvicorn Async / Coroutine 1.14 4.40 1.03 Tornado Tornado Async / Coroutine 1.12 4.19 1.03 Falcon Gevent Async / Greenlet 1.12 4.66 0.99 FastAPI Uvicorn Async / Coroutine 1.08 4.33 1.02 Aioflask Uvicorn Async / Coroutine 1.08 3.57 1.07 Falcon uWSGI Sync 1.07 1.00 1.43 Quart Uvicorn Async / Coroutine 1.05 3.99 0.99 Bottle uWSGI Sync 1.05 0.90 1.35 Bottle Gunicorn Sync 1.02 0.97 1.11 Flask Gunicorn Sync 1.00 1.00 1.00 Flask uWSGI Sync 0.94 0.90 1.26 Falcon Gunicorn Sync 0.91 1.00 1.11 Quart Hypercorn Async / Coroutine 0.90 3.24 0.80 这不是令人讨厌吗？ 请记住，基准始终是相同的，我所做的只是更改配置参数。 “ Better Async”基准测试显示，所有的同步测试都接近 Flask/Gunicorn 测试的1.0基准，而异步测试的速度要快3到6倍。即使是在我的基准测试中非常慢的 Hypercorn 测试，也得了一个相当不错的分数。“ Better Sync”基准测试显示 uWSGI 测试的性能比其他测试做得更好，尽管大多数异步测试结果都高于1.0，但查看这些结果并不会激发任何人进入异步测试。 总结我希望本文能够帮助你认识到基准游戏已经被操纵了。我可以很容易地做出合理的论证，支持这些结果集中的任何一组，这正是每个发布基准的人所做的。我并不是说基准作者不诚实，实际上我相信大多数人都不是。只是在构建基准和分析其结果时，很难把个人观点放在一边，保持客观。 正如我在标题中所说的，我认为我能给你的最好的建议就是理解异步和同步解决方案的优势，并并据此而不是基准测试所说的来做出决定。一旦你知道哪种模式最适合你，请记住，不同框架 或 Web服务器之间的性能差异不会非常显着，因此请选择可以提高工作效率的工具！ 如果你有兴趣使用我的版本的基准测试，可以在这个 GitHub 仓库. 找到它。]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sync 与 Async Python：有什么区别？]]></title>
    <url>%2F2020%2F05%2F23%2FSync%20%E4%B8%8E%20Async%20Python%EF%BC%9A%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F.html</url>
    <content type="text"><![CDATA[Sync 与 Async Python：有什么区别？你有没有听人说过异步 Python 代码比“普通”(或同步) Python 代码更快？这怎么可能？在本文中，我将尝试解释什么是异步以及它与普通 Python 代码的区别。 Sync 和 Async 是什么意思？Web 应用程序通常需要处理许多请求，所有请求都是在短时间内从不同的客户端发出的。为了避免处理延迟，它们必须能够并行处理多个请求（通常称为并发）。在本文中，我将继续使用 web 应用程序作为例子，但请记住，还有其他类型的应用程序也受益于同时完成多个任务，因此这个讨论并不是专门针对 web 的。 术语“ sync”和“ async”指的是编写使用并发的应用程序的两种方式。所谓的“sync”服务器使用线程和进程的底层操作系统支持来实现这种并发。以下是同步部署的效果图: 在这种情况下，我们有五个客户端，所有客户端都向应用程序发送请求。这个应用程序的公共访问点是一个 web 服务器，它充当一个负载均衡器，将请求分发给一组服务器 worker，这些 worker 可以实现为进程、线程或两者的组合。worker 执行负载均衡器分配给他们的请求。你可以用 Flask 或 Django 这样的 web 应用程序框架来编写应用程序逻辑，它们就位于这些 worker 中。 这种类型的解决方案非常适合拥有多个 CPU 的服务器，因为你可以将 worker 的数量配置为 cpu 数量的倍数，并且通过这种配置，实现 cores 的均匀利用率，这是单个 Python 进程无法做到的，因为 全局解释器锁定（GIL） 强加了一些限制。 就缺点而言，上图清楚地表明了此方法的主要局限性。 我们有5个客户端，但只有4个 worker 。 如果这5个客户端同时发送请求，而负载平衡器只能给每个worker 分派 1个请求，没有竞争到 worker 的请求将保留在队列中，等待一个 worker 可用。 因此，5个客户端中有4个将及时收到回复，但其中1个将不得不等待更长的时间。 使服务器性能良好的关键在于选择适当数量的 worker，以防止或尽量减少在给定预期负载的情况下阻塞请求的情况。 异步服务器设置较难绘制，但这是我的最佳选择： 这种类型的服务器在由循环控制的单个进程中运行。 循环是一个非常高效的任务管理器和调度器，它创建任务以处理客户端发送的请求。 与长期运行的服务器 worker 不同，循环会创建一个异步任务来处理特定的请求，当该请求完成时，该任务将被销毁。 在任何给定的时间，异步服务器可能有数百个甚至数千个活动任务，所有这些任务由循环管理并同时完成自己的工作。 你可能想知道异步任务之间的并行性是如何实现的。这是有趣的部分，因为异步应用程序完全依赖于协作式多任务处理。这意味着什么？当一个任务需要等待一个外部事件时，例如来自数据库服务器的响应，而不是像同步 worker 那样等待，它告诉循环需要等待什么，然后将控制权返回给循环。然后循环可以找到另一个准备运行的任务，而此任务被数据库阻塞。最终数据库将发送响应，此时循环将考虑第一个任务准备再次运行，并将尽快恢复它。 异步任务暂停和恢复执行的这种能力比较抽象可能难以理解。为了帮助你将其应用于你可能已经知道的事情，请考虑在 Python 中，实现此目的的一种方法是使用 await 或 yield 关键字，但这并不是唯一的方法，你稍后将看到。 异步应用程序完全在单个进程和单个线程中运行，这令人惊讶。 当然，这种类型的并发需要一定的规则，因为你不能让任务在 CPU 上停留太长时间，否则剩余的任务就会饿死。 为了使异步工作，所有任务都需要自动暂停并及时将控制权返回给循环。 要从异步风格中受益，应用程序需要执行的任务通常会被 I/O 阻塞，并且不需要太多的CPU工作。 Web应用程序通常非常适合，特别是如果它们需要处理大量客户端请求时。 为了在使用异步服务器时最大限度地利用多个 CPU，通常会创建一个混合解决方案，添加一个负载平衡器并在每个CPU上运行一个异步服务器，如下图所示： 在 Python 中实现异步的两种方法我确定你知道，要在 Python 中编写异步应用程序，你可以使用 asyncio 包，它构建在协程之上，以实现所有异步应用程序都需要的挂起和恢复特性。关键词 yield，以及更新的 async 和 await，是 asyncio 构建异步功能的基础。为了描绘一幅完整的图景，Python 生态系统中还有其他基于协程的异步解决方案，比如 Trio 和 Curio。还有 Twisted，它是最古老的协同框架，甚至早于 asyncio。 如果你有兴趣编写一个异步 web 应用程序，有很多基于 coroutines 的异步框架可供选择，包括 aiohttp、sanic、FastAPI 和 Tornado。 很多人不知道的是，协程只是 Python 中可用于编写异步代码的两种方法之一。 第二种方法是基于一个名为greenlet 的软件包，你可以使用pip进行安装。 Greenlets与协程类似，因为它们也允许 Python 函数暂停执行并在以后恢复执行，但是实现方式却完全不同，这意味着 Python 中的异步生态系统分为两个大类。 coroutine 和 greenlets 进行异步开发的有趣的区别在于，前者需要 Python 语言的特定关键字和特性才能工作，而后者不需要。我的意思是，基于 coroutine 的应用程序需要使用非常特定的语法编写，而基于 greenlet 的应用程序看起来与普通的 Python 代码完全一样。这非常酷，因为在某些条件下，它允许异步执行同步代码，这是基于 coroutine 的解决方案（例如asyncio）无法做到的。 那么在 greenlet 方面有哪些 asyncio 的等价物呢？我知道三个基于 greenlets 的异步包: Gevent, Eventlet 和 Meinheld，尽管最后一个更像是一个 web 服务器而不是一个通用的异步库。它们都有自己的异步循环实现，并且提供了一个有趣的“ monkey-patching”特性，用在 greenlets 上实现的等效非阻塞版本替换 Python 标准库中的阻塞函数，比如那些执行网络和线程的函数。如果你有一段希望异步运行的同步代码，那么这些包很有可能会让你做到这一点。 你会对此感到惊讶的。据我所知，唯一明确支持 greenlets 的 web 框架是 Flask。此框架会自动检测你何时在greenlet web 服务器上运行，并进行相应的调整，而无需进行任何配置。在执行此操作时，您需要注意不要调用阻塞函数，否则，请使用Monkey-patching来“修复”这些阻塞函数。 但是，Flask 并不是唯一可以从 greenlets 中受益的框架。 其他的 web 框架，比如 Django 和 Bottle，它们不知道 greenlets，当它们与 greenlet web 服务器配对时，也可以异步运行，并且猴子补丁修复了阻塞功能。 异步比同步更快吗？关于同步和异步应用程序的性能，存在广泛的误解。 人们认为异步应用程序比同步应用程序要快得多。 让我澄清一下，以便我们达成统一认知。 不管 Python 代码是同步编写还是异步编写，它的运行速度都是完全相同的。 除了代码外，还有两个因素可以影响并发应用程序的性能：上下文切换和可伸缩性。 上下文切换在所有正在运行的任务之间公平地共享 CPU 所需的工作（称为上下文切换）可能会影响应用程序的性能。对于同步应用程序，此工作由操作系统完成，并且基本上是一个没有配置或微调选项的黑匣子。对于异步应用程序，上下文切换由循环完成。 asyncio 提供的默认循环实现是用 Python 编写的，它不被认为是非常高效的。 uvloop 软件包提供了一个替代循环，该循环部分用C代码实现，以实现更好的性能。 Gevent和 Meinheld 使用的事件循环也用 C 代码编写。Eventlet使用 Python 编写的循环。 高度优化的异步循环在进行上下文切换方面可能比操作系统更有效，但是以我的经验，要想看到切实的性能提升，你必须在很高的并发级别上运行。对于大多数应用程序，我认为同步和异步上下文切换之间的性能差异不会很显著。 伸缩性我认为，异步更快的神话来源于异步应用程序通常能够更有效地使用 cpu，因为它们比同步具有更好的伸缩性和更灵活的方法。 考虑一下如果上图所示的同步服务器同时接收100个请求，将会发生什么情况。该服务器一次不能处理超过4个请求，因此其中大多数请求将在队列中等待一段时间，然后才能分配 worker。 与异步服务器相比，异步服务器会立即创建100个任务(如果使用混合模型，4个异步 worker 每个会创建25个任务)。使用异步服务器，所有请求都可以在不必等待的情况下开始处理(不过公平地说，可能还存在其他会降低速度的瓶颈，比如对活动数据库连接数的限制)。 如果这100个任务大量使用 CPU，那么同步和异步解决方案将有类似的性能，因为 CPU 运行的速度是固定的，Python 的执行代码的速度总是相同的，应用程序所做的工作也是相同的。但是，如果任务需要执行大量 I/O 操作，那么只有4个并发请求，同步服务器可能无法实现高 CPU 利用率。另一方面，异步服务器肯定能够更好地保持 cpu 处于忙碌状态，因为它并行地运行所有100个请求。 你可能想知道为什么不能运行100个同步 worker，这样两个服务器就具有相同的并发性。考虑一下，每个 worker都需要有自己的 Python 解释器，以及与之相关的所有资源，再加上具有自己资源应用程序的一个单独副本。服务器和应用程序的大小将决定可以运行多少个 worker 实例，但通常这个数字并不是很高。另一方面，异步任务非常轻量级，并且都在单个 worker 进程的上下文中运行，因此它们具有明显的优势。 记住这些，我们可以说异步只有在以下情况下才会比同步更快: 高负载（没有高负载就没有高并发性的优势） 任务受 I/O 约束（如果任务受CPU约束，那么 超过CPU 数以上的并发性就没有帮助了） 你可以查看每单位时间处理的平均请求数。如果查看单个请求处理时间，你不会看到很大的差异，并且因为有更多的并发任务竞争 CPU，异步甚至可能会稍微慢一点 我希望本文能够澄清一些关于异步代码的混淆和误解。我希望你们记住以下两个要点: 在高负载下，异步应用程序只会比同步等效程序做得更好 由于 greenlet，即使你编写普通代码并使用传统框架(如 Flask 或 Django) ，也可以从异步中受益 如果你想更详细地了解异步系统是如何工作的，请查看我的 PyCon 演示文稿 Asynchronous Python for the Complete Beginner。 翻译Sync vs. Async Python: What is the Difference?]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 HTTPS 上运行 FLASK 应用程序]]></title>
    <url>%2F2020%2F05%2F23%2F%E5%9C%A8%20HTTPS%20%E4%B8%8A%E8%BF%90%E8%A1%8C%20FLASK%20%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F.html</url>
    <content type="text"><![CDATA[在 HTTPS 上运行 FLASK 应用程序介绍在开发FLASK 应用过程中，通常会运行开发 web 服务器，它提供了一个基本的、但功能齐全的 WSGI HTTP 服务器。但是当部署应用程序到生产环境中，需要考虑的事情之一是，是否应该要求客户端使用加密连接以增加安全性。 那么应该如何在 HTTPS 上运行 FLASK 应用程序呢？在这篇文章中，我将介绍几个为 Flask 应用程序添加加密功能的选项，从一个只需要5秒钟就可以实现的非常简单的解决方案，到一个健壮的A+ 评级的解决方案。 HTTPS 是如何工作的？HTTP 的加密和安全功能是通过传输层安全(TLS)协议实现的。总的来说，TLS 定义了一种标准的方式来保证网络通道的安全。 其基本思想是，当客户端与服务器建立连接并请求加密连接时，服务器将使用其 SSL 证书 进行响应。该证书充当服务器的标识，因为它包括 服务器名称和域。为了确保服务器提供的信息是正确的，证书由证书颁发机构(CA)进行加密签名。如果客户端了解并信任CA，它可以确认证书签名确实来自此实体，并且通过此客户端，客户端可以确定其连接的服务器是合法的。 在客户端验证证书之后，它将创建一个加密密钥以用于与服务器的通信。为了确保此密钥安全地发送到服务器，它使用服务器证书中包含的公钥对其进行加密。服务器拥有与证书中的公钥一起使用的私钥，因此它是唯一能够解密的一方。从服务器接收到加密密钥开始，所有流量都使用只有客户端和服务器知道的密钥进行加密。 为了实现 TLS 加密，我们需要两个条目: 服务器证书，其中包括由CA签名的公共密钥; 与证书中包含的公共密钥一起的私钥。 最简单的方法Flask (更具体地说是 Werkzeug)支持使用动态证书(on-the-fly certificates) ，这对于通过HTTPS快速为应用程序提供服务而无需证书时非常有用。 要在 Flask 上使用临时证书，你需要在虚拟环境中安装一个附加依赖项:1$ pip install pyopenssl 然后将ssl_context =’adhoc’添加到 app.run()调用中：123456789from flask import Flaskapp = Flask(__name__)@app.route("/")def hello(): return "Hello World!"if __name__ == "__main__": app.run(ssl_context='adhoc') 如果您使用的是Flask 1.x发行版，则还可以通过Flask CLI使用此选项：1$ flask run --cert=adhoc 当运行这个脚本(或者 flask run ) ，你会注意到 Flask 表明它运行的是 https://server:12$ python hello.py * Running on https://127.0.0.1:5000/ (Press CTRL+C to quit) 但是存在的问题是，浏览器不喜欢这种类型的证书，所以它们会显示一个可怕的警告，您需要在访问应用程序之前解除这个警告。一旦你允许浏览器连接，你将会有一个加密的连接，就像你从一个有效证书的服务器那里得到的一样，使用这些临时证书可以很方便进行测试，但不适用于任何实际用途。 自签名证书所谓的自签名证书是使用与该证书关联的私钥生成签名的证书。 我在上面提到，客户端需要“了解并信任”签署证书的CA，因为这种信任关系使客户端可以验证服务器证书。 Web 浏览器和其他 HTTP 客户端预先配置了已知和受信任的 CA 列表，但是显然，如果使用自签名证书，则CA将不会被知晓，并且验证将失败。 这正是我们在上一节中使用的临时证书所发生的。 如果 web 浏览器无法验证服务器证书，它允许继续进行操作并访问有问题的网站，但它将提醒你这样做需要承担的风险。 但是真的有风险吗？ 使用上一部分的Flask服务器，你显然相信自己，所以对你来说没有风险。 问题是，当用户连接到他们不了解或控制的站点时，会出现此警告。 在这种情况下，用户将无法知道服务器是否真实，因为任何人都可以为任何域生成证书。 虽然自签名证书有时很有用，但 Flask 中的临时证书并不是很好，因为每次服务器运行时，都会通过 pyOpenSSL 生成不同的证书。当使用自签名证书时，最好在每次启动服务器时使用相同的证书，因为这样可以配置浏览器信任它，并消除安全警告。 可以通过命令行生成自签名证书，只需安装 openssl:1openssl req -x509 -newkey rsa:4096 -nodes -out cert.pem -keyout key.pem -days 365 该命令在cert.pem中写入一个新证书，并在key.pem中写入其对应的私钥，有效期为365天。运行此命令时，将询问几个问题： 12345678910111213141516171819Generating a 4096 bit RSA private key......................++.............++writing new private key to 'key.pem'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]:USState or Province Name (full name) [Some-State]:OregonLocality Name (eg, city) []:PortlandOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Miguel Grinberg BlogOrganizational Unit Name (eg, section) []:Common Name (e.g. server FQDN or YOUR name) []:localhostEmail Address []: 现在，我们可以在 Flask 应用程序中使用这个新的自签名证书，方法是将 app.run()中的 ssl_context 参数设置为一个元组，其中包含证书和私钥文件的文件名。1234567rom flask import Flaskapp = Flask(__name__)@app.route("/")def hello(): return "Hello World!"if __name__ == "__main__": app.run(ssl_context=('cert.pem', 'key.pem')) 如果你使用的是Flask 1.x或更高版本，则可以在flask run命令中添加–cert和–key选项：1$ flask run --cert=cert.pem --key=key.pem 浏览器仍然会告警，但是如果你检查这个证书，你会看到你创建它时输入的信息 使用生产 Web 服务器我们都知道 Flask 开发服务器只适用于开发和测试。那么，我们如何在生产服务器上安装 SSL 证书呢？ 如果你使用 gunicorn，你可以使用命令行参数:1$ gunicorn --certfile cert.pem --keyfile key.pem -b 0.0.0.0:8000 hello:app 如果你使用 nginx 作为反向代理，那么你可以使用 nginx 配置证书，然后 nginx 可以“终止”加密连接，这意味着它将接受来自外部的加密连接，但随后使用常规的非加密连接与 Flask 后端通信。这是一个非常有用的设置，因为它使应用程序不必处理证书和加密。Nginx 的配置项如下:1234567server &#123; listen 443 ssl; server_name example.com; ssl_certificate /path/to/cert.pem; ssl_certificate_key /path/to/key.pem; # ...&#125; 你需要考虑的另一个重要问题是如何处理通过常规 HTTP 连接的客户端。在我看来，最好的解决方案是通过重定向到相同的 URL 但使用 HTTPS 来响应未加密的请求。对于一个 Flask 应用程序，你可以通过 Flask-SSLify 扩展来实现。使用 nginx，你可以在配置中包含另一个服务器块:1234567server &#123; listen 80; server_name example.com; location / &#123; return 301 https://$host$request_uri; &#125;&#125; 使用「真正」证书我们现在已经研究了自签名证书的所有选项，但是在所有这些情况下，局限性仍然存在，除非你告诉 web 浏览器，否则它们不会信任这些证书。 因此对于生产站点来说，服务器证书的最佳选择是从这些众所周知并被所有 web 浏览器自动信任的 CA 之一获得它们。 当你向 CA 请求证书时，该实体将验证您是否在服务器和域的控制范围内，但是验证的方式取决于 CA。如果服务器通过此验证，那么 CA 将为其颁发一个带有自己签名的证书，并将其交给你安装。证书有效期通常不超过一年。大多数CA会对这些证书收费，但也有一些免费提供证书。最受欢迎的免费 CA 叫做 Let’s Encrypt。 从 Let’s Encrypt 获取证书相当容易，因为整个过程是自动化的。假设你正在使用一个基于 Ubuntu 的服务器，你需要在你的服务器上安装他们的开源 certbot 工具:1234$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update$ sudo apt-get install certbot 现在，你可以使用 certbot 工具请求证书。Certbot 可通过多种方式来验证您的站点。 通常，“ webroot”方法是最容易实现的。使用这种方法，certbot 将一些文件添加到 web 服务器以静态文件形式公开的目录中，然后尝试使用要为其生成证书的域通过 HTTP 访问这些文件。如果这个测试成功，certbot 知道运行它的服务器与正确的域相关联，并与之匹配，并颁发证书。使用此方法请求证书的命令如下:1$ sudo certbot certonly --webroot -w /var/www/example -d example.com 在此示例中，我们尝试为example.com域生成证书，该证书使用 /var/www/example 中的目录作为静态文件根。 不幸的是，基于Flask的网站没有静态文件根目录，至少使用默认配置时，使用 /static前缀访问应用程序中的所有静态文件，因此需要进行更多规划。 在此示例中，我们尝试为example.com域生成证书，该证书使用 /var/www/example 中的目录作为静态文件根。 不幸的是，基于Flask的网站没有静态文件根目录（至少使用默认配置时），需要使用 /static前缀访问应用程序中的所有静态文件。 Certbot 对静态根目录执行的操作是添加一个 .well-known 子目录，并在其中存储一些文件。然后它使用 HTTP 客户端以 [http://example.com/.well-known/...](http://example.com/.well-known/...) 的形式检索这些文件 。如果可以检索这些文件，则表明你的服务器完全控制了域名。对于 Flask 和其他没有静态文件根目录的应用程序，有必要定义一个根目录。 如果将nginx用作反向代理，则可以利用可在配置中创建的强大映射为certbot提供一个私有目录，在该目录中可以写入其验证文件。 在以下示例中，我扩展了上一节中显示的HTTP服务器块，以将所有与加密相关的请求（始终以/.well-known / …开头）发送到您选择的特定目录： 如果使用 nginx 作为反向代理，那么可以在配置中创建的强大映射来为 certbot 提供一个私有目录，在这个目录中它可以写入其验证文件12345678910server &#123; listen 80; server_name example.com; location ~ /.well-known &#123; root /path/to/letsencrypt/verification/directory; &#125; location / &#123; return 301 https://$host$request_uri; &#125;&#125; 然后你可以把这个目录交给 certbot:1$ sudo certbot certonly --webroot -w /path/to/letsencrypt/verification/directory -d example.com 如果 certbot 能够验证域名，它将把证书文件写成/etc/letsencrypt/live/ example.com/fullchain.pem ，私钥写成/etc/letsencrypt/live/ example.com/privkey.pem ，有效期为90天。 要使用这个新获得的证书，可以输入上面提到的两个文件名来代替我们之前使用的自签名文件，这应该适用于上面描述的任何配置。当然，你也需要让你的应用程序通过你注册的域名可用，因为这是浏览器接受证书为有效的唯一方式。 当你需要更新证书时也可以使用 Certbot:1$ sudo certbot renew 如果系统中有任何证书即将过期，上面的命令将更新它们，并在相同的位置留下新的证书。如果你希望获取更新后的证书，你可能需要重新启动你的 web 服务器。 获得SSL A+ 等级如果您在生产站点上使用 Let’s Encrypt 或其他已知 CA 的证书，并在此服务器上运行最新维护的操作系统，那么你很可能拥有一个在 SSL 安全性方面有最高评分的服务器。您可以前往 Qualys SSL Labs 实验室网站，获得一个报告。 报告会指出你需要改进的地方，但是一般来说，我希望你会被告知服务器公开的加密通信选项太宽，或者太弱，使你容易受到已知漏洞的影响。 易于改进的地方之一是如何生成在加密密钥交换过程中使用的系数，这些系数通常具有相当弱的默认值。 特别是，Diffie-Hellman 系数需要花费大量时间才能生成，因此默认情况下，服务器使用较小的数字来节省时间。 但是我们可以预先生成强系数并将其存储在文件中，然后 nginx 就可以使用它们了。 使用openssl工具，你可以运行以下命令：1openssl dhparam -out /path/to/dhparam.pem 2048 如果你想要更强的系数，你可以把上面的2048改成4096。这个命令需要一些时间来运行，特别是如果你的服务器没有很多的 CPU 能量，但是当它运行的时候，你会有一个带有强系数的 dhparam.pem 文件，你可以插入 nginx 的 ssl 服务器 block1ssl_dhparam /path/to/dhparam.pem; 你可能需要配置服务器允许加密通信的密码。这是我服务器上的列表:1ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:!DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA'; 在此列表中，使用！前缀禁用ciphers 。 SSL 报告将告诉你是否存在不建议使用的任何密码。 你必须不时地检查，以确定是否发现了需要修改此列表的新漏洞。 下面你可以找到我当前的 nginx SSL 配置，包括上面的设置，还有一些我添加到 SSL 报告中的警告:123456789101112131415server &#123; listen 443 ssl; server_name example.com; ssl_certificate /path/to/cert.pem; ssl_certificate_key /path/to/key.pem; ssl_dhparam /path/to/dhparam.pem; ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:!DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA'; ssl_protocols TLSv1.2; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_stapling on; ssl_stapling_verify on; add_header Strict-Transport-Security max-age=15768000; # ...&#125; 你可以看到我的网站获得的SSL 安全报告。 如果你在所有类别中的得分都未达到100％，则必须对配置添加其他限制，但这将限制可以连接到你的站点的客户端的数量。 通常，较旧的浏览器和HTTP客户端使用的 ciphers 不被认为是最强的，但是如果禁用 ciphers，则这些客户端将无法连接。 因此，你基本上需要妥协，并且还需要定期检查安全报告并随着情况的变化进行更新。 不幸的是，对于最近这些 SSL改进的复杂程度，你将需要使用专业级的Web服务器，因此，如果你不想使用nginx，则需要找到一个支持这些设置的服务器，而且这个列表非常小。 我知道 Apache 可以，但是除此之外，我不知道还有别的。 翻译自Running Your Flask Application Over HTTPS]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Flask 处理文件上传]]></title>
    <url>%2F2020%2F04%2F12%2F%E4%BD%BF%E7%94%A8%20Flask%20%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html</url>
    <content type="text"><![CDATA[使用 Flask 处理文件上传Web 应用程序的一个常见特性是允许用户将文件上传到服务器。在 RFC 1867 中协议记录了客户端上传文件的机制，我们最喜欢的 Web 框架 Flask 完全支持这一机制，但是对于许多开发者来说，还有许多实现细节未遵循该正式规范。诸如在何处存储上传的文件，如何事后使用它们，或者如何保护服务器不受恶意文件上传的影响，这些都会产生很多混乱和不确定性。 在本文中，我将向你展示如何为 Flask 服务器实现强大的文件上传功能，该功能不仅支持基于 Web 浏览器中的标准文件上传并且与基于 JavaScript 的上传小部件兼容： 基本文件上传表单从高层次的角度来看，上传文件的客户端与其他任何表单数据提交一样。 换句话说，你必须定义一个包含文件字段的 HTML 表单。 下面是一个简单的 HTML 页面，该表单接受一个文件:12345678910111213&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;File Upload&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;File Upload&lt;/h1&gt; &lt;form method="POST" action="" enctype="multipart/form-data"&gt; &lt;p&gt;&lt;input type="file" name="file"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="Submit"&gt;&lt;/p&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 你可能知道，&lt;form&gt; 元素的 method 属性可以是 GET 或 POST。使用 GET 时，数据将在请求 URL 的查询字符串中提交，而使用 POST 时，数据将进入请求主体。在表单中包含文件时，必须使用 POST，因为不可能在查询字符串中提交文件数据。 没有文件的表单通常不包含 &lt;form&gt; 元素中的 enctype 属性。此属性定义浏览器在将数据提交到服务器之前应该如何格式化数据。HTML 规范为其定义了三个可能的值： application/x-www-form-urlencoded: 这是默认格式，也是不包含文件字段的表单的最佳格式 multipart/form-data: 如果表单中至少有一个字段是文件字段，则需要此格式 text/plain: 这种格式没有实际用途，所以你应该忽略它 实际的文件字段是我们用于大多数其他表单字段的标准 &lt;input&gt; 元素，其类型设置为 file。 在上面的示例中，我没有包含任何其他属性，但是file字段支持两个有时有用的属性： multiple: 可用于允许在单个文件字段中上载多个文件。例如:1&lt;input type="file" name="file" multiple&gt; accept: 可以用于筛选允许的文件类型，这些文件类型可以通过文件扩展名或媒体类型选择。例子:12&lt;input type="file" name="doc_file" accept=".doc,.docx"&gt;&lt;input type="file" name="image_file" accept="image/*"&gt; ## 使用 Flask 接受文件提交对于常规表单，Flask 提供了对 request.form 字典中提交的表单字段的访问。 但是，文件字段包含在request.files 字典中。 request.form 和 request.files 字典实际上是“multi-dicts”，它是一种支持重复键的专门字典实现。 这是必要的，因为表单可以包含多个具有相同名称的字段，通常情况下是由多组复选框组成。 对于允许多个文件的文件字段，也会发生这种情况。 暂时忽略诸如验证和安全性等重要方面，下面简短的 Flask 应用程序接受使用上一节中定义的表单上传的文件，并将提交的文件写入当前目录：1234567891011from flask import Flask, render_template, request, redirect, url_forapp = Flask(__name__)@app.route('/')def index(): return render_template('index.html')@app.route('/', methods=['POST'])def upload_file(): uploaded_file = request.files['file'] if uploaded_file.filename != '': uploaded_file.save(uploaded_file.filename) return redirect(url_for('index')) upload_file() 函数使用@app.route装饰，以便在浏览器发送POST请求时调用该函数。 请注意，同一个根 URL 是如何在两个视图函数之间进行拆分的，并将 index() 设置为接受 GET 请求，将 upload_file``() 上传为 POST 请求。 uploaded_file 变量保存提交的文件对象。 这是 Flask 从 Werkzeug 导入的 FileStorage 类的实例。 FileStorage 中的 filename 属性提供客户端提交的文件名。如果用户提交表单时没有在 file 字段中选择文件，那么文件名将是一个空字符串，因此始终检查文件名以确定文件是否可用是很重要的。 Flask 收到文件提交后，不会自动将其写入磁盘。 这实际上是一件好事，因为它使应用程序有机会查看和验证文件提交，这一点将在后面看到。 可以从 stream 属性访问实际文件数据。 如果应用程序只想将文件保存到磁盘，则可以调用 save() 方法，并将所需路径作为参数传递。 如果未调用文件的 save() 方法，则该文件将被丢弃。 是否要使用此应用程序测试文件上传？ 为你的应用程序创建目录，并将上面的代码编写为 app.py。 然后创建一个模板子目录，并将上一节中的HTML页面编写为templates/index.html。 创建一个虚拟环境并在其上安装Flask，然后使用 flask run 运行该应用程序。 每次提交文件时，服务器都会把它的副本写到当前目录中。 在继续讨论安全性主题之前，我将讨论上面的代码的一些变体，你可能会发现这些变体很有用。 如前所述，可以将文件上传字段配置为接受多个文件。 如果像上面那样使用 request.files[&#39;file&#39;]，则只会得到一个提交的文件，但是使用 getlist() 方法，你可以在for循环中访问所有文件：123for uploaded_file in request.files.getlist('file'): if uploaded_file.filename != '': uploaded_file.save(uploaded_file.filename) 许多人在 Flask 中编写表单处理路由时，对 GET 和 POST 请求使用单个视图函数。使用单视图函数的示例应用程序的版本编码如下:12345678@app.route('/', methods=['GET', 'POST'])def index(): if request.method == 'POST': uploaded_file = request.files['file'] if uploaded_file.filename != '': uploaded_file.save(uploaded_file.filename) return redirect(url_for('index')) return render_template('index.html') 最后，如果使用 Flask-WTF 扩展来处理表单，则可以使用 FileField 对象上传文件。到目前为止，你看到的例子中使用的表单可以使用 Flask-WTF 编写如下:123456from flask_wtf import FlaskFormfrom flask_wtf.file import FileFieldfrom wtforms import SubmitFieldclass MyForm(FlaskForm): file = FileField('File') submit = SubmitField('Submit') 注意，FileField 对象来自 flask_wtf 包，与大多数其他字段类不同，后者直接从 wtforms 包导入。Flask-WTF 为文件字段提供了两个验证器，FileRequired 和 FileAllowed，前者执行类似于空字符串检查的检查，后者确保文件扩展名包含在允许的扩展名列表中。 当您使用 Flask-WTF 表单时，file 字段对象的 data 属性指向 FileStorage 实例，因此将文件保存到磁盘的工作方式与上面的示例相同。 保护文件上传上一节中给出的文件上传示例是一个非常简单的实现，不是很健壮。Web 开发中最重要的规则之一是永远不要信任客户提交的数据，因此在使用常规表单时，像 Flask-WTF 这样的扩展会在接受表单和整合数据到应用程序中之前对所有字段进行严格验证。对于包含文件字段的表单，也需要进行验证，因为如果不进行文件验证，服务器将为攻击敞开大门。例如: 攻击者可以上传一个非常大的文件，以至于服务器中的磁盘空间完全被填满，从而导致服务器出现故障 攻击者可以使用文件名（例如../../../.bashrc或类似文件）的上传请求，以试图欺骗服务器重写系统配置文件。 攻击者可以上传带有病毒或其他类型恶意软件的文件到应用程序需要使用的位置，例如，用户头像### 限制上传文件的大小为了防止客户端上传非常大的文件，您可以使用 Flask 提供的配置选项。MAX_CONTENT_LENGTH 选项控制请求主体可以拥有的最大大小。虽然这不是一个特定于文件上传的选项，但设置一个最大的请求体大小有效地使 Flask 使用413状态码丢弃大于允许的请求体大小的请求 让我们修改上一节中的 app.py 示例，只接受最大为1 MB 的请求:1app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024 如果你试图上传一个大于1 MB 的文件，应用程序现在将拒绝它。 验证文件名我们不能完全相信客户端提供的文件名是有效的和可以安全使用的，所以随上传文件一起提供的文件名必须经过验证。 要执行的一个非常简单的验证是确保文件扩展名是应用程序愿意接受的扩展名，这与使用 Flask-WTF 时F FileAllowed 验证器所做的类似。假设应用程序接受图像，那么它可以配置允许的文件扩展名列表:1app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.gif'] 对于每个上传的文件，应用程序可以确保文件扩展名是允许的:12345filename = uploaded_file.filenameif filename != '': file_ext = os.path.splitext(filename)[1] if file_ext not in current_app.config['UPLOAD_EXTENSIONS']: abort(400) 使用这种逻辑，任何不在允许的文件扩展名的文件名，都会出现400错误。 除了文件扩展名之外，验证文件名以及提供的任何路径也很重要。 如果你的应用程序不关心客户端提供的文件名，则处理上传的最安全方法是忽略客户端提供的文件名，而是生成自己的文件名，然后传递给 save() 方法。 这种技术工作良好的示例是头像上传。 每个用户的头像都可以使用用户 ID 保存为文件名，因此客户端提供的文件名可以丢弃。 如果你的应用程序使用 Flask-Login，则可以实现以下 save() 调用：1uploaded_file.save(os.path.join('static/avatars', current_user.get_id())) 在其他情况下，保留客户端提供的文件名可能更好，因此必须首先清理文件名。对于这些情况，Werkzeug 提供了 secure_filename() 函数。让我们通过在 Python shell 中运行一些测试来看看这个函数是如何工作的:1234567&gt;&gt;&gt; from werkzeug.utils import secure_filename&gt;&gt;&gt; secure_filename('foo.jpg')'foo.jpg'&gt;&gt;&gt; secure_filename('/some/path/foo.jpg')'some_path_foo.jpg'&gt;&gt;&gt; secure_filename('../../../.bashrc')'bashrc' 正如你在示例中看到的，无论文件名有多么复杂或多么恶意，secure_filename() 函数都将其缩减为一个单位文件名。 让我们将 secure_filename() 合并到示例上传服务器中，并添加一个配置变量，该变量定义文件上传的专用位置。下面是带有安全文件名的完整 app.py 源文件:1234567891011121314151617181920import osfrom flask import Flask, render_template, request, redirect, url_for, abortfrom werkzeug.utils import secure_filenameapp = Flask(__name__)app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.gif']app.config['UPLOAD_PATH'] = 'uploads'@app.route('/')def index(): return render_template('index.html')@app.route('/', methods=['POST'])def upload_files(): uploaded_file = request.files['file'] filename = secure_filename(uploaded_file.filename) if filename != '': file_ext = os.path.splitext(filename)[1] if file_ext not in app.config['UPLOAD_EXTENSIONS']: abort(400) uploaded_file.save(os.path.join(app.config['UPLOAD_PATH'], filename)) return redirect(url_for('index')) ### 注意secure_filename 函数将过滤所有非ASCII字符，因此，如果filename 是 “头像.jpg”之类的，则结果为”jpg”，但没有格式，这是个问题，我建议使用uuid模块重命名上传的文件，以避免出现上述情况。 验证文件内容我将要讨论的第三层验证是最复杂的。如果您的应用程序接受某种文件类型的上传，那么理想情况下，它应该执行某种形式的内容验证，并拒绝任何不同类型的文件。 如何实现内容验证在很大程度上取决于应用程序接受的文件类型。对于本文中的示例应用程序，我使用的是图像，因此可以使用 Python 标准库中的 imghdr 包验证文件头实际上是一个图像。 让我们编写一个 validate_image() 函数，对图像执行内容验证:12345678import imghdrdef validate_image(stream): header = stream.read(512) stream.seek(0) format = imghdr.what(None, header) if not format: return None return '.' + (format if format != 'jpeg' else 'jpg') 这个函数以一个字节流作为参数。它首先从流中读取512个字节，然后重置流指针，因为稍后当调用 save ()函数时，我们希望它看到整个流。前512字节的图像数据将足以识别图像的格式。 如果第一个参数是文件名，imghdr.what() 函数可以查看存储在磁盘上的文件; 如果第一个参数是 None，数据在第二个参数中传递，则可以查看存储在内存中的数据。FileStorage 对象为我们提供了一个流，因此最方便的选项是从它中读取安全数量的数据，并在第二个参数中将其作为字节序列传递。 imghdr.what() 的返回值是检测到的图像格式。该函数支持多种格式，其中包括流行的 jpeg、 png 和 gif。如果未检测到已知的图像格式，则返回值为 None。如果检测到格式，则返回该格式的名称。最方便的是将格式作为文件扩展名返回，因为应用程序可以确保检测到的扩展名与文件扩展名匹配，所以 validate_image() 函数将检测到的格式转换为文件扩展名。这很简单，只需为除 jpeg 外的所有图像格式添加一个点作为前缀，jpeg 除外，通常使用 .jpg扩展名。 下面是完整的 app.py，包含前面几节中的所有特性和内容验证:1234567891011121314151617181920212223242526272829import imghdrimport osfrom flask import Flask, render_template, request, redirect, url_for, abortfrom werkzeug.utils import secure_filenameapp = Flask(__name__)app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.gif']app.config['UPLOAD_PATH'] = 'uploads'def validate_image(stream): header = stream.read(512) stream.seek(0) format = imghdr.what(None, header) if not format: return None return '.' + (format if format != 'jpeg' else 'jpg')@app.route('/')def index(): return render_template('index.html')@app.route('/', methods=['POST'])def upload_files(): uploaded_file = request.files['file'] filename = secure_filename(uploaded_file.filename) if filename != '': file_ext = os.path.splitext(filename)[1] if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \ file_ext != validate_image(uploaded_file.stream): abort(400) uploaded_file.save(os.path.join(app.config['UPLOAD_PATH'], filename)) return redirect(url_for('index')) 在视图函数中唯一的变化就是加入了最后一个验证逻辑:123if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \ file_ext != validate_image(uploaded_file.stream): abort(400) 这个扩展检查首先确保文件扩展名在允许的列表中，然后确保通过查看数据流检测到的文件扩展名与文件扩展名相同。 在测试这个版本的应用程序之前，创建一个名为 uploads 的目录(或者你在 UPLOAD_PATH 配置变量中定义的路径) ，以便可以将文件保存在那里。 使用上传的文件你现在知道如何处理文件上传。对于某些应用程序，这就是所需要的全部内容，因为这些文件用于某些内部进程。但是对于大量的应用程序，特别是那些具有社交功能的应用程序，比如头像，用户上传的文件必须与应用程序集成。以 avatar 为例，一旦用户上传了他们的 avatars 图片，任何提到用户名的地方都需要上传的图片显示在侧面。 我将文件上传分为两大类，具体取决于用户上传的文件是供公众使用还是对每个用户私有。 本文中多次讨论过的 avatar 图像显然属于第一类，因为这些 avatar 旨在与其他用户公开共享。 另一方面，对上传的图像执行编辑操作的应用程序可能在第二类中，因为你希望每个用户只能访问自己的图像。 公共文件上传当图像属于公共性质时，使图像可供应用程序使用的最简单方法是将上传目录放在应用程序的静态文件夹中。例如，可以在 static 中创建 avatars 子目录，然后使用用户 id 作为名称在该位置保存头像。 使用 url_for() 函数以与应用程序的常规静态文件相同的方式引用存储在静态文件夹的子目录中的这些上传文件。 我之前建议在保存上传的头像图像时使用用户 id 作为文件名。这就是图片保存的方式:1uploaded_file.save(os.path.join('static/avatars', current_user.get_id())) 使用这个实现，给定一个用户 id，可以生成用户头像的 URL 如下:1url_for('static', filename='avatars/' + str(user_id)) 或者，可以将上传保存到静态文件夹外的目录中，然后可以添加新的路由来为其提供服务。在示例 app.py 应用程序文件中，上传的文件保存到 UPLOAD_PATH 配置变量中设置的位置。为了从该位置提供这些文件，我们可以实现以下路由:1234from flask import send_from_directory@app.route('/uploads/&lt;filename&gt;')def upload(filename): return send_from_directory(app.config['UPLOAD_PATH'], filename) 这个解决方案比在静态文件夹中存储上传的一个优点是，在返回这些文件之前，你可以实现额外的限制，要么直接在函数体内使用 Python 逻辑，要么使用 decorator。例如，如果你只希望向登录的用户提供对上传的访问，那么你可以将 Flask-Login 的 @login_required 装饰器添加到这个路由中，或者添加用于正常路由的任何其他身份验证或角色检查机制。 让我们使用这种实现思想在示例应用程序中显示上传的文件。下面是 app.py 的一个新的完整版本:12345678910111213141516171819202122232425262728293031323334import imghdrimport osfrom flask import Flask, render_template, request, redirect, url_for, abort, \ send_from_directoryfrom werkzeug.utils import secure_filenameapp = Flask(__name__)app.config['MAX_CONTENT_LENGTH'] = 1024 * 1024app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.gif']app.config['UPLOAD_PATH'] = 'uploads'def validate_image(stream): header = stream.read(512) # 512 bytes should be enough for a header check stream.seek(0) # reset stream pointer format = imghdr.what(None, header) if not format: return None return '.' + (format if format != 'jpeg' else 'jpg')@app.route('/')def index(): files = os.listdir(app.config['UPLOAD_PATH']) return render_template('index.html', files=files)@app.route('/', methods=['POST'])def upload_files(): uploaded_file = request.files['file'] filename = secure_filename(uploaded_file.filename) if filename != '': file_ext = os.path.splitext(filename)[1] if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \ file_ext != validate_image(uploaded_file.stream): abort(400) uploaded_file.save(os.path.join(app.config['UPLOAD_PATH'], filename)) return redirect(url_for('index'))@app.route('/uploads/&lt;filename&gt;')def upload(filename): return send_from_directory(app.config['UPLOAD_PATH'], filename) 除了新的 upload() 函数之外，index() 视图函数使用 os.listdir ()获取上传位置中的文件列表，并将其发送到模板以进行呈现。更新后的 index.html 模板内容如下:1234567891011121314151617&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;File Upload&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;File Upload&lt;/h1&gt; &lt;form method="POST" action="" enctype="multipart/form-data"&gt; &lt;p&gt;&lt;input type="file" name="file"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="Submit"&gt;&lt;/p&gt; &lt;/form&gt; &lt;hr&gt; &#123;% for file in files %&#125; &lt;img src="&#123;&#123; url_for('upload', filename=file) &#125;&#125;" style="width: 64px"&gt; &#123;% endfor %&#125; &lt;/body&gt;&lt;/html&gt; 有了这些改变，每次你上传一张图片，页面底部就会添加一个缩略图: 私有文件上传当用户将私有文件上传到应用程序时，需要进行额外的检查，以防止一个用户与未经授权的方共享文件。这些情况的解决方案需要上面所示的 upload() 视图函数的变体，以及额外的访问检查。 一个常见的要求是只与所有者共享上传的文件。当存在此需求时，存储上传的一种方便方法是为每个用户使用一个单独的目录。例如，可以将给定用户的上传保存到 uploads/ 目录，然后可以修改 uploads() 函数，使其只服务于用户自己的上传目录，这样一来，一个用户就不可能从另一个用户那里查看文件。下面你可以看到这个技术的一个可能的实现，再次假设使用了 Flask-Login: 12345@app.route('/uploads/&lt;filename&gt;')@login_requireddef upload(filename): return send_from_directory(os.path.join( app.config['UPLOAD_PATH'], current_user.get_id()), filename) 显示上传进度到目前为止，我们一直依赖 web 浏览器提供的原生文件上传小部件来启动我们的文件上传。我相信我们都同意这个小工具不是很吸引人。不仅如此，由于缺少上传进度显示，它无法用于上传大文件，因为用户在整个上传过程中不能收到任何反馈。虽然本文的范围是涵盖服务器端，但我认为，如果能够给你提供一些关于如何实现一个基于 JavaScript 的现代文件上传小部件以显示上传进度的想法将很有用。 好消息是，在服务器上不需要进行任何大的更改，无论你在浏览器中使用哪种方法来启动上传，上传机制都以相同的方式工作。 为了向你展示一个示例实现，我将用与流行的文件上传客户端 dropzone.js 兼容的index.html 替换HTML表单。 下面是一个新版本的 templates/index.html，它从 CDN 加载下拉区 CSS 和 JavaScript 文件，并根据dropzone documentation 实现一个上传表单:123456789101112&lt;html&gt; &lt;head&gt; &lt;title&gt;File Upload&lt;/title&gt; &lt;link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/dropzone/5.7.1/min/dropzone.min.css"&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;File Upload&lt;/h1&gt; &lt;form action="&#123;&#123; url_for('upload_files') &#125;&#125;" class="dropzone"&gt; &lt;/form&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/dropzone/5.7.1/min/dropzone.min.js"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 在实现 dropzone 时，我发现了一件有趣的事情，那就是它要求设置 元素中的 action 属性，即使标准 forms 接受一个空的动作来指示提交到相同的 URL。 用这个新版的模板启动服务器，你会得到以下结果:基本上就是这样！现在你可以拖拽文件，它们将上传到服务器，并带有一个进度条和成功或失败的最终指示。 如果文件上传失败，无论是由于文件太大或无效，dropzone 想要显示一个错误消息。因为我们的服务器正在返回413和400错误的标准 Flask 错误页面，您将在错误弹出窗口中看到一些乱七八糟的 HTML。为了纠正这个错误，我们可以更新服务器以文本形式返回错误响应。 当请求有效负载大于配置中设置的大小时，Flask 会生成文件过大条件的413错误。要覆盖默认的错误页面，我们必须使用 app.errorhandler 装饰器:123@app.errorhandler(413)def too_large(e): return "File is too large", 413 当任何验证检查失败时，应用程序将生成第二个错误条件。在这种情况下，错误是通过一个 abort(400) 调用生成的。取而代之的是，可以直接生成响应:123if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \ file_ext != validate_image(uploaded_file.stream): return "Invalid image", 400 我要做的最后一个改变并不是真的需要，但是它节省了一点带宽。对于成功上传，服务器返回一个 redirect() 到主路由。这将导致上传表单再次显示，并刷新页面底部的上载缩略图列表。现在这些都不需要了，因为上传是作为后台请求通过 dropzone 完成的，所以我们可以消除重定向，并使用代码204切换到空响应。 下面是 app.py 的完整更新版本，可以与 dropzone.js 一起使用:12345678910111213141516171819202122232425262728293031323334353637import imghdrimport osfrom flask import Flask, render_template, request, redirect, url_for, abort, \ send_from_directoryfrom werkzeug.utils import secure_filenameapp = Flask(__name__)app.config['MAX_CONTENT_LENGTH'] = 2 * 1024 * 1024app.config['UPLOAD_EXTENSIONS'] = ['.jpg', '.png', '.gif']app.config['UPLOAD_PATH'] = 'uploads'def validate_image(stream): header = stream.read(512) stream.seek(0) format = imghdr.what(None, header) if not format: return None return '.' + (format if format != 'jpeg' else 'jpg')@app.errorhandler(413)def too_large(e): return "File is too large", 413@app.route('/')def index(): files = os.listdir(app.config['UPLOAD_PATH']) return render_template('index.html', files=files)@app.route('/', methods=['POST'])def upload_files(): uploaded_file = request.files['file'] filename = secure_filename(uploaded_file.filename) if filename != '': file_ext = os.path.splitext(filename)[1] if file_ext not in app.config['UPLOAD_EXTENSIONS'] or \ file_ext != validate_image(uploaded_file.stream): return "Invalid image", 400 uploaded_file.save(os.path.join(app.config['UPLOAD_PATH'], filename)) return '', 204@app.route('/uploads/&lt;filename&gt;')def upload(filename): return send_from_directory(app.config['UPLOAD_PATH'], filename) 用这个更新重新启动应用程序，现在错误将会有一个正确的消息:dropzone.js 库非常灵活，有许多定制选项，因此我鼓励你访问他们的文档，了解如何使其适应你的需求。你也可以寻找其他的 JavaScript 文件上传库，因为它们都遵循 HTTP 标准，这意味着你的 Flask 服务器可以很好地与它们一起工作。 翻译Handling File Uploads With Flask]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Systemd将Flask应用程序作为服务运行]]></title>
    <url>%2F2020%2F03%2F08%2F%E4%BD%BF%E7%94%A8%20Systemd%E5%B0%86Flask%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%BD%9C%E4%B8%BA%E6%9C%8D%E5%8A%A1%E8%BF%90%E8%A1%8C.html</url>
    <content type="text"><![CDATA[使用 Systemd将Flask应用程序作为服务运行在服务器上部署应用程序时，需要确保应用程序不间断地运行。如果应用程序崩溃，则希望它自动重启，如果服务器断电，则希望该应用程序在恢复电源后立即启动。 基本上，您需要的是监视应用程序并在发现不再运行时将其重启。 在以前的教程中，我向你展示了如何使用supervisord（一种用Python编写的第三方实用程序）实现此功能。 今天，我将向您展示基于 systemd 的类似解决方案，它是许多 Linux发行版中的本地组件，包括Debian衍生产品（如Ubuntu）和 RedHat 衍生产品（如Fedora和CentOS）。 使用 Systemd 配置服务Systemd 通过称为 unit 的实体进行配置。 有几种类型的 unit，包括服务，套接字，设备，计时器等。 对于服务，unit 配置文件必须具有.service扩展名。 在下面，你可以看到服务 unit 配置文件的基本结构：123456789101112[Unit]Description=&lt;a description of your application&gt;After=network.target[Service]User=&lt;username&gt;WorkingDirectory=&lt;path to your app&gt;ExecStart=&lt;app start command&gt;Restart=always[Install]WantedBy=multi-user.target [Unit] 部分是所有类型的 unit 配置文件的公共部分。它用于配置关于 unit 和任何依赖项的一般信息，这些信息有助于系统确定启动顺序。在我的模板中，我添加了服务的描述，并且我还指定我希望我的应用程序在网络子系统初始化后启动，因为它是一个 web 应用程序。 [Service] 部分包含了特定于你的应用程序的详细信息。我使用最常见的选项来定义运行服务的用户、起始目录和执行命令。Restart 选项告诉 systemd，除了在系统启动时启动服务外，如果应用程序退出，我还希望重新启动它。这样可以解决崩溃或其他可能导致进程结束的意外问题。 最后， [Install] 部分将配置启用该 unit 的方式和时间。通过添加 WantedBy=multi-user.target 行我告诉 systemd 在系统以多用户模式运行时激活这个 unit，这是 Unix 服务器在运行时的正常模式。如果你想了解更多关于多用户模式的细节，请参阅关于 Unix runlevels 的讨论。 unit 配置文件添加到 /etc/systemd/system 目录中，供 systemd 查看。每次添加或修改单元文件时，必须告诉 systemd 刷新其配置:1$ sudo systemctl daemon-reload 然后，您可以使用 systemctl &lt;action&gt; &lt;service-name&gt; 命令启动、停止、重新启动或获得服务状态:1234$ sudo systemctl start &lt;service-name&gt;$ sudo systemctl stop &lt;service-name&gt;$ sudo systemctl restart &lt;service-name&gt;$ sudo systemctl status &lt;service-name&gt; 注意: 可以使用 service 命令来管理服务，而不是使用 systemctl。在大多数发行版中，service 命令映射到 systemctl 并给出相同的结果。 为 Flask 应用程序编写系统配置文件如果你想为你自己的应用程序创建一个 systemd 服务文件，只需要使用上面的模板并填写 Description, User, WorkingDirectory 和 ExecStart 即可。 作为一个例子，假设我想在 Linux 服务器上部署 Flask Mega-Tutorial 中提到的 microblog 应用程序，但是我想使用 systemd 来监视这个 process，而不是使用 supervisord。 作为你的参考，这里是我在教程中使用的 supervisord 配置文件:12345678[program:microblog]command=/home/ubuntu/microblog/venv/bin/gunicorn -b localhost:8000 -w 4 microblog:appdirectory=/home/ubuntu/microbloguser=ubuntuautostart=trueautorestart=truestopasgroup=truekillasgroup=true systemd的等效单元配置文件将写入/etc/systemd/system/microblog.service中，并将具有以下内容：123456789101112[Unit]Description=Microblog web applicationAfter=network.target[Service]User=ubuntuWorkingDirectory=/home/ubuntu/microblogExecStart=/home/ubuntu/microblog/venv/bin/gunicorn -b localhost:8000 -w 4 microblog:appRestart=always[Install]WantedBy=multi-user.target 请注意，启动命令如何到达虚拟环境内部以获取可执行 gunicorn 。 这等效于激活虚拟环境，然后在没有路径的情况下运行 gunicorn，但是这样做的好处是可以在单个命令中完成。 将这个文件添加到你的系统后，你可以使用以下命令启动服务:12$ sudo systemctl daemon-reload$ sudo systemctl start microblog 环境变量如果 Flask 应用程序希望提前设置一个或多个环境变量，那么可以将它们添加到服务文件中。例如，如果需要设置 FLASK_CONFIG 和 DATABASE_URL 变量，可以使用 Environment 选项定义它们如下:1234567891011121314[Unit]Description=Microblog web applicationAfter=network.target[Service]User=ubuntuWorkingDirectory=/home/ubuntu/microblogEnvironment=FLASK_CONFIG=productionEnvironment=DATABASE_URL=sqlite:////path/to/the/database.sqliteExecStart=/home/ubuntu/microblog/venv/bin/gunicorn -b localhost:8000 -w 4 microblog:appRestart=always[Install]WantedBy=multi-user.target 请注意，如果你遵循我的教程风格，并为环境变量使用.env文件，则无需通过 systemd 服务文件添加它们。 实际上，我更喜欢通过.env文件处理环境，因为这是一种适用于开发和生产的统一方法。 访问日志Systemd 有一个称为 journal 的日志记录子系统，由 journald 守护进程实现，它收集所有正在运行的 Systemd 单元的日志。可以使用 journalctl 实用工具查看日记的内容。下面是一些常见日志访问命令的示例。 查看 microblog 服务的日志:1$ journalctl -u microblog 查看 microblog 服务的最后25个日志条目:1$ journalctl -u microblog -n 25 跟踪 microblog 服务的日志:1$ journalctl -u microblog -f 还有更多的选项可用。运行 journalctl --help 查看更完整的选项摘要。 高级用法: 使用 Systemd 的运行 Worker Pools如果你使用 Celery 运行后台进程，则将上述解决方案扩展到适用于你的 workers 是很简单，因为 Celery允许你使用单个命令启动 worker 进程池。 这实际上与处理带有多个 worker 的gunicorn的方式相同，因此您要做的就是创建第二个.service文件来管理 Celery 主进程，该文件又将管理 worker。 但是，如果你读到了我的 Flask Mega-Tutorial 的最后几章，你就会知道我已经引入了一个基于RQ的任务队列来执行后台任务。 使用RQ时，您必须单独启动 workers，没有主流程可以为你管理 workers pool。 这是我在教程中使用supervisor 管理 RQ workers 的方法：123456789[program:microblog-tasks]command=/home/ubuntu/microblog/venv/bin/rq worker microblog-tasksnumprocs=1directory=/home/ubuntu/microbloguser=ubuntuautostart=trueautorestart=truestopasgroup=truekillasgroup=true 在这里，numprocs 参数使你可以根据需要启动任意数量的 worker。 通过此参数，supervisor 将从单个配置文件启动并监视指定数量的实例。 不幸的是，在 systemd 中没有 numprocs 选项，因此这种类型的服务需要不同的解决方案。 最简单的方法是为每个工作实例创建一个单独的服务文件，但是这样做会很麻烦。 相反，我要做的是将服务文件创建为模板，可用于启动所有这些相同的实例：123456789101112[Unit]Description=Microblog task worker %IAfter=network.target[Service]User=ubuntuWorkingDirectory=/home/ubuntu/microblogExecStart=/home/ubuntu/microblog/venv/bin/rq worker microblog-tasksRestart=always[Install]WantedBy=multi-user.target 你可能在此文件中注意到的奇怪的事情是，我在服务描述中添加了 %I。这是服务参数，一个要传递给每个实例的数字。在描述中包含这个 %I 将帮助我识别实例，因为来自 systemd 命令的所有输出都将替换为实例号。对于这种特定的情况，我实际上并不需要使用此参数，但是在其他字段中包含 %I 是很常见的，比如必要时使用 start 命令。 与常规服务文件的另一个区别是，我将使用 /etc/systemd/system/microblog-tasks@.service 这个名称来编写此服务文件。 文件名中的@表示这是一个模板，因此在它后面将有一个参数来标识从中衍生出的每个实例。 我将使用实例编号作为参数，因此该服务的不同实例将在 systemd 中被称为 microblog-tasks@1, microblog-tasks@2 等。 现在，我可以在bash中使用大括号扩展来启动四个 worker：123$ sudo systemctl daemon-reload$ sudo systemctl start microblog-tasks@&#123;1..4&#125;$ sudo systemctl status microblog-tasks@&#123;1..4&#125; 如果你想单独处理一个实例，你也可以这样做:1$ sudo systemctl restart microblog-tasks@3 这几乎和单个 supervisord 配置一样方便，但是有一个缺点，当你想对所有工作程序执行操作时，必须在命令中包括 {1..4} 范围。 要将整个 worker pool 真正视为一个实体，我可以创建一个新的systemd target，这是另一种类型的 unit。 然后，我可以将所有实例映射到该目标，当我要对组的所有成员执行操作时，这将允许我引用该目标。 让我们从新目标的 unit 配置文件开始，我将其命名为 /etc/systemd/system/microblog-tasks.target：12345[Unit]Description=Microblog RQ worker pool[Install]WantedBy=multi-user.target 除了描述之外，唯一需要的定义是对 multi-user.target 的依赖，就像你记得的那样，multi-user.target 是定义上上述所有单元文件的目标。 现在，我可以更新服务文件模板以引用新目标，由于对原始 multi-user.target 的可传递引用，最终等同于新目标。123456789101112[Unit]Description=Microblog task worker %IAfter=network.target[Service]User=ubuntuWorkingDirectory=/home/ubuntu/microblogExecStart=/home/ubuntu/microblog/venv/bin/rq worker microblog-tasksRestart=always[Install]WantedBy=microblog-tasks.target 现在系统可以使用以下命令重新配置，使用新的设置:123$ sudo systemctl daemon-reload$ sudo systemctl disable microblog-tasks@&#123;1..4&#125;$ sudo systemctl enable microblog-tasks@&#123;1..4&#125; 必须使用 disable 和 enable 命令，以强制 systemd 为 worker 任务删除旧目标并应用新目标。 现在 woker pool 可以使用 target 来处理：1$ sudo systemctl restart microblog-tasks.target 如果之后你决定增加第5个 worker，你可以这样做:12$ sudo systemctl enable microblog-tasks@5$ sudo systemctl start microblog-tasks.target 当然，你也可以减少 worker。下面是如何减少 worker 4 和 5:12$ sudo systemctl stop microblog-tasks@&#123;4..5&#125;$ sudo systemctl disable microblog-tasks@&#123;4..5&#125; 在这一点上，我认为这个解决方案在方便性和功能性方面超过了 supervisor 的 numprocs 命令，因为我不仅可以控制整个 worker 进程，而且可以添加和删除 worker，而不必编辑任何配置文件！ 翻译Running a Flask Application as a Service with Systemd]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB 单机多实例]]></title>
    <url>%2F2019%2F10%2F21%2FMariaDB%20%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%AE%9E%E4%BE%8B.html</url>
    <content type="text"><![CDATA[安装mariadb1# yum install mariadb-server -y 创建对应的目录文件12# mkdir -p /mariadb/data&#123;3306,3307,3308&#125;# chown -R mysql:mysql /mariadb 初始化数据库文件123# mysql_install_db --datadir=/mariadb/data3306 --user=mysql# mysql_install_db --datadir=/mariadb/data3307 --user=mysql# mysql_install_db --datadir=/mariadb/data3308 --user=mysql 可能会报如下的错误 123456Neither host 'galera-57561c9a' nor 'localhost' could be looked up with'/usr/libexec/resolveip'Please configure the 'hostname' command to return a correcthostname.If you want to solve this at a later stage, restart this scriptwith the --force option 如果出现如上的错误，就按提示上加上 –force 选项123# mysql_install_db --datadir=/mariadb/data3306 --user=mysql --force# mysql_install_db --datadir=/mariadb/data3307 --user=mysql --force# mysql_install_db --datadir=/mariadb/data3308 --user=mysql --force 手动启动流程创建对应配置文件1234567[mysqld]port=3306socket=/tmp/mysql3306.sockpid-file=/tmp/mysql3306.piddatadir=/mariadb/data3306[mysqld_safe]log-error=/mysql/3306/log/mariadb.logpid-file=/mysql/3306/pid/mariadb.pid mysqld_safe 方式启动配置文件 1234567# vi /etc/my.cnf.d/3306.cnf[mysqld]port=3306socket=/tmp/mysql3306.sockpid-file=/tmp/mysql3306.piddatadir=/mariadb/data3306log-error=/var/log/mariadb/3306.log 1234567# vi /etc/my.cnf.d/3307.cnf[mysqld]port=3307socket=/tmp/mysql3307.sockpid-file=/tmp/mysql3307.piddatadir=/mariadb/data3307log-error=/var/log/mariadb/3307.log 1234567# vi /etc/my.cnf.d/3308.cnf[mysqld]port=3308socket=/tmp/mysql3308.sockpid-file=/tmp/mysql3308.piddatadir=/mariadb/data3308log-error=/var/log/mariadb/3308.log mysqld_safe 启动 123# mysqld_safe --defaults-file=/etc/my.cnf.d/3306.cnf# mysqld_safe --defaults-file=/etc/my.cnf.d/3307.cnf# mysqld_safe --defaults-file=/etc/my.cnf.d/3308.cnf 通过脚本启动 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash#chkconfig: 345 80 2port=3306mysql_user="root"mysql_pwd=""cmd_path="/usr/bin"defaults-file="/etc/my.cnf.d/3306.cnf"mysql_sock="/tmp/mysql3306.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting MySQL...\n" $&#123;cmd_path&#125;/mysqld_safe --defaults-file=$&#123;defaults-file&#125; &amp;&gt; /dev/null &amp; else printf "MySQL is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "MySQL is stopped...\n" exit else printf "Stoping MySQL...\n" $&#123;cmd_path&#125;/mysqladmin -u $&#123;mysql_user&#125; -p$&#123;mysql_pwd&#125; -S $&#123;mysql_sock&#125; shutdown fi&#125;function_restart_mysql()&#123; printf "Restarting MySQL...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf "Usage: ./mysqld3306 &#123;start|stop|restart&#125;\n" mysqld_multi配置文件1234567891011121314151617181920212223242526# cp -a /etc/my.cnf /etc/my.cnf.bak# vi /etc/my.cnf # 添加如下代码,里面没有列出来的值都是保持默认的值[mysqld_multi]mysqld = /usr/bin/mysqld_safeuser = mysql[mysqld3306]port=3306socket=/tmp/mysql3306.sockpid-file=/tmp/mysql3306.piddatadir=/mariadb/data3306log-error=/var/log/mariadb/3306.log[mysqld3307]port=3307socket=/tmp/mysql3307.sockpid-file=/tmp/mysql3307.piddatadir=/mariadb/data3307log-error=/var/log/mariadb/3307.log[mysqld3308]port=3308socket=/tmp/mysql3308.sockpid-file=/tmp/mysql3308.piddatadir=/mariadb/data3308log-error=/var/log/mariadb/3308.log 启动实例注：[mysqld3306]，[mysqld3307]，[mysqld3308] 分别对应3306，3307,3308 123# mysqld_multi --defaults-extra-file=/etc/my.cnf start 3306# mysqld_multi --defaults-extra-file=/etc/my.cnf start 3307# mysqld_multi --defaults-extra-file=/etc/my.cnf start 3308 查看启动的实例1# mysqld_multi --defaults-extra-file=/etc/my.cnf report 客户端登录通过TCP/IP连接1# mysql -P3306 -hlocalhost --protocol=tcp 通过连接实例的方式（只能本地连接，不能用于远程连接）1# mysql -S /tmp/mysql3307.sock 停止实例123# mysqladmin -u root -p -S /tmp/mysql3306.sock shutdown# mysqladmin -u root -p -S /tmp/mysql3307.sock shutdown# mysqladmin -u root -p -S /tmp/mysql3308.sock shutdown 修改密码123# mysqladmin --no-defaults --port=3306 --user=root --protocol=tcp password '123456'# mysqladmin --no-defaults --port=3307--user=root --protocol=tcp password '123456'# mysqladmin --no-defaults --port=3308 --user=root --protocol=tcp password '123456' 另一种方式 123# systemctl restart mariadb --skip-grant-tables --skip-networking# mysql -e"UPDATE mysql.user SET password=password('somenewpassword') WHERE user='root'"# systemctl restart mariadb]]></content>
      <categories>
        <category>MariaDB</category>
      </categories>
      <tags>
        <tag>MariaDB</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负载均衡和高可用的区别]]></title>
    <url>%2F2019%2F10%2F01%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E5%8C%BA%E5%88%AB.html</url>
    <content type="text"><![CDATA[有些客户都会在询问的时候负载均衡和高可用，对于这二者的概念很混淆，下面TCloud带大家来区分下二者的区别。 负载均衡：就是对负载或流量分摊，不至于把一台机器超载导致服务终断或不可用，多台机器经常组成一个集群，来处理所有的并发量或负载等而不是单单的一台机器，相关软件：haproxy，lvs，nginx，这些软件提供对集群的管理，是集群的大门。 高可用性：一个集群（负载均衡集群），一般都有一个公共ip或域名等对外提供服务，通过这个ip或域名等，就可以访问这个集群，因为这个域名或ip或相关的服务出问题了，那么就会出现整个集群不能对外提供服务，高可用性就是为了解决单点故障的问题，当集群中的主节点出问题后，次节点就会接管，这样的话保证了集群的高可用性，次节点通常是主节点的镜像，相关软件：keepalived，heartbeat.可以说高可用性解决了负载均衡出现单一管理节点出问题后整个集群不能对外提供服务的问题。 原文链接]]></content>
      <categories>
        <category>负载均衡</category>
      </categories>
      <tags>
        <tag>高可用</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Virtual IP 的实现原理]]></title>
    <url>%2F2019%2F09%2F21%2FVirtual%20IP%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html</url>
    <content type="text"><![CDATA[什么是VIP？VIP即Virtual IP Address，是实现HA（高可用）系统的一种方案，高可用的目的是通过技术手段避免因为系统出现故障而导致停止对外服务，一般实现方式是部署备用服务器，在主服务器出现故障时接管业务。 VIP用于向客户端提供一个固定的“虚拟”访问地址，以避免后端服务器发生切换时对客户端的影响。 例如在下图的系统中，采用了三个服务器的集群来实现服务的高可用，后端服务器集群通过VIP 193.168.0.6对外提供服务，客户端只知道VIP，并不关注后端服务器的真实地址。 VIP被加载在Master的网卡上，所有指向VIP的请求会被发向Master，Slave服务器出于Standby状态。如果Master出现故障，集群会通过选举算法从可用的Slave节点中选出一个新的Master节点，并将VIP也迁移到新Master节点的网卡上。这样可以保证服务始终可用，并且对客户端来说访问的IP也不会变化。 注意VIP始终指向一个Master，因此VIP的方案并不能实现LB，只能实现HA。 1234567891011121314151617181920______________________| || VIP: 193.168.0.6 ||-----| Host IP: 193.168.0.2 || | Role: Master || |______________________||| ______________________| | || | VIP: Unassigned |Public ----(example.com = 193.168.0.6)--|-----| Host IP: 193.168.0.3 || | Role: Slave || |______________________||| ______________________| | || | VIP: Unassigned ||-----| Host IP: 193.168.0.4 || Role: Slave ||______________________| VIP的实现原理 Master选举： 集群创建或者Master出现故障时，集群通过选举协议得到一个Master作为对外服务的节点 配置VIP： HA软件将VIP配置到Master节点的网卡上 ARP广播： 主动对外广播ARP消息，声明VIP对应的MAC地址为Master的网卡MAC地址 通过arp -a 命令查看193.168.0.6对应的MAC地址和193.168.0.2相同 123arp -a|grep 193.168.0? (193.168.0.6) at fa:16:3e:2a:7e:d4 [ether] on br-apidefault? (193.168.0.2) at fa:16:3e:2a:7e:d4 [ether] on br-apidefault 登录到193.168.0.2主机上，使用ip addr命令可以看到网卡上绑定了VIP 193.168.0.6 1234567ip addr10: br-apidefault: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default qlen 1000link/ether fa:16:3e:2a:7e:d4 brd ff:ff:ff:ff:ff:ffinet 193.168.0.3/16 brd 193.168.255.255 scope global br-apidefaultvalid_lft forever preferred_lft foreverinet 193.168.0.6/16 brd 193.168.255.255 scope global secondary br-apidefaultvalid_lft forever preferred_lft forever 采用Keepalived实现VIPKeepalived的设计目的即是为了管理VIP，因此使用Keepalived实现VIP的配置非常简单。Keepalived采用了Virtual Router Redundancy Protocol (VRRP)协议来进行实现主备服务器之间的通信以及选举。 下面介绍如何采用Keepalived配置一个两节点的HA集群。 首先将用于设置VIP的脚本放到主备两个服务器的 /etc/keepalived/notify.sh 路径下 1234567#!/bin/bashvipAddress="192.168.121.100/24"if [[ "x$1" == "xmaster" ]]; thenip address add dev eth1 $&#123;vipAddress&#125;elseip address del dev eth1 $&#123;vipAddress&#125;fi Master节点的Keepalived配置文件 keepalived.conf 1234567891011121314151617vrrp_instance VI_1 &#123;state MASTERinterface eth0garp_master_delay 10smtp_alertvirtual_router_id 51priority 100vrrp_unicast_bind 192.168.121.51vrrp_unicast_peer 192.168.121.52advert_int 1authentication &#123;auth_type PASSauth_pass testpass&#125;notify_master "/etc/keepalived/notify.sh master"notify_backup "/etc/keepalived/notify.sh backup"&#125; Backup节点的Keepalived配置文件 keepalived.conf 1234567891011121314151617vrrp_instance VI_1 &#123;state BACKUPinterface eth0garp_master_delay 10smtp_alertvirtual_router_id 51priority 50vrrp_unicast_bind 192.168.121.52vrrp_unicast_peer 192.168.121.51advert_int 1authentication &#123;auth_type PASSauth_pass testpass&#125;notify_master &quot;/etc/keepalived/notify.sh master&quot;notify_backup &quot;/etc/keepalived/notify.sh backup&quot;&#125; 采用pacemaker实现VIPPacemaker和Keepalived的定位不同，Keepalived一般用于无状态，可以Active-Active的HA集群；而Pacemaker可以实现有状态，Active-Passive的HA集群。例如采用pacemaker可以将服务状态和数据从出现故障的服务器上迁移到备份机上，例如拷贝配置文件，加载数据库等。因此Pacemaker的内部结构和配置比Keepalived的更复杂。 Packemaker包括下列组件： Cluster Information Base (CIB) 集群信息库：使用XML保存了集群内部的配置和当前状态，CIB保存的内容在集群内保持同步。 Policy Engine (PEngine or PE)：策略引擎：当集群中有节点宕机导致资源当前状态和理想状态不一致时，策略引擎使用CIB中的信息计算需要执行哪些动作使集群达到应处于的理想状态。 Cluster Resource Management daemon (CRMd)：集群资源管理守护进程：集群选举一个CRMd为Master，由Master通过集群消息系统将策略引擎的指令发向本地的LRMd或者集群中的其他CRMd执行。 Local Resource Management daemon (LRMd)：本地资源管理守护进程 Fencing daemon (STONITHd): 爆头守护进程： Shoot the other node in the head,在某些情况下，可能有必要关闭节点，以保护共享数据或完整的资源回收。为此，Pacemaker配备了stonithd设备。STONITH可以将其它节点“爆头”，通常是实现与远程电源开关。 cluster abstraction layer下面为集群的底层消息系统。 采用Pacemaker实现VIP的原理和Keepalived基本相同，也是采用将VIP作为Secondary IP绑定到Master网卡的方式，具体设置步骤略。 参考 VIP Management With keepalived Virtual Router Redundancy Protocol (VRRP)]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx + httpd负载均衡和缓存]]></title>
    <url>%2F2019%2F09%2F18%2Fnginx%20%2B%20httpd%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E7%BC%93%E5%AD%98.html</url>
    <content type="text"><![CDATA[实验环境1234操作系统：centos7.5httpd服务器1: 10.0.0.101httpd服务器2: 10.0.0.102nginx服务器: 192.168.46.103 安装并启动httpd 在需要部署httpd 的节点上安装 httpd 1# yum install httpd -y 设置httpd首页显示信息，这里设置显示服务器 ip 地址，方便我们判断访问的是哪台服务器 http 服务器1 1# echo "10.0.0.101" &gt;/var/www/html/index.html http 服务器2 1# echo "10.0.0.102" &gt;/var/www/html/index.html 关闭所有节点的防火墙 12# systemctl stop firewalld# systemctl disable firewalld 启动所有节点的 httpd 服务，并确定可以通过浏览器访问所有节点的 http 服务器 12# systemctl start httpd# systemctl enable httpd http 服务器1 http 服务器2 Nginx 实现 httpd 负载均衡 安装 nginx 12# yum -y install epel-release #默认Centos7没有nginx源，需要安装epel的yum源# yum install -y nginx 配置 nginx 实现httpd 的负载均衡 默认的配置文件为 1/etc/nginx/nginx.conf 我们可以改默认的配置文件，也可以在/etc/nginx/conf.d/ 新增配置文件，默认配置会include /etc/nginx/conf.d/ 目录下的配置 在/etc/nginx/conf.d/ 目录下新建webservers.conf 文件，配置如下： 12345678910111213# 负载均衡upstream webservers &#123; server 10.0.0.101; # httpd 服务器1 server 10.0.0.102; # httpd 服务器2&#125;server &#123; listen 80; server_name upstream.geekspeng.com; # 域名 location / &#123; proxy_pass http://webservers; # 反向代理 proxy_set_header X-Real-IP $remote_addr; &#125;&#125; 测试配置是否正确并启动 nginx 12345[root@node3 nginx]# nginx -t # 测试配置是否正确nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@node3 ~]# systemctl start nginx[root@node3 ~]# systemctl enable nginx 访问http://upstream.geekspeng.com/ 由于nginx 默认配置文件默认配置80 端口指向nginx 测试页面（如下图），所以这里我们配置通过域名 upstream.geekspeng.com 访问 nginx服务器（可以通过配置不同的域名指向不同的应用程序） 为了能通过域名访问 nginx服务器，我们需要在 hosts 文件追加添加一条记录 win7 的host 文件在 C:\Windows\System32\drivers\etc\hosts 110.0.0.103 upstream.geekspeng.com 通过域名访问，此时请求会交替的转发给httpd 服务器 Nginx 实现服务器静态缓存 配置 nginx 实现缓存 在/etc/nginx/conf.d/ 目录下新建cache.conf 文件，配置如下： 1234567891011proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=cache_zone:10m inactive=1d max_size=100m;server &#123;listen 80;server_name cache.geekspeng.com; # 域名 location / &#123; proxy_cache cache_zone; #keys_zone的名字 proxy_cache_key $host$uri$is_args$args; #缓存规则 proxy_cache_valid any 1m; proxy_pass http://10.0.0.101; &#125;&#125; 首先需要在http中加入proxy_cache_path，用来制定缓存的目录以及缓存目录深度制定等。它的格式如下： 1proxy_cache_path path [levels=number] keys_zone=zone_name:zone_size [inactive=time] [max_size=size]; path是用来指定缓存在磁盘的路径地址。比如：/data/nginx/cache。那以后生存的缓存文件就会存在这个目录下。levels用来指定缓存文件夹的级数，可以是：levels=1, levels=1:1, levels=1:2, levels=1:2:3 可以使用任意的1位或2位数字作为目录结构分割符，如 X, X:X,或 X:X:X 例如: 2, 2:2, 1:1:2，但是最多只能是三级目录。 那这个里面的数字是什么意思呢。表示取hash值的个数。比如： 现在根据请求地址localhost/index.php?a=4用md5进行哈希，得到e0bd86606797639426a92306b1b98ad9levels=1:2 表示建立2级目录，把hash最后1位(9)拿出建一个目录，然后再把9前面的2位(ad)拿来建一个目录, 那么缓存文件的路径就是/data/nginx/cache/9/ad/e0bd86606797639426a92306b1b98ad9以此类推：levels=1:1:2表示建立3级目录，把hash最后1位(9)拿出建一个目录，然后再把9前面的1位(d)建一个目录, 最后把d前面的2位(8a)拿出来建一个目录 那么缓存文件的路径就是/data/nginx/cache/9/d/8a/e0bd86606797639426a92306b1b98ad9 keys_zone 所有活动的key和元数据存储在共享的内存池中，这个区域用keys_zone参数指定。zone_name指的是共享池的名称， zone_size指的是共享池的大小。注意每一个定义的内存池必须是不重复的路径，例如： 123proxy_cache_path /data/nginx/cache/one levels=1 keys_zone=one:10m;proxy_cache_path /data/nginx/cache/two levels=2 keys_zone=two:100m;proxy_cache_path /data/nginx/cache/three levels=1 keys_zone=three:10m; inactive 表示指定的时间内缓存的数据没有被请求则被删除，默认inactive为10分钟。inactive=1d 1小时。inactive=30m 30分钟。max_size 表示单个文件最大不超过的大小。它被用来删除不活动的缓存和控制缓存大小，当目前缓存的值超出max_size指定的值之后， 超过其大小后最少使用数据（LRU替换算法）将被删除。max_size=10g表示当缓存池超过10g就会清除不常用的缓存文件。clean_time 表示每间隔自动清除的时间。clean_time=1m 1分钟清除一次缓存。 说完了这个很重要的参数。我们再来说在server模块里的几个配置参数： proxy_cache用来指定用哪个keys_zone的名字，也就是用哪个目录下的缓存。 上面我们指定了三个one,two,three。比如，我现在想用one这个缓存目录: proxy_cache oneproxy_cache_key 这个其实蛮重要的，它用来指定生成hash的url地址的格式。根据这个key映射成一个hash值， 然后存入到本地文件。proxy_cache_key $host$uri表示无论后面跟的什么参数，都会访问一个文件，不会再生成新的文件。 而如果proxy_cache_key $is_args$args，那么传入的参数localhost/index.php?a=4与localhost/index.php?a=44将映射成两个不同hash值的文件。proxy_cache_key 默认是 “$scheme$host$request_uri”。但是一般我们会把它设置成：$host$uri$is_args$args一个完整的url路径。proxy_cache_valid 它是用来为不同的http响应状态码设置不同的缓存时间。123proxy_cache_valid 200 302 10m;proxy_cache_valid 301 1h;proxy_cache_valid any 1h; #所有的状态都缓存1小时 表示为http status code 为200和302的设置缓存时间为10分钟，404代码缓存1分钟。 测试配置是否正确并重新加载 nginx 123[root@node3 nginx]# nginx -t # 测试配置是否正确nginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@node3 ~]# systemctl reload nginx 访问http://cache.geekspeng.com/ 为了能通过域名访问 nginx服务器，我们需要在 hosts 文件追加添加一条记录 win7 的host 文件在 C:\Windows\System32\drivers\etc\hosts 110.0.0.103 cache.geekspeng.com 查看 nginx 缓存目录 12345[root@node3 ~]# tree /var/cache/nginx//var/cache/nginx/└── 5 └── a7 └── 2b21765c7b4c13abf90a75280fd43a752 directories, 1 file 查看缓存文件内容 1234567891011[root@node3 ~]# cat /var/cache/nginx/5/a7/2b21765c7b4c13abf90a75280fd43a75`kn"b-5846a255896c3"KEY: cache.geekspeng.com/HTTP/1.1 200 OKDate: Wed, 20 Mar 2019 08:41:53 GMTServer: Apache/2.4.6 (CentOS)Last-Modified: Tue, 19 Mar 2019 03:31:51 GMTETag: "b-5846a255896c3"Accept-Ranges: bytesContent-Length: 11Connection: closeContent-Type: text/html; charset=UTF-810.0.0.101 刷新网页，再次访问查看浏览器 和 httpd 服务器情况 打开Chrome开发者工具，并且切换到Network，刷新页面 在 Response Headers 中我们可以看到： 12X-Cache: HITX-Via: 10.0.0.103 MISS 未命中，请求被传送到后端HIT 缓存命中EXPIRED 缓存已经过期请求被传送到后端UPDATING 正在更新缓存，将使用旧的应答STALE 后端将得到过期的应答BYPASS 缓存被绕过了 查看httpd 服务器1 的访问日志，如果缓存没有过期，此时不会新增访问日志 1[root@node1 ~]# tailf /var/log/httpd/access_log tailf /var/log/httpd/access_log 更新httpd 服务器1 的内容后，再次访问查看浏览器 和 httpd 服务器情况 更新 httpd 服务器1 的内容 1[root@node1 ~]# echo "10.0.0.101 \n 10.0.0.101" &gt;/var/www/html/index.html 打开Chrome开发者工具，并且切换到Network，刷新页面 在 Response Headers 中我们可以看到 cache 已经过期： 12X-Cache: EXPIREDX-Via: 10.0.0.103 查看httpd 服务器1 的访问日志，此时会看到访问信息 12[root@node1 ~]# tailf /var/log/httpd/access_log tailf /var/log/httpd/access_log10.0.0.103 - - [20/Mar/2019:04:51:46 -0400] "GET / HTTP/1.0" 200 14 "-" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36" 查看缓存文件内容，此时缓存已经更新 12345678910111213[root@node3 ~]# cat /var/cache/nginx/5/a7/2b21765c7b4c13abf90a75280fd43a75`ko"ֽ19-58482a752aad1"KEY: cache.geekspeng.com/HTTP/1.1 200 OKDate: Wed, 20 Mar 2019 08:46:13 GMTServer: Apache/2.4.6 (CentOS)Last-Modified: Wed, 20 Mar 2019 08:46:11 GMTETag: "19-58482a752aad1"Accept-Ranges: bytesContent-Length: 25Connection: closeContent-Type: text/html; charset=UTF-810.0.0.101 \n 10.0.0.101 Nginx 实现浏览器静态缓存123456# 静态文件，nginx自己处理location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /var/www/virtual/htdocs; expires 30d; # 过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点&#125; 反向代理示例123456789101112## 下面配置反向代理的参数server &#123; listen 80; ## 1. 用户访问 http://ip:port，则反向代理到 https://github.com location / &#123; proxy_pass https://github.com; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 遗留问题 动态缓存 缓存更新策略]]></content>
      <categories>
        <category>负载均衡</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived + httpd 高可用集群]]></title>
    <url>%2F2019%2F09%2F12%2Fkeepalived%20%2B%20httpd%20%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4.html</url>
    <content type="text"><![CDATA[实验环境12345678操作系统：centos7.5keepalived MASTER: 192.168.46.133keepalived BACKUP1: 192.168.46.134keepalived BACKUP2: 192.168.46.135http 服务器1: 192.168.46.133 http 服务器2: 192.168.46.134http 服务器3: 192.168.46.135VIP: 192.168.46.100 注：keepalived 和 http 服务既可以放到同一个节点也可以放到不同的节点 安装 httpd 并启动服务 在所有节点上安装 httpd 1# yum install httpd -y 三台节点分别设置httpd首页显示信息，这里设置显示服务器 ip 地址，方便我们判断访问的是哪台服务器 http 服务器1 1# echo "192.168.46.133" &gt;/var/www/html/index.html http 服务器2 1# echo "192.168.46.134" &gt;/var/www/html/index.html http 服务器3 1# echo "192.168.46.135" &gt;/var/www/html/index.html 关闭所有节点的防火墙 12# systemctl stop firewalld# systemctl disable firewalld 启动所有节点的 httpd 服务，并确定可以通过浏览器访问所有节点的 http 服务器 12# systemctl start httpd# systemctl enable httpd http 服务器1 http 服务器2 http 服务器3 keepalived 实现 http 服务的高可用 在所有节点上安装 keepalived 1# yum install keepalived -y 配置 keepalived 实现 httpd 的高可用 MASTER 节点配置如下 12345678910111213141516# vim /etc/keepalived/keepalived.confvrrp_instance VI_1 &#123; state MASTER #指定该节点为主节点，备用节点设置为BACKUP interface ens33 #绑定虚拟IP的服务器的网卡 virtual_router_id 51 #虚拟路由编号，主备要一致 priority 50 #主节点的优先级，数值在1~254，注意从节点必须比主节点的优先级别低 advert_int 1 #组播信息发送间隔，主备要一致 #设置验证信息，主备要一致 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.46.100 #指定虚拟IP，主备要设置一样，可多设，每行一个 &#125; &#125; BACKUP 节点配置基本同 MASTER 节点一样，不同之处如下 12345# vim /etc/keepalived/keepalived.confstate BACKUPpriority 30 #其它配置跟keepalived主机相同 启动 keepalived 12# systemctl start keepalived# systemctl enable keepalived 在MASTER 节点查看是否生成 VIP 1234567891011121314# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:f9:43:90 brd ff:ff:ff:ff:ff:ff inet 192.168.46.133/24 brd 192.168.46.255 scope global dynamic ens33 valid_lft 1204sec preferred_lft 1204sec inet 192.168.46.100/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fef9:4390/64 scope link valid_lft forever preferred_lft forever可以看到网卡ens33 多了一个 192.168.46.100 的 IP 地址 测试keepalived 是否生效 通过 VIP 访问http 服务器，此时访问的是master 节点的http 服务器 关闭 master 节点的 keepalived 服务，再通过 VIP访问http服务器，此时访问的是keepalivedbackup节点的 http 服务器 keepalived master 节点 12345678910111213# systemctl stop keepalived.service# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:f9:43:90 brd ff:ff:ff:ff:ff:ff inet 192.168.46.133/24 brd 192.168.46.255 scope global dynamic ens33 valid_lft 1279sec preferred_lft 1279sec inet6 fe80::20c:29ff:fef9:4390/64 scope link valid_lft forever preferred_lft forever此时网卡ens33 已经没有 192.168.46.100 的 IP 地址 此时访问的是 keepalived backup2 节点上的 http 服务器，查看 keepalived backup2 节点查看是否生成 VIP 123456789101112131415# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:ea:c4:b2 brd ff:ff:ff:ff:ff:ff inet 192.168.46.135/24 brd 192.168.46.255 scope global noprefixroute dynamic ens33 valid_lft 1289sec preferred_lft 1289sec inet 192.168.46.100/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::96ad:543:7d7d:2ea1/64 scope link noprefixroute valid_lft forever preferred_lft forever 可以看到网卡ens33 多了一个 192.168.46.100 的 IP 地址 启动 master 节点的 keepalived 服务，通过 VIP访问http服务器，查看VIP 是否恢复到 master keepalived master 节点 1234567891011121314# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:f9:43:90 brd ff:ff:ff:ff:ff:ff inet 192.168.46.133/24 brd 192.168.46.255 scope global dynamic ens33 valid_lft 1452sec preferred_lft 1452sec inet 192.168.46.100/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fef9:4390/64 scope link valid_lft forever preferred_lft forever keepalived backup2 节点 123456789101112# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:ea:c4:b2 brd ff:ff:ff:ff:ff:ff inet 192.168.46.135/24 brd 192.168.46.255 scope global noprefixroute dynamic ens33 valid_lft 1745sec preferred_lft 1745sec inet6 fe80::96ad:543:7d7d:2ea1/64 scope link noprefixroute valid_lft forever preferred_lft forever 测试结果说明，当keepalived backup 节点在keepalived master 节点宕机的情况会自动接管了资源。但待keepalived主机恢复正常的时候，主机会重新接管资源 存在的问题，如果只是 master 节点 的 http 服务挂了，但是keepalived 正常运行，此时backup 节点并不会接管 master 节点的工作，导致 http 服务不可用，所以需要keepalived 定时检测 http是否可用，如果不可用可以考虑恢复 master 节点的 http 服务或者关闭 master 节点的 keepalived 服务（此时backup 节点并接管 master 节点的工作） keepalived 负载均衡配置LVS的IP负载均衡技术是通过IPVS模块实现的。IPVS模块是LVS集群的核心软件模块，它安装在LVS集群作为负载均衡的主节点上，虚拟出一个IP地址和端口对外提供服务。用户通过访问这个虚拟服务（VS），然后访问请求由负载均衡器（LB）调度到后端真实服务器（RS）中，由RS实际处理用户的请求给返回响应。 修改所有节点的 keepalived 配置文件，添加以下内容 12345678910111213141516171819202122232425262728293031323334353637#虚拟IP服务virtual_server 192.168.46.100 80 &#123; delay_loop 6 #设置检查间隔 lb_algo rr #设置LVS调度算法, rr|wrr|lc|wlc|lblc 等调度算法 lb_kind DR #设置LVS实现负载的机制，有NAT、TUN、DR三个模式 nat_mask 255.255.255.0 persistence_timeout 50 #持久连接设置，会话保持时间 protocol TCP #转发协议为TCP #后端实际TCP服务配置 real_server 192.168.46.133 80 &#123; # 指定real server1的IP地址 weight 3 # 配置节点权值，数字越大权重越高 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.46.134 80 &#123; # 指定real server1的IP地址 weight 3 # 配置节点权值，数字越大权重越高 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.46.135 80 &#123; # 指定real server1的IP地址 weight 3 # 配置节点权值，数字越大权重越高 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; IPVS的三种转发模式需要进行的操作 DR模式（Direct Routing） DR模式下，客户端的请求包到达负载均衡器的虚拟服务IP端口后，负载均衡器不会改写请求包的IP和端口，但是会改写请求包的MAC地址为后端RS的MAC地址，然后将数据包转发；真实服务器处理请求后，响应包直接回给客户端，不再经过负载均衡器。所以DR模式的转发效率是最高的，特别适合下行流量较大的业务场景，比如请求视频等大文件。 DR模式的特点 数据包在LB转发过程中，源/目的IP端口都不会变化 LB只是将数据包的MAC地址改写为RS的MAC地址，然后转发给相应的RS。 每台RS上都必须在环回网卡上绑定LB的虚拟服务IP 因为LB转发时并不会改写数据包的目的IP，所以RS收到的数据包的目的IP仍是LB的虚拟服务IP。为了保证RS能够正确处理该数据包，而不是丢弃，必须在RS的环回网卡上绑定LB的虚拟服务IP。这样RS会认为这个虚拟服务IP是自己的IP，自己是能够处理这个数据包的。否则RS会直接丢弃该数据包！ RS上的业务进程必须监听在环回网卡的虚拟服务IP上，且端口必须和LB上的虚拟服务端口一致 因为LB不会改写数据包的目的端口，所以RS服务的监听端口必须和虚拟服务端口一致，否则RS会直接拒绝该数据包。 RS处理完请求后，响应直接回给客户端，不再经过LB因为RS 收到的请求数据包的源IP是客户端的IP，所以理所当然RS的响应会直接回给客户端，而不会再经过LB。这时候要求RS和客户端之间的网络是可达的。 LB和RS须位于同一个子网 因为LB在转发过程中需要改写数据包的MAC为RS的MAC地址，所以要能够查询到RS的MAC。而要获取到RS的MAC，则需要保证二者位于一个子网，否则LB只能获取到RS网关的MAC地址。 所有 real_server 的环回网卡上绑定LB的 virtual_server 的 ip 123456789101112131415161718192021222324252627# vim /etc/init.d/realserverVIP=192.168.46.100case "$1" instart) ifconfig lo:0 $VIP netmask 255.255.255.255 broadcast $VIP route add -host $VIP dev lo:0 echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce sysctl -p &gt;/dev/null 2&gt;&amp;1 echo "RealServer Start OK" ;;stop) ifconfig lo:0 down route del $VIP &gt;/dev/null 2&gt;&amp;1 echo "0" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo "0" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "0" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "0" &gt;/proc/sys/net/ipv4/conf/all/arp_announce echo "RealServer Stoped" ;;*) echo "Usage: $0 &#123;start|stop&#125;" exit 1esacexit 0 保存脚本文件后更改该文件权限，然后开启realserver服务 12# chmod 755 /etc/init.d/realserver# service realserver start NAT模式（Network Address Translation） NAT模式下，请求包和响应包都需要经过LB处理。当客户端的请求到达虚拟服务后，LB会对请求包做目的地址转换（DNAT），将请求包的目的IP改写为RS的IP。当收到RS的响应后，LB会对响应包做源地址转换（SNAT），将响应包的源IP改写为LB的IP。 NAT模式的特点 LB会修改数据包的地址 对于请求包，会进行DNAT；对于响应包，会进行SNAT。 LB会透传客户端IP到RS（DR模式也会透传） 虽然LB在转发过程中做了NAT转换，但是因为只是做了部分地址转发，所以RS收到的请求包里是能看到客户端IP的。 需要将RS的默认网关地址配置为LB的浮动IP地址 因为RS收到的请求包源IP是客户端的IP，为了保证响应包在返回时能走到LB上面，所以需要将RS的默认网关地址配置为LB的虚拟服务IP地址。当然，如果客户端的IP是固定的，也可以在RS上添加明细路由指向LB的虚拟服务IP，不用改默认网关。 LB和RS须位于同一个子网，并且客户端不能和LB/RS位于同一子网 因为需要将RS的默认网关配置为LB的虚拟服务IP地址，所以需要保证LB和RS位于同一子网。 又因为需要保证RS的响应包能走回到LB上，则客户端不能和RS位于同一子网。否则RS直接就能获取到客户端的MAC，响应包就直接回给客户端了，不会走网关，也就走不到LB上面了。这时候由于没有LB做SNAT，客户端收到的响应包源IP是RS的IP，而客户端的请求包目的IP是LB的虚拟服务IP，这时候客户端无法识别响应包，会直接丢弃。 FULLNAT模式 FULLNAT模式下，LB会对请求包和响应包都做SNAT+DNAT。 FULLNAT模式的特点 LB完全作为一个代理服务器 FULLNAT下，客户端感知不到RS，RS也感知不到客户端，它们都只能看到LB。此种模式和七层负载均衡有点相似，只不过不会去解析应用层协议，而是在TCP层将消息转发。 LB和RS对于组网结构没有要求 不同于NAT和DR要求LB和RS位于一个子网，FULLNAT对于组网结构没有要求。只需要保证客户端和LB、LB和RS之间网络互通即可。 三种转发模式性能从高到低：DR &gt; NAT &gt;FULLNAT 虽然FULLNAT模式的性能比不上DR和NAT，但是FULLNAT模式没有组网要求，允许LB和RS部署在不同的子网中，这给运维带来了便利。并且 FULLNAT模式具有更好的可拓展性，可以通过增加更多的LB节点，提升系统整体的负载均衡能力。 重启 keepalived 服务，并验证负载均衡是否生效 重启 keepalived 服务 1# service keepalived restart 验证负载均衡是否生效 此时访问的是 http 服务器3 关闭 http 服务器3上的 http 服务 1# service httpd stop 此时访问的是 http 服务器2 IPVS支持的调度算法对于后端的RS集群，LB是如何决策应该把消息调度到哪个RS节点呢？这是由负载均衡调度算法决定的。IPVS常用的调度算法有： 轮询（Round Robin） LB认为集群内每台RS都是相同的，会轮流进行调度分发。从数据统计上看，RR模式是调度最均衡的。 加权轮询（Weighted Round Robin） LB会根据RS上配置的权重，将消息按权重比分发到不同的RS上。可以给性能更好的RS节点配置更高的权重，提升集群整体的性能。 最小连接数（Least Connections） LB会根据和集群内每台RS的连接数统计情况，将消息调度到连接数最少的RS节点上。在长连接业务场景下，LC算法对于系统整体负载均衡的情况较好；但是在短连接业务场景下，由于连接会迅速释放，可能会导致消息每次都调度到同一个RS节点，造成严重的负载不均衡。 加权最小连接数（Weighted Least Connections） 最小连接数算法的加权版~ 地址哈希（Address Hash） LB上会保存一张哈希表，通过哈希映射将客户端和RS节点关联起来。]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 抢占IP的问题]]></title>
    <url>%2F2019%2F09%2F01%2Fkeepalived%20%E6%8A%A2%E5%8D%A0%20IP%20%E7%9A%84%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[在 master-&gt;backup 模式下，一旦主库宕掉， 虚拟IP会自动漂移到从库，当主库修复后，keepalived启动后，还会把虚拟IP抢过来，即使你设置nopreempt（不抢占）的方式抢占IP的动作也会发生 在 backup-&gt;backup 模式下，关闭 VIP抢占模式，当主库宕掉后虚拟IP会自动漂移到从库上，当原主恢复之后重启keepalived服务，并不会抢占新主的虚拟IP， 即使是优先级高于从库的优先级别，也不会抢占 IP 示例 节点1 1234567891011121314vrrp_instance VI_1 &#123; state BACKUP # 通过下面的priority来区分MASTER和BACKUP，也只有如此，底下的nopreempt才有效 interface eth0@if49 virtual_router_id 51 priority 100 advert_int 1 nopreempt #防止切换到从库后，主keepalived恢复后自动切换回主库 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.17.0.4/16 &#125;&#125; 节点2 1234567891011121314vrrp_instance VI_1 &#123; state BACKUP interface eth0@if51 virtual_router_id 51 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 172.17.0.4/16 &#125;&#125;]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过ARP协议实现VIP]]></title>
    <url>%2F2019%2F09%2F01%2F%E8%99%9A%E6%8B%9FIP%E6%8A%80%E6%9C%AF.html</url>
    <content type="text"><![CDATA[通过ARP协议实现VIPIP 地址只是一个逻辑地址，在以太网中MAC 地址才是真正用来进行数据传输的物理地址，每台主机中都有一个ARP 高速缓存，存储同一个网络内的IP 地址与MAC 地址的对应关系，以太网中的主机发送数据时会先从这个缓存中查询目标IP 对应的MAC 地址，会向这个MAC 地址发送数据。操作系统会自动维护这个缓存。这就是整个实现的关键 比如下面是机器A 上的 ARP 缓存 123(192.168.1.219) at 00:21:5A:DB:68:E8 [ether] on bond0(192.168.1.217) at 00:21:5A:DB:68:E8 [ether] on bond0(192.168.1.218) at 00:21:5A:DB:7F:C2 [ether] on bond0 192.168.1.217、192.168.1.218 是两台真实的电脑；192.168.1.217 为对外提供服务的主机；192.168.1.218 为热备的机器；192.168.1.219 为虚IP 注意此时219(VIP)、217 的MAC 地址是相同的 假如217 宕机了，218 检测到217 心跳挂了，于是启动切换。218 会进行ARP 广播，让VIP 对应的MAC 地址变成自己的MAC 地址。于是，机器A 上的ARP 缓存就变成这样了 123(192.168.1.219) at 00:21:5A:DB:7F:C2 [ether] on bond0(192.168.1.217) at 00:21:5A:DB:68:E8 [ether] on bond0(192.168.1.218) at 00:21:5A:DB:7F:C2 [ether] on bond0 注意现在219(VIP)、218 的MAC 地址是相同的了 不需要人手工修改机器A 的配置，即可实现自动切换的效果！ 这是一种简单的VIP 实现，通过MAC 的更改来实现切换。但也有一些局限性，因为实现于MAC 层，所以无法跨网段。也无法屏蔽掉后面的服务器的IP 地址 nginx 的IP 是要暴露到外网的，所以这种方案的VIP 可以吗？ 不过这种方案在内网做MySQL、Redis 的冗余还是可行的！ 为什么就需要Mac地址又需要IP地址？假如局域网中有计算机A、计算机B，以及一个唯一与外网连通的路由器，局域网外面是远在他方的百度。当计算机A 想要连接百度时，计算机A 就先发出一个连接百度的请求谁的IP 地址是220.181.57.217，但因为百度在外网，并不在局域网内，所以局域网内部没有人能够回应它的请求！ 那正确的做法是怎么样的呢？ 正确的做法就是用两种地址，首先使用MAC 地址访问路由器，然后用路由器作为中转站去访问百度的IP 地址！ 现实中数据包通过网络中的各种设备（路由器、服务器、交换机、网关等），经过数次的转发，从一端传达到另一端 基于VRRP协议实现VIPVRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议），VRRP 是为了解决静态路由的高可用。虚拟路由器由多个路由器组成，每个路由器都有各自的IP 和共同的VRIP(0-255)，其中每个VRRP 路由器通过竞选成为Master，占有VIP，对外提供路由服务，其他成为Backup，Master 以IP 组播形式发送VRRP 协议包，与Backup 保持心跳连接，若Master 不可用（或Backup 接收不到VRRP 协议包），则Backup通过竞选产生新的Master，并继续对外提供路由服务，从而实现高可用 Keepalived 是Linux 下面实现VRRP 备份路由的高可靠性运行件。基于Keepalived 设计的服务模式能够真正做到主服务器和备份服务器故障时IP 瞬间无缝交接。二者结合，可以构架出比较稳定的软件LB 方案！ 参考资料 虚拟IP原理 Virtual IP Address的实现 nginx - 性能优化，突破十万并发 Nginx+keepalived 双机热备（主从模式） VRRP－虚拟路由冗余协议 虚拟IP继NGINX之后，keepalived的心跳之路 高可用架构图一图三用（keepalived+haproxy,keepalived+lvs,heartbeat+haproxy）]]></content>
      <categories>
        <category>高可用</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 CPU 隔离 和 绑定]]></title>
    <url>%2F2019%2F05%2F11%2FCentos7%20CPU%20%E9%9A%94%E7%A6%BB%20%E5%92%8C%20%E7%BB%91%E5%AE%9A.html</url>
    <content type="text"><![CDATA[隔离CPU核心从一般内核 SMP 平衡和调度算法中删除指定的 cpu (由cpu_number定义)。 将进程移动到或移出“独立” CPU 的唯一方法是通过 CPU 亲和系统调用。 cpu 数量从0开始，因此最大值比系统上的 cpu 数量少1 此选项是隔离 cpu 的首选方法。 另一种方法是手动设置系统中所有任务的 CPU 掩码，这可能会导致问题和次优的负载均衡器性能 查看 CPU 情况，共有4个CPU 123456789101112131415161718192021222324# lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 4On-line CPU(s) list: 0-3Thread(s) per core: 1Core(s) per socket: 1Socket(s): 4NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 42Model name: Intel(R) Core(TM) i5-2520M CPU @ 2.50GHzStepping: 7CPU MHz: 2491.949BogoMIPS: 4983.89Hypervisor vendor: VMwareVirtualization type: fullL1d cache: 32KL1i cache: 32KL2 cache: 256KL3 cache: 3072KNUMA node0 CPU(s): 0-3 修改/etc/default/grub 文件GRUB_CMDLINE_LINUX 行末尾添加 isolcpus=1,2，隔离出第2个和第3个CPU 1GRUB_CMDLINE_LINUX="crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet isolcpus=2,3" 重新编译image 123456# grub2-mkconfig -o /boot/grub2/grub.cfgGenerating grub configuration file ...Found linux image: /boot/vmlinuz-3.10.0-514.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-514.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-120896e1b2924a618de2776af043d4dcFound initrd image: /boot/initramfs-0-rescue-120896e1b2924a618de2776af043d4dc.img 重启 1# reboot 检查启动项是否设置成功 12[root@localhost ~]# cat /proc/cmdlineBOOT_IMAGE=/vmlinuz-3.10.0-862.el7.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet LANG=en_US.UTF-8 isolcpus=1,2 检查隔离是否生效，如果设置成功，则落在该核心的线程会很少，而其他核心的线程比较多 123456789101112# ps -eLo pid,user,lwp,psr | awk '&#123;if($4==1) print $0&#125;' #检查核心1 12 root 12 1 13 root 13 1 14 root 14 1 15 root 15 1 16 root 16 1# ps -eLo pid,user,lwp,psr | awk '&#123;if($4==2) print $0&#125;' #检查核心2 17 root 17 2 18 root 18 2 19 root 19 2 20 root 20 2 21 root 21 2 可以用 top 命令来查看 1# 执行top，按数字1，就可以调出每个核心的使用状态，然后按下f按键，向下找到"P= Last Used Cpu (SMP)"这一行，按下空格或者'd'，再按q按键返回，就可以看到每个线程具体落在哪个核心上面（最后一项P） CPU 绑定taskset 查看进程的 CPU 关联信息（十六进制形式）12# taskset -p 2915pid 2915's current affinity mask: ff 对应于二进制格式的“11111111” ，这意味着进程可以在8个不同的 CPU 核心(从0到7)中的任何一个上运行。最低位对应于核心 ID 0，从右到核心 ID 1的第二个最低位，从第三个最低位到核心 ID 2，等等。 查看进程的 CPU 关联信息（列表形式） 12# taskset -cp 2915pid 2915's current affinity list: 0-7 固定一个正在运行的进程到特定的 CPU 核心 12$ taskset -p &lt;COREMASK&gt; &lt;PID&gt;$ taskset -cp &lt;CORE-LIST&gt; &lt;PID&gt; 启动一个固定在特定 CPU 内核上的新程序 12# taskset &lt;COREMASK&gt; &lt;EXECUTABLE&gt;$ taskset -c &lt;CORE-LIST&gt; &lt;EXECUTABLE&gt; 查看进程使用的哪个CPU 1# ps -o psr -p &lt;PID&gt; 注：如果 taskset 命令不可用，需要安装 util-linux 1# sudo yum install util-linux Cgroup 创建一个控制组 1# mkdir /sys/fs/cgroup/cpuset/tiger # 创建一个控制组，删除用 rmdir 命令 限制 tiger 控制组下所有进程只能使用逻辑核 1 和 2 12# echo "1-2" &gt; /sys/fs/cgroup/cpuset/tiger/cpuset.cpus# echo "0" &gt; /sys/fs/cgroup/cpuset/tiger/cpuset.mems 对于 cpuset.mems 参数而言，每个内存节点和 NUMA 节点一一对应。如果进程的内存需求量较大，可以把所有的 NUMA 节点都配置进去。出于性能的考虑，配置的逻辑核和内存节点一般属于同一个 NUMA 节点，可用“numactl –hardware”命令获知它们的映射关系。 验证效果 将当前会话加入刚刚创建的控制组里 1# echo $$ &gt; /sys/fs/cgroup/cpuset/tiger/cgroup.procs # 写入当前进程编号 进程在加入一个控制组后，控制组所对应的限制会即时生效。启动一个计算密集型的任务，申请用 4 个逻辑核。 1# stress -c 4 注：如果 stress 命令不可用，需要安装 stress 1# yum install -y stress 观察 CPU 的使用情况来验证效果，只有编号为 1 和 2 的两个逻辑核在工作，用户态的比例高达 100% 12345678# toptop - 05:54:12 up 1:44, 7 users, load average: 3.14, 2.66, 4.67Tasks: 139 total, 9 running, 130 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 997980 total, 511464 free, 152984 used, 333532 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 632004 avail Mem]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virsh 命令详解]]></title>
    <url>%2F2019%2F04%2F24%2Fvirsh%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[安装1# yum install qemu-kvm libvirt virt-install virt-manager 命令列表版本信息 virsh-v 只显示版本号 virsh-V 显示版本的详细信息 查看实例 virsh list查看活动的虚拟机 virsh list –all 查看所有的虚拟机（关闭和运行的虚拟机） 虚拟机的状态有（8）种 runing 是运行状态 idel 是空闲状态 pause 暂停状态 shutdown 关闭状态 shut off 不运行完全关闭 crash 虚拟机崩坏状态 daying 垂死状态 pmsuspended 客户机被关掉电源中中断连接方式 qemu:///system (本地连接到系统实例) qemu+unix:///system(本地连接到系统实例) qemu://example.com/system(远程连接，TLS) qemu+tcp://example.com/system(远程登录，SASI) qemu+ssl://example.com/system(远程登录，SSL) -c - -connect 连接远程的主机 -l - -log 输出日志 -q - -quiet避免额外的信息 -r - - readonly 只读，一般和connect配合使用 -t - - timing 输出消逝的时间 -e - - escape 设置转意序列 domain命令创建、连接虚拟机 define（file）从文件定义一个虚拟机（但是不启动） undefine （file） 取消定义的虚拟机 create （file）：从文件创建虚拟机 console （domain）：连接虚拟机的控制台 查看虚拟机状态 dominfo（domian）显示虚拟机的信息 domname（idorUUID）显示虚拟机的名字 domuuid （domian）显示虚拟机的id domid（id or name ） 根据名字得到id domstate（domian） 显示虚拟机的状态 domstats（domian） 显示虚拟机的统计信息 domcontrol(domian) 显示虚拟机的控制接口状态ok or error domtime（domian） 显示虚拟机的时间 dommemstat（domain）获取虚拟机的内存统计信息 domhostname（domain）显示虚拟机的主机名 dump （domian file） 把文件配置输出到文件file dumpxml（domian）直接显示domian的xml文件配置 domblklist（domain）显示虚拟机的磁盘 domblkerror（domian）显示有错的磁盘 domblkinfo（domaindevice）显示磁盘大小信息 domblkstat（domaindevice）显示磁盘统计信息 domiflist（domain）显示网卡接口 domifaddr（domianinterface） 显示网络接口地址 domif-getlink（domianinterface） 显示虚拟接口的链接状态 domifstat（domianinterface） 显示网卡统计信息 vcpuinfo（domian） 显示cpu的信息 vcpucount （domian）显示 vcpu个数 cpu-stats （domian） 显示虚拟机的cpu统计信息 domdisplay （domian）显示地址和显卡 vncdisplay（domian） 显示虚拟机的vnc 信息 ttyconsole （domian） 显示设备用的终端 domjobinfo （domian） 显示虚拟机的任务 domjobabort（domian） 终止虚拟机活动的任务 memtune（domian） 获取或设置虚拟机内存参数 blkdeviotune（domian） 获取或设置虚拟机的块设备IO参数 blkiotune（domian） 获取或设置虚拟机的磁盘参数 domiftune（domian） 获取或设置虚拟机的虚拟接口参数 metadata（domian） 获取或设置虚拟机的metadata schedinfo（domian） 获取或设置虚拟机的调度信息 管理虚拟机 reset（domian）reset虚拟机 reboot（domian） 重启虚拟机 start（name or id） 开启虚拟机 shutdown（domian） 关闭虚拟机(soft shutdown) destroy（domain） 销毁虚拟机（Hard poweroff a physical machine） suspend （domian） 挂起虚拟机 resume（domian） 回复虚拟机的suspend状态 dompmsuspend（ ） 挂起虚拟机（电源功能） dompmwakeup（） 回复虚拟机的suspend状态（电源功能） save（）保存虚拟机状态到文件中 restore（）从保存状态的文件还原虚拟机 managedsave（domian）托管保存虚拟机状态 managedsave-remove（domian） 移除托管保存虚拟机状态 managedsave-edit（domian）编辑托管保存状态的XML文件 managedsave-dumpxml（domian）以XML文件格式显示托管保存状态文件 managedsave-define（domianxml）用托管保存状态文件替换与之相关联的虚拟机的XML文件 autostart （domain）：标示自动启动虚拟机 screenshot （domian） 虚拟机截屏 修改虚拟机配置 set-user-password（domianuser password）设置虚拟机用户密码 domrename（domiannew-name） 重新命名虚拟机 setvcpus（domian count）设置虚拟机的虚拟cpu个数 setmaxmen（domian）设置虚拟机的最大内存 setmen（domian） size 设置虚拟机的内存 vcpupin（domian）绑定虚拟机的vcpu与物理CPU emulatorpin（domian）绑定虚拟机的仿真器与物理CPU edit （domian） 编辑虚拟机的配置文件 domif-setlink set link state of a virtual interface 虚拟机文件系统 domfsfreeze Freeze domain’s mounted filesystems. domfsthaw Thaw domain’s mounted filesystems. domfsinfo Get information of domain’s mounted filesystems. domfstrim Invoke fstrim on domain’s mounted filesystems. 虚拟机迁移 migrate migrate domain to another host migrate-setmaxdowntime set maximum tolerable downtime migrate-getmaxdowntime get maximum tolerable downtime migrate-compcache get/set compression cache size migrate-setspeed Set the maximum migration bandwidth migrate-getspeed Get the maximum migration bandwidth migrate-postcopy Switch running migration from pre-copy to post-copy 虚拟机 attach 和 detach attach-device attach device from an XML file attach-disk attach disk device attach-interface attach network interface detach-device detach device from an XML file detach-device-alias detach device from an alias detach-disk detach disk device detach-interface detach network interface update-device update device from an XML file 虚拟机 image save-image-define redefine the XML for a domain’s saved state file save-image-dumpxml saved state domain information in XML save-image-edit edit XML for a domain’s saved state file 虚拟机 block blockcommit Start a block commit operation. blockcopy Start a block copy operation. blockjob Manage active block operations blockpull Populate a disk from its backing image. blockresize Resize block device of domain. virtual network 命令 net-list 显示网络 net-info（）显示网络信息 net-uuid （）显示网络的id net-name（）显示网络的名字 net-dumpxml（） 以XML形式显示网络信息 net-dhcp-leases（）显示 dhcp 租约信息 net-define （） 从XML文件定义网卡 net-undefine （） 取消定义的网卡 net-create （） 从XML文件创建网卡 net-edit（） 编辑网卡信息 net-update（ ） 更新网卡配置 net-autostart () 自动启动网卡 net-start （）开启网卡 net-destory ( ) 摧毁（停止）网卡 interface 命令 iface-list 列出所有的接口 iface-name （mac） 根据mac得到名字 iface-mac(interface) 根据名字得到mac iface-dumpxml （interface）显示接口的信息 iface-define（file）从XML文件定义接口 iface-undefine（interface） 取消定义的接口 iface-edit（interface） 编辑接口 iface-start（interface）开启接口 (enable it / “if-up”) iface-destroy（interface） 摧毁（停止）接口（disable it / “if-down”） iface-bridge 创建 bridge 设备并将现有网络设备连接到它 iface-unbriged 解绑定网桥 iface-begin（interface）创建当前接口设置的快照，可以稍后提交（iface-commit）或恢复（iface-rollback） iface-commit （interface）提交自 iface-begin 和 iface-rollbak以来所做的更改 iface-rollbak （interface）回滚到通过iface-begin创建的先前保存的配置 storage pool 命令 pool-list 的列表 pool-info 池的信息 pool-name（id）根据id得到name pool-id（name）根据name得到id pool-uuid （pool） 返回一个池的uuid pool-define（file）定义但是不开启 pool-create（file）根据文件创建池 pool-build（pool）建造一个池 pool-start（poop）开启池 pool-destory（pool）销毁池，以后能回复 pool-delete（pool）删除池，以后不能恢复 pool-auto （pool）标记池自动启动 pool-dumpxml（pool）查看池的定义文件 pool-edit（pool）编辑池的定义文件 volume 命令 vol-list（pool）列出卷 vol-info（pool）卷的信息 vol-name（path）得到卷的名字 vol-path returns the volume path for a given volume name or key vol-pool returns the storage pool for a given volume key or path vol-create create a vol from an XML file vol-create-as create a volume from a set of args vol-create-from create a vol, using another volume as input vol-delete（）卷的删除 vol-upload（pool） upload file contents to a volume vol-download download volume contents to a file vol-resize resize a vol vol-wipe wipe a vol vol-clone clone a volume. vol-dumpxml vol information in XML vol-key returns the volume key for a given volume name or path nwfilter 命令 nwfilter-define （file）根据文件生成一个网络过滤器 nwfilter-undefine（name） 删除网络过滤 nwfilter-list 列出来网络过滤 nwfilter-dumpxml（file）生成一个网络过滤的文件 nwfilter-edit（name） 编辑一个网络过滤器动手实践 创建虚拟机 准备虚拟机配置文件，复制一份 cirros.xml并命名为cirros_instance.xml 1234567[root@geekspeng ~]# cd /etc/libvirt/qemu[root@geekspeng qemu]# lsautostart cirros.xml networks[root@geekspeng qemu]# cp cirros.xml cirros_instance.xml [root@geekspeng qemu]# lsautostart cirros_instance.xml cirros.xml networks[root@geekspeng qemu]# 修改 cirros_instance.xml 中的 name 为 cirros_instance，并删掉uuid 1[root@geekspeng qemu]# vim cirros_instance.xml 创建虚拟机的第一种方式（先定义在启动） 定义一个虚拟机1234567[root@geekspeng qemu]# virsh define cirros_instance.xml Domain cirros_instance defined from cirros_instance.xml[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 5 cirros running - cirros_instance shut off 可以看到此时虚拟机 cirros_instance 处于关机状态 启动虚拟机123456[root@geekspeng qemu]# virsh start cirros_instance Domain cirros_instance started[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 5 cirros running 6 cirros_instance running 可以看到此时虚拟机 cirros_instance 处于运行状态 创建虚拟机的第二种方式（直接启动）123456789[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 5 cirros running[root@geekspeng qemu]# virsh create cirros_instance.xml Domain cirros_instance created from cirros_instance.xml[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 5 cirros running 7 cirros_instance running 可以看到创建成功后，虚拟机 cirros_instance 直接处于运行状态 查看虚拟机 列出所有的虚拟机 12345[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 5 cirros running 7 cirros_instance running 列出活动状态的虚拟机（将cirros 虚拟机关机） 123456789[root@geekspeng qemu]# virsh shutdown cirrosDomain cirros is being shutdown[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 7 cirros_instance running - cirros shut off[root@geekspeng qemu]# virsh list Id Name State---------------------------------------------------- 7 cirros_instance running 显示虚拟机信息 123456789101112131415[root@geekspeng qemu]# virsh dominfo cirros_instanceId: 7Name: cirros_instanceUUID: 734c231f-0cea-497b-8a24-33368f1c10f5OS Type: hvmState: runningCPU(s): 1CPU time: 223.5sMax memory: 102400 KiBUsed memory: 102400 KiBPersistent: noAutostart: disableManaged save: noSecurity model: noneSecurity DOI: 0 显示虚拟机的内存统计信息 123[root@geekspeng qemu]# virsh dommemstat cirros_instance actual 102400rss 108380 显示虚拟机的 cpu信息 1234567891011[root@geekspeng qemu]# virsh vcpucount cirrosmaximum config 1maximum live 1current config 1current live 1[root@geekspeng qemu]# virsh vcpuinfo cirros_instance VCPU: 0CPU: 0State: runningCPU time: 219.5sCPU Affinity: y 上面显示的是VCPU，CPU显示的是编号而不是个数，CPU Affinity为 y 显示 VCPU0绑定到CPU0 显示虚拟机的磁盘 1234567[root@geekspeng qemu]# virsh domblklist cirros_instance Target Source------------------------------------------------hda /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img[root@geekspeng qemu]# virsh domblkinfo cirros_instance hdaCapacity: 41126400Allocation: 14602240Physical: 14614528 显示虚拟机的网卡接口 12345[root@geekspeng qemu]# virsh domiflist cirros_instance Interface Type Source Model MAC-------------------------------------------------------vnet1 network default rtl8139 52:54:00:31:e9:4d[root@geekspeng qemu]# virsh domif-getlink cirros_instance vnet1 vnet1 up 查看虚拟机的 xml 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137[root@geekspeng qemu]# virsh dumpxml cirros_instance &lt;domain type='kvm' id='7'&gt; &lt;name&gt;cirros_instance&lt;/name&gt; &lt;uuid&gt;734c231f-0cea-497b-8a24-33368f1c10f5&lt;/uuid&gt; &lt;memory unit='KiB'&gt;102400&lt;/memory&gt; &lt;currentMemory unit='KiB'&gt;102400&lt;/currentMemory&gt; &lt;vcpu placement='static'&gt;1&lt;/vcpu&gt; &lt;resource&gt; &lt;partition&gt;/machine&lt;/partition&gt; &lt;/resource&gt; &lt;os&gt; &lt;type arch='x86_64' machine='pc-i440fx-rhel7.0.0'&gt;hvm&lt;/type&gt; &lt;boot dev='hd'/&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;/features&gt; &lt;cpu mode='custom' match='exact' check='full'&gt; &lt;model fallback='forbid'&gt;SandyBridge&lt;/model&gt; &lt;feature policy='require' name='hypervisor'/&gt; &lt;feature policy='disable' name='xsaveopt'/&gt; &lt;/cpu&gt; &lt;clock offset='utc'&gt; &lt;timer name='rtc' tickpolicy='catchup'/&gt; &lt;timer name='pit' tickpolicy='delay'/&gt; &lt;timer name='hpet' present='no'/&gt; &lt;/clock&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;pm&gt; &lt;suspend-to-mem enabled='no'/&gt; &lt;suspend-to-disk enabled='no'/&gt; &lt;/pm&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2'/&gt; &lt;source file='/var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img'/&gt; &lt;backingStore/&gt; &lt;target dev='hda' bus='ide'/&gt; &lt;alias name='ide0-0-0'/&gt; &lt;address type='drive' controller='0' bus='0' target='0' unit='0'/&gt; &lt;/disk&gt; &lt;controller type='usb' index='0' model='ich9-ehci1'&gt; &lt;alias name='usb'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x7'/&gt; &lt;/controller&gt; &lt;controller type='usb' index='0' model='ich9-uhci1'&gt; &lt;alias name='usb'/&gt; &lt;master startport='0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0' multifunction='on'/&gt; &lt;/controller&gt; &lt;controller type='usb' index='0' model='ich9-uhci2'&gt; &lt;alias name='usb'/&gt; &lt;master startport='2'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x1'/&gt; &lt;/controller&gt; &lt;controller type='usb' index='0' model='ich9-uhci3'&gt; &lt;alias name='usb'/&gt; &lt;master startport='4'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x2'/&gt; &lt;/controller&gt; &lt;controller type='pci' index='0' model='pci-root'&gt; &lt;alias name='pci.0'/&gt; &lt;/controller&gt; &lt;controller type='ide' index='0'&gt; &lt;alias name='ide'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/&gt; &lt;/controller&gt; &lt;controller type='virtio-serial' index='0'&gt; &lt;alias name='virtio-serial0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/&gt; &lt;/controller&gt; &lt;interface type='network'&gt; &lt;mac address='52:54:00:31:e9:4d'/&gt; &lt;source network='default' bridge='virbr0'/&gt; &lt;target dev='vnet1'/&gt; &lt;model type='rtl8139'/&gt; &lt;alias name='net0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/&gt; &lt;/interface&gt; &lt;serial type='pty'&gt; &lt;source path='/dev/pts/4'/&gt; &lt;target type='isa-serial' port='0'&gt; &lt;model name='isa-serial'/&gt; &lt;/target&gt; &lt;alias name='serial0'/&gt; &lt;/serial&gt; &lt;console type='pty' tty='/dev/pts/4'&gt; &lt;source path='/dev/pts/4'/&gt; &lt;target type='serial' port='0'/&gt; &lt;alias name='serial0'/&gt; &lt;/console&gt; &lt;channel type='spicevmc'&gt; &lt;target type='virtio' name='com.redhat.spice.0' state='disconnected'/&gt; &lt;alias name='channel0'/&gt; &lt;address type='virtio-serial' controller='0' bus='0' port='1'/&gt; &lt;/channel&gt; &lt;input type='mouse' bus='ps2'&gt; &lt;alias name='input0'/&gt; &lt;/input&gt; &lt;input type='keyboard' bus='ps2'&gt; &lt;alias name='input1'/&gt; &lt;/input&gt; &lt;graphics type='spice' port='5901' autoport='yes' listen='127.0.0.1'&gt; &lt;listen type='address' address='127.0.0.1'/&gt; &lt;image compression='off'/&gt; &lt;/graphics&gt; &lt;sound model='ich6'&gt; &lt;alias name='sound0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/&gt; &lt;/sound&gt; &lt;video&gt; &lt;model type='qxl' ram='65536' vram='65536' vgamem='16384' heads='1' primary='yes'/&gt; &lt;alias name='video0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt; &lt;/video&gt; &lt;redirdev bus='usb' type='spicevmc'&gt; &lt;alias name='redir0'/&gt; &lt;address type='usb' bus='0' port='1'/&gt; &lt;/redirdev&gt; &lt;redirdev bus='usb' type='spicevmc'&gt; &lt;alias name='redir1'/&gt; &lt;address type='usb' bus='0' port='2'/&gt; &lt;/redirdev&gt; &lt;memballoon model='virtio'&gt; &lt;alias name='balloon0'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/&gt; &lt;/memballoon&gt; &lt;/devices&gt; &lt;seclabel type='dynamic' model='dac' relabel='yes'&gt; &lt;label&gt;+107:+107&lt;/label&gt; &lt;imagelabel&gt;+107:+107&lt;/imagelabel&gt; &lt;/seclabel&gt;&lt;/domain&gt; 连接虚拟机 通过控制窗口登录虚拟机（ctrl + ] 退出登录） 1234[root@geekspeng qemu]# virsh console cirros_instance Connected to domain cirros_instanceEscape character is ^]login as 'cirros' user. default password: 'cubswin:)'. use 'sudo' for root.cirros login: 通过 ssh 连接虚拟机 123[root@geekspeng ~]# ssh cirros@192.168.122.157cirros@192.168.122.157's password: $ 远程连接虚拟机 1[root@geekspeng ~]# virt-viewer -c qemu+ssh://10.0.0.200/system cirros 管理虚拟机 关闭虚拟机（shutodwn） 12345678910[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 1 cirros running 3 cirros_instance running[root@geekspeng qemu]# virsh shutdown cirrosDomain cirros is being shutdown[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running - cirros shut off 启动虚拟机（start） 12345678910[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running - cirros shut off[root@geekspeng qemu]# virsh start cirrosDomain cirros started[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 4 cirros running 挂起虚拟机（suspend ） 12345678910[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 4 cirros running[root@geekspeng qemu]# virsh suspend cirrosDomain cirros suspended[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 4 cirros paused 恢复虚拟机（resume） 12345678910[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 4 cirros paused[root@geekspeng qemu]# virsh resume cirrosDomain cirros resumed[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 4 cirros running 保存虚拟机状态到文件中（save） 123456789[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 5 cirros running[root@geekspeng qemu]# virsh save cirros testDomain cirros saved to test[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running - cirros shut off 从保存状态的文件还原虚拟机（restore） 12345678910[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running - cirros shut off[root@geekspeng qemu]# virsh restore testDomain restored from test[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 3 cirros_instance running 6 cirros running 重置虚拟机（reset ） 12[root@geekspeng qemu]# virsh reset cirrosDomain cirros was reset 重启虚拟机（reboot） 12[root@geekspeng qemu]# virsh reboot cirrosDomain cirros is being rebooted 创建删除快照 1234567[root@geekspeng dnsmasq]# virsh snapshot-create cirrosDomain snapshot 1548304381 created[root@geekspeng dnsmasq]# virsh snapshot-revert cirros 1548304381[root@geekspeng dnsmasq]# virsh snapshot-list cirros Name Creation Time State------------------------------------------------------------ 1548304381 2019-01-23 20:33:01 -0800 running[root@geekspeng dnsmasq]# virsh snapshot-delete cirros 1548304381 Domain snapshot 1548304381 deleted[root@geekspeng dnsmasq]# virsh snapshot-list cirros Name Creation Time State 冷迁移虚拟机（虚拟机需要关机） 源主机（10.0.0.200） 12345678910111213[root@geekspeng ~]# virsh list --all Id Name State---------------------------------------------------- - cirros shut off - cirros_instance shut off[root@geekspeng ~]# virsh migrate cirros --offline qemu+ssh://10.0.0.201/system --persistentroot@10.0.0.201's password: [root@geekspeng ~]# virsh migrate cirros_instance --offline qemu+ssh://10.0.0.201/system --persistentroot@10.0.0.201's password: [root@geekspeng ~]# virsh list --all Id Name State---------------------------------------------------- - cirros shut off - cirros_instance shut off 目标主机（10.0.0.201） 12345[root@geekspeng1 ~]# virsh list --all Id Name State---------------------------------------------------- - cirros shut off - cirros_instance shut off 迁移完成后，虚拟机同时在源主机和目标主机存在 热迁移虚拟机（需要共享存储） 修改虚拟机配置 重新命名虚拟机（domrename） 12345678910111213[root@geekspeng qemu]# virsh shutdown cirrosDomain cirros is being shutdown[root@geekspeng qemu]# virsh domrename cirros cirros1Domain successfully renamed[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 13 cirros_instance running - cirros1 shut off[root@geekspeng qemu]# virsh domrename cirros1 cirrosDomain successfully renamed[root@geekspeng qemu]# virsh start cirrosDomain cirros started[root@geekspeng qemu]# virsh list --all Id Name State---------------------------------------------------- 13 cirros_instance running 14 cirros running 编辑虚拟机的配置文件（edit） 将vcpu 个数从1个改成两个 2 123456789101112[root@geekspeng qemu]# virsh vcpucount cirrosmaximum config 1maximum live 1current config 1current live 1[root@geekspeng qemu]# virsh shutdown cirrosDomain cirros is being shutdown[root@geekspeng qemu]# virsh edit cirrosDomain cirros XML configuration edited.[root@geekspeng qemu]# virsh create /etc/libvirt/qemu/cirros.xml Domain cirros created from /etc/libvirt/qemu/cirros.xml[root@geekspeng qemu]# virsh vcpucount cirrosmaximum config 2maximum live 2current config 2 current live 2 设置虚拟机的内存大小（setmaxmem，setmem） 12345678910[root@geekspeng qemu]# virsh shutdown cirrosDomain cirros is being shutdown[root@geekspeng qemu]# virsh dominfo cirros | grep memoryMax memory: 131072 KiBUsed memory: 131072 KiB[root@geekspeng qemu]# virsh setmaxmem cirros 524288 # 需要关机[root@geekspeng qemu]# virsh dominfo cirros | grep memoryMax memory: 524288 KiBUsed memory: 131072 KiB[root@geekspeng qemu]# virsh start cirrosDomain cirros started[root@geekspeng qemu]# virsh setmem cirros 524288 # 需要开机[root@geekspeng qemu]# virsh dominfo cirros | grep memoryMax memory: 524288 KiBUsed memory: 524288 KiB 设置虚拟机的vcpu个数（setvcpus） 12345678910[root@geekspeng ~]# virsh vcpucount cirros_instance maximum config 2maximum live 2current config 1current live 1[root@geekspeng ~]# virsh setvcpus cirros_instance 2 --current [root@geekspeng ~]# virsh setvcpus cirros_instance 2 --config[root@geekspeng ~]# virsh vcpucount cirros_instance maximum config 2maximum live 2current config 2current live 2 关闭或打开某个网口（domif-setlink） 12345678[root@geekspeng qemu]# virsh domiflist cirrosInterface Type Source Model MAC-------------------------------------------------------vnet0 bridge br0 rtl8139 52:54:00:b9:bf:4f[root@geekspeng qemu]# virsh domif-setlink cirros vnet0 downDevice updated successfully[root@geekspeng qemu]# virsh domif-getlink cirros vnet0vnet0 down[root@geekspeng qemu]# virsh domif-setlink cirros vnet0 upDevice updated successfully[root@geekspeng qemu]# virsh domif-getlink cirros vnet0vnet0 up 挂载卸载硬盘 创建虚拟硬盘 1234567[root@geekspeng ~]# virsh vol-create-as default cirros.qcow2 100M --format qcow2Vol cirros.qcow2 created[root@geekspeng ~]# virsh vol-list default Name Path ------------------------------------------------------------------------------ cirros-0.3.4-x86_64-disk.img /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img cirros.qcow2 /var/lib/libvirt/images/cirros.qcow2 挂载虚拟硬盘 12345678910[root@geekspeng ~]# virsh domblklist cirrosTarget Source------------------------------------------------vda /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img[root@geekspeng ~]# virsh attach-disk cirros /var/lib/libvirt/images/cirros.qcow2 vdbDisk attached successfully[root@geekspeng ~]# virsh domblklist cirrosTarget Source------------------------------------------------vda /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.imgvdb /var/lib/libvirt/images/cirros.qcow2 重启后仍然生效 卸载虚拟硬盘 123456789[root@geekspeng ~]# virsh domblklist cirrosTarget Source------------------------------------------------vda /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.imgvdb /var/lib/libvirt/images/cirros.qcow2[root@geekspeng ~]# virsh detach-disk cirros vdbDisk detached successfully[root@geekspeng ~]# virsh domblklist cirrosTarget Source------------------------------------------------vda /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img 删除虚拟硬盘 123456789[root@geekspeng ~]# virsh vol-list default Name Path ------------------------------------------------------------------------------ cirros-0.3.4-x86_64-disk.img /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img cirros.qcow2 /var/lib/libvirt/images/cirros.qcow2 [root@geekspeng ~]# virsh vol-delete cirros.qcow2 --pool default Vol cirros.qcow2 deleted[root@geekspeng ~]# virsh vol-list default Name Path ------------------------------------------------------------------------------ cirros-0.3.4-x86_64-disk.img /var/lib/libvirt/images/cirros-0.3.4-x86_64-disk.img 挂载卸载网卡临时挂载虚拟网卡，修改保存在内存中，重启就失效 12345678[root@geekspeng dnsmasq]# virsh domiflist cirrosInterface Type Source Model MAC-------------------------------------------------------vnet1 network default virtio 52:54:00:f2:14:b0[root@geekspeng dnsmasq]# virsh attach-interface cirros network default --model virtioInterface attached successfully[root@geekspeng dnsmasq]# virsh domiflist cirrosInterface Type Source Model MAC-------------------------------------------------------vnet1 network default virtio 52:54:00:f2:14:b0vnet2 network default virtio 52:54:00:12:9c:2b 虽然 virsh 看绑定了vnet2，但是虚拟机内部并没有增加一张网卡，手动增加并启动永久挂载虚拟网卡，修改会保存到配置文件中（也可以直接修改配置文件） 123[root@geekspeng dnsmasq]# virsh attach-interface cirros bridge br0 --model virtio --persistent --config[root@geekspeng dnsmasq]# virsh dumpxml cirros &gt;/etc/libvirt/qemu/cirros.xml[root@geekspeng dnsmasq]# virsh define /etc/libvirt/qemu/cirros.xml 卸载虚拟网卡 123456789[root@geekspeng dnsmasq]# virsh domiflist cirrosInterface Type Source Model MAC-------------------------------------------------------vnet1 network default virtio 52:54:00:f2:14:b0vnet2 network default virtio 52:54:00:12:9c:2b[root@geekspeng dnsmasq]# virsh detach-interface cirros --type network --mac 52:54:00:12:9c:2bInterface detached successfully[root@geekspeng dnsmasq]# virsh domiflist cirrosInterface Type Source Model MAC-------------------------------------------------------vnet1 network default virtio 52:54:00:f2:14:b0 删除虚拟机12345678910[root@geekspeng ~]# virsh shutdown cirros_instance # 关机Domain cirros_instance is being shutdown[root@geekspeng ~]# virsh list --all Id Name State---------------------------------------------------- 23 cirros running - cirros_instance shut off[root@geekspeng ~]# virsh undefine cirros_instance # 删除定义虚拟机的xml文件 Domain cirros_instance has been undefined[root@geekspeng ~]# virsh list --all Id Name State---------------------------------------------------- 23 cirros running 遇到的问题 virsh shutdown 不起作用 如果使用 Xen HVM or QEMU/KVM，需要安装 ACPI 并且启动 ACPI ，同时检查虚拟机的配置文件是否配置了 ACPI 12# virsh dumpxml $your-vm-name | grep acpi&lt;features&gt;&lt;acpi/&gt;&lt;/features&gt; 如果 shutdown 还不起作用需要确定虚拟机此时已经完全启动起来，否则虽然virsh list 显示虚拟机是运行状态，但是还是无法执行virsh shutdown命令 如果我更改了正在运行的虚拟机的XML，那么更改是否会立即生效？ 不会. 重新定义正在运行的虚拟机的XML不会更改任何内容，更改将在下一次VM启动后生效.。Libvirt 有一组命令用于对正在运行的虚拟机进行实时更改，这些命令具有不同的支持，具体取决于hypervisor，例如 virsh attach- ， virsh detach- ，virsh setmem，virsh setvcpus]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用virt-install安装虚拟机]]></title>
    <url>%2F2019%2F04%2F18%2F%E4%BD%BF%E7%94%A8virt-install%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BA.html</url>
    <content type="text"><![CDATA[准备工作安装 virt-install 1# yum install -y virt-install ISO镜像安装虚拟机 在官方网站下载CentOS-7ISO镜像 使用qemu-img工具创建一个虚拟硬盘1qemu-img create -f qcow2 /tmp/centos7.qcow2 10G 注意qemu 用户需要有/tmp/centos7.qcow2 访问权限 以ISO文件作为cdrom，qcow2文件作为第一块虚拟硬盘，启动虚拟机12345678910virt-install \ --name centos7 \ --ram 1024 \ --vcpus 1 \ --disk /tmp/centos7.qcow2,format=qcow2 \ --network bridge=virbr0 \ --graphics none \ --os-type linux \ --os-variant centos7.0 \ --cdrom=CentOS-7-x86_64-Minimal-1804.iso 1234567* 进入安装界面，进行相关配置，比如时区、键盘映射、语言等。* 安装程序会识别虚拟机的虚拟硬盘，即qcow2文件，映射为/dev/vda，并进入分区引导界面。* 分区完成后，开始拷贝操作系统所需要的文件。* 用户自定义设置，包括创建用户、预装程序。* 安装grub引导程序，退出重启，此时操作系统已经安装到qcow2虚拟硬盘中。* 从硬盘启动，进入虚拟机，安装cloud-init、growpart、qemu-guest-agent等工具。* 删除虚拟机，只需要保留qcow2虚拟硬盘文件，镜像制作完成。 从安装源安装 使用qemu-img工具创建一个虚拟硬盘1qemu-img create -f qcow2 /tmp/centos7.qcow2 10G 注意qemu 用户需要有/tmp/centos7.qcow2 访问权限 用 –location 代替 –cdrom 参数，qcow2文件作为第一块虚拟硬盘，启动虚拟机12345678910virt-install \--name centos7 \--ram 1024 \--vcpus 1 \--disk /tmp/centos7.qcow2,format=qcow2 \--os-type linux \--os-variant centos7.0 \--network bridge=virbr0 \--graphics none \--location 'http://mirror.i3d.net/pub/centos/7/os/x86_64/' 直接启动 qow2 镜像 修改Cloud image的密码 image 下载地址http://cloud.centos.org/centos/7/images/ 安装软件 libguestfs-tools 1# yum install libguestfs-tools 设置 root 密码 1# virt-customize -a centos7.qcow2 --root-password password:123456 12设置一个随机密码# virt-customize -a centos7.qcow2 --root-password random 启动 qow2 镜像12345678910virt-install \--name centos7 \--ram 1024 \--vcpus 1 \--disk ./centos7.qcow2,format=qcow2 \--os-type linux \--os-variant centos7.0 \--network bridge=virbr0 \--graphics none \--boot hd 注意 qemu 用户需要有./centos7.qcow2 访问权限–boot hd，从磁盘启动 cloud image默认是不允许用 root以及密码进行登录，放开限制并重启sshd1234# vi /etc/ssh/sshd_configPermitRootLogin yesPasswordAuthentication yes# systemctl restart sshd 附录 network –network bridge=virbr0 # 桥接模式 –network network=default # 默认方式 –graphics –graphics none # 无界面 –graphics vnc,port=5999 # vnc控制台 –os-variant 操作系统变异 使用 osinfo-query os 命令获得支持的操作系统变种的列表 123456789101112131415161718192021222324252627282930osinfo-query os Short ID | Name | Version | ID----------------------+----------------------------------------------------+----------+----------------------------------------- .................. centos6.0 | CentOS 6.0 | 6.0 | http://centos.org/centos/6.0 centos6.1 | CentOS 6.1 | 6.1 | http://centos.org/centos/6.1 centos6.2 | CentOS 6.2 | 6.2 | http://centos.org/centos/6.2 centos6.3 | CentOS 6.3 | 6.3 | http://centos.org/centos/6.3 centos6.4 | CentOS 6.4 | 6.4 | http://centos.org/centos/6.4 centos6.5 | CentOS 6.5 | 6.5 | http://centos.org/centos/6.5 centos6.6 | CentOS 6.6 | 6.6 | http://centos.org/centos/6.6 centos6.7 | CentOS 6.7 | 6.7 | http://centos.org/centos/6.7 centos6.8 | CentOS 6.8 | 6.8 | http://centos.org/centos/6.8 centos6.9 | CentOS 6.9 | 6.9 | http://centos.org/centos/6.9 centos7.0 | CentOS 7.0 | 7.0 | http://centos.org/centos/7.0 .................. ubuntu10.04 | Ubuntu 10.04 LTS | 10.04 | http://ubuntu.com/ubuntu/10.04 ubuntu10.10 | Ubuntu 10.10 | 10.10 | http://ubuntu.com/ubuntu/10.10 ubuntu11.04 | Ubuntu 11.04 | 11.04 | http://ubuntu.com/ubuntu/11.04 ubuntu11.10 | Ubuntu 11.10 | 11.10 | http://ubuntu.com/ubuntu/11.10 ubuntu12.04 | Ubuntu 12.04 LTS | 12.04 | http://ubuntu.com/ubuntu/12.04 ubuntu12.10 | Ubuntu 12.10 | 12.10 | http://ubuntu.com/ubuntu/12.10 ubuntu13.04 | Ubuntu 13.04 | 13.04 | http://ubuntu.com/ubuntu/13.04 ubuntu13.10 | Ubuntu 13.10 | 13.10 | http://ubuntu.com/ubuntu/13.10 ubuntu14.04 | Ubuntu 14.04 LTS | 14.04 | http://ubuntu.com/ubuntu/14.04 ubuntu14.10 | Ubuntu 14.10 | 14.10 | http://ubuntu.com/ubuntu/14.10 ubuntu15.04 | Ubuntu 15.04 | 15.04 | http://ubuntu.com/ubuntu/15.04 ubuntu15.10 | Ubuntu 15.10 | 15.10 | http://ubuntu.com/ubuntu/15.10 ubuntu16.04 | Ubuntu 16.04 | 16.04 | http://ubuntu.com/ubuntu/16.04 ubuntu16.10 | Ubuntu 16.10 | 16.10 | http://ubuntu.com/ubuntu/16.10 ubuntu17.04 | Ubuntu 17.04 | 17.04 | http://ubuntu.com/ubuntu/17.04 ubuntu17.10 | Ubuntu 17.10 | 17.10 | http://ubuntu.com/ubuntu/17.10 .................. virt-customize 常用命令 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/sect-guest_virtual_machine_disk_access_with_offline_tools-using_virt_customize 安装 virt-customize 1# yum install libguestfs-tools 安装或删除软件包 1# virt-customize -a centos7.qcow2 --install epel-release 设置自己的SSH key 1# virt-customize -a centos7.qcow2 --ssh-inject centos:string:"ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBKCqX6EZIrGHoGaMII4QAqr0QC72t+Kg/c5ZIRNTMb6Q+BwzejQgjhBTXeyPnp0rfE9XI4pTxkZqAUOGSK9Bfqg= smiller@bruckner" 设置 root 用户的密码为 daemon 1virt-customize -acentos7.qcow2 --root-password password:daemon 报错 1234567891011121314virt-customize: error: libguestfs error: could not create appliance throughlibvirt.Try running qemu directly without libvirt using this environment variable:export LIBGUESTFS_BACKEND=directOriginal error from libvirt: Cannot access storage file'/root/CentOS-7-aarch64-GenericCloud-2003.qcow2' (as uid:107, gid:107):Permission denied [code=38 int1=13]If reporting bugs, run virt-customize with debugging enabled and includethe complete output:virt-customize -v -x [...] 解决方法 设置环境变量 1export LIBGUESTFS_BACKEND=direct]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 libvirt 远程管理虚拟机]]></title>
    <url>%2F2019%2F04%2F16%2F%E9%80%9A%E8%BF%87%20libvirt%20%E8%BF%9C%E7%A8%8B%E7%AE%A1%E7%90%86%E8%99%9A%E6%8B%9F%E6%9C%BA.html</url>
    <content type="text"><![CDATA[通过qemu+ssh方式通过qemu+ssh连接方式比较简单，只要能通过ssh远程访问，命令如下： 1# virsh -c qemu+ssh://root@192.168.1.166/system 如果2个节点设置了互信，免密钥登录，可直接执行virsh相关命令， 1234# virsh -c qemu+ssh://root@192.168.1.166/system list Id 名称 状态---------------------------------------------------- 3 vm01 running 通过qemu+tcp方式被控端上： 修改/etc/sysconfig/libvirtd,开启以下2个配置项： 123# egrep -v "^#|^$" /etc/sysconfig/libvirtdLIBVIRTD_CONFIG=/etc/libvirt/libvirtd.confLIBVIRTD_ARGS="--listen 修改配置文件123456# vim /etc/libvirt/libvirtd.conflisten_tls = 0 #禁用tls登录listen_tcp = 1 #启用tcp方式登录tcp_port = "16509" #tcp端口16509listen_addr = "0.0.0.0" #监听地址auth_tcp = "none" #TCP不使用认证 重启libvirtd并查看监听的端口 123# systemctl restart libvirtd# netstat -anltp|grep 16509tcp 0 0 0.0.0.0:16509 0.0.0.0:* LISTEN 28843/libvirtd 主控端上远程访问（需要确保可以访问被控端的16509 tcp端口） 1234# virsh -c qemu+tcp://192.168.1.166/system list Id 名称 状态---------------------------------------------------- 3 vm01 running]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ 持久化]]></title>
    <url>%2F2019%2F04%2F15%2FRabbitMQ%20%E6%8C%81%E4%B9%85%E5%8C%96.html</url>
    <content type="text"><![CDATA[RabbitMQ 持久化分为三部分：交换器的持久化、队列的持久化和消息的持久化 交换器持久化交换器的持久化是通过在声明队列是将 durable 参数置为 true 实现的，如果交换器不设置持久化，那么在 RabbitM 务重启之后，相关的交换器元数据会丢失，不过消息不会丢失，只是不能将消息发送到这个交换器中了。 Features那列 大写的D说明 durable 参数置为 true，交换器进行了持久化 队列持久化队列的持久化是通过在声明队列时将 durable 参数置为 true 实现的，如果队列不设置持久化，那么在 RabbitMQ 服务重启之后，相关队列的元数据会丢失，此时数据也会丢失。正所谓”皮之不存，毛将焉附”。 队列的持久化能保证其本身的元数据不会因异常情况而丢失，但是并不能保证内部所存储的消息不会丢失。 Features那列大写的D说明 durable 参数置为 true，队列进行了持久化 消息的持久化通过将消息的投递模式(BasicProperties 中的 deliveryMode 属性)设置为即可实现消息的持久化。 Persistent为1说明有一条持续化消息，持久消息同时也会保存在内存中 只有同时设置了队列和消息的持久化，当 RabbitMQ 服务重启之后，消息依旧存在 单单只设置队列持久化，重启之后消息会丢失；单单只设置消息的持久化，消息并不会被持久化，重启之后队列消失，继而消息也丢失。 可以将所有的消息都设直为持久化，但是这样会严重影响 RabbitMQ 的性能(随机)。对于可靠性不是那么高的消息可以不采用持久化处理以提高整体的吞吐量。在选择是否要将消息持久化时，需要在可靠性和吐吞量之间做一个权衡。 即使将交换器、队列、消息都设置了持久化之后也不能百分之百保证数据不丢失 问题1： 首先从消费者来说，如果在订阅消费队列时将 autoAck 参数设置为 true ，那么当消费者接收到相关消息之后，还没来得及处理就宕机了，这样也算数据丢失。 解决方案： 将autoAck 参数设置为 false 并进行手动确认 问题2： 在持久化的消息正确存入 RabbitMQ 之后，还需要有一段时间才能存入磁盘之中。 RabbitMQ 并不会为每条消息都进行同步存盘(调用内核的 fsync方法)的处理，可能仅仅保存到操作系统缓存之中而不是物理磁盘之中。如果在这段时间内RabbitMQ 服务节点发生了岩机、重启等异常情况，消息保存还没来得及落盘，那么这些消息将会丢失。 解决方案： 可以引入 RabbitMQ 镜像队列机制，相当于配置了副本，如果主节点 master 在此特殊时间内挂掉，可以自动切换到从节点 slave ), 这样有效地保证了高可用性，除非整个集群都挂掉。虽然这样也不能完全保证 RabbitMQ 消息不丢失，但是配置了镜像队列要比没有配置镜像队列的可靠性要高很多，在实际生产环境中的关键业务队列一般都会设置镜像队列 还可以在发送端引入事务机制或者发送方确认机制来保证消息己经正确地发送并存储至 RabbitMQ 中，前提还要保证在调用 channel.basicPublish 方法的时候交换器能够将消息 正确路由到相应的队列之中。 如果exchange和queue都是持久化的，那么它们之间的binding也是持久化的。如果exchange和queue两者之间有一个持久化，一个非持久化，就不允许建立绑定]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机的四种网络模型]]></title>
    <url>%2F2019%2F04%2F12%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%9B%9B%E7%A7%8D%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html</url>
    <content type="text"><![CDATA[我们主要以 VirtualBox 和 VMwareWorkstation 这两款目前最主流的桌面虚拟化软件作为例。 总的来说，目前有四种常见的网络模型： 桥接（Bridge Adapter） NAT 主机（Host-only Adapter） 内部网络（Internal） VirtualBox 支持的四种模型，对于 VMware，则只有前三种 VirtualBox 支持的几种网络模型： VMware 支持的几种网络模型： 桥接模式（Bridge Adapter）使用虚拟交换机（Linux Bridge）将虚拟机和物理机连接起来，它们处于同一个网段。 如下图所示： 在这种网络模型下，虚拟机和物理机都处在一个二层网络里面，所以有： 虚拟机之间彼此互通 虚拟机与物理机彼此可以互通 只要物理机可以上网，那么虚拟机也可以 优点：简单方便 缺点：一旦虚拟机太多，广播就会很严重 桥接网络一般也只适用于桌面虚拟机或者小规模网络这种简单的形式 NAT模式NAT，即网络地址转换（Network Address Translatation）。严格来讲又分为 NAT 和 NAT网络两种。 根据 NAT 的原理，虚拟机所在的网络和物理机所在的网络不在同一个网段，虚拟机要访问物理所在网络必须经过一个地址转换的过程，也就是说在虚拟机网络内部需要内置一个虚拟的 NAT 设备来做这件事 但其中 NAT 和 NAT网络 两者还有些许的不同： NAT：主机上的虚拟机之间是互相隔离的，彼此不能通信（它们有独立的网络栈，独立的虚拟 NAT 设备） NAT网络：虚拟机之间共享虚拟 NAT 设备，彼此互通。 下图展示了两者细微的差别： PS：NAT 网络模式中一般还会内置一个虚拟的 DHCP 服务器来进行 IP 地址的管理。 下面我们通过实验来验证一下两种模式的区别，首先是 NAT 模式： 访问外网没问题： 访问其他虚拟机： 可以看到，两个虚拟机由于有隔离的网络栈，所以它们的 IP 地址并不在一个网段，所以 ping 不通。 再来看 NAT网络，访问外网同样没问题，我们来看下 VM 之间的互通： 可以看到，差别体现出来了， NAT网络 虚拟机之间共享网络栈，它们的 IP 地址处于同一个网段，所以彼此是互通的。 总结一下，以上两种 NAT 模式，如果不做其他配置，那么有： 虚拟机可以访问主机，反之不行 如果主机可以上外网，那么虚拟机也可以 对于 NAT，同主机上的虚拟机之间不能互通 对于 NAT网络，虚拟机之间可以互通 PS：如果做了端口映射配置，那么主机也可以访问虚拟机。 主机网络模式（Host-only Adapter）只限于主机内部访问的网络，虚拟机之间彼此互通，虚拟机与主机之间彼此互通。但是默认情况下虚拟机不能访问外网 主机网络看似简单，其实它的网络模型是相对比较复杂的，可以说前面几种模式实现的功能，在这种模式下，都可以通过虚拟机和网卡的配置来实现，这得益于它特殊的网络模型。 主机网络模型会在主机中模拟出一块虚拟网卡供虚拟机使用，所有虚拟机都连接到这块网卡上，这块网卡默认会使用网段 192.168.56.x（在主机的网络配置界面可以看到这块网卡），如下是基本的拓扑图示： 默认情况下，虚拟机之间可以互通，虚拟机只能和主机上的虚拟网卡互通，不能和不同网段的网卡互通，更不能访问外网，如果想做到这样，那么需要如图中红虚线所示，将物理网卡和虚拟网卡桥接或共享。在主机上做如下设置即可： 通过以上配置，我们来验证一下，虚拟机可以访问主机物理网卡和外网了： 内部网络模型（internal）虚拟机与外部环境完全断开，只允许虚拟机之间互相访问 总结下面以一张表来描述它们之间的通信行为： 参考资料 https://mp.weixin.qq.com/s?__biz=MzI1OTY2MzMxOQ==&amp;mid=2247485152&amp;idx=1&amp;sn=7e54ffcb0bc29169eeec216a59f584b8&amp;scene=19#wechat_redirect]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>虚拟化</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux虚拟网络基础]]></title>
    <url>%2F2019%2F04%2F06%2FLinux%E8%99%9A%E6%8B%9F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80.html</url>
    <content type="text"><![CDATA[TAP/TUNTAP/TUN 是 Linux 内核实现的一对虚拟网络设备，TAP 工作在二层虚拟以太设备，TUN 工作在三层 基于 TAP 驱动，即可实现虚拟机 vNIC 的功能，虚拟机的每个 vNIC 都与一个 TAP 设备相连，vNIC 之于 TAP 就如同 NIC 之于 eth 甚至连数据结构，tap与tun的定义都是同一个，两者仅仅是通过一个Flag来区分 当一个 TAP 设备被创建时，在 Linux 设备文件目录下会生成一个对应的字符设备文件，用户程序可以像打开一个普通文件一样对这个文件进行读写 Linux得有tun模块（Linux使用tun模块实现了tun/tap） 123456789101112# modinfo tunfilename: /lib/modules/4.14.37-4.el7.x86_64/kernel/drivers/net/tun.ko.xzalias: devname:net/tunalias: char-major-10-200license: GPLauthor: (C) 1999-2004 Max Krasnyansky &lt;maxk@qualcomm.com&gt;description: Universal TUN/TAP device driversrcversion: 768D398B7DC8B10F73D9182depends:intree: Yname: tunvermagic: 4.14.37-4.el7.x86_64 SMP mod_unload modversions 当Linux版本具有tun模块时，还得看看其是否已经加载 12# lsmod | grep tuntun 32768 21 vhost_net 如果没有加载，则使用如下命令进行加载： 1# modprobe tun 创建 tap/tun 设备： 12ip tuntap add dev tap0 mod tap # 创建 tap ip tuntap add dev tun0 mod tun # 创建 tun 删除 tap/tun 设备： 12ip tuntap del dev tap0 mod tap # 删除 tap ip tuntap del dev tun0 mod tun # 删除 tun VETH 设备总是成对出现，一端连着内核协议栈，另一端连着另一个设备，一个设备收到内核发送的数据后，会发送到另一个设备上去，这种设备通常用于容器中两个 namespace 之间的通信。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JMeter 进行压力测试]]></title>
    <url>%2F2019%2F03%2F24%2FJMeter%20%E8%BF%9B%E8%A1%8C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95.html</url>
    <content type="text"><![CDATA[下载JMeter 5.1.1（Requires Java 8+）并设置中文界面 下载后解压到任意位置 http://mirrors.shu.edu.cn/apache//jmeter/binaries/apache-jmeter-5.1.1.zip 设置中文界面 修改启动文件 jmeter.batapache-jmeter-5.1.1\bin\jmeter.bat，把默认language 改为zh_CN 1234改动前：set JMETER_LANGUAGE=-Duser.language=&quot;en&quot; -Duser.region=&quot;EN&quot;改动后：set JMETER_LANGUAGE=-Duser.language=&quot;zh&quot; -Duser.region=&quot;CN&quot; 启动JMeter 进入JMeter的bin目录下，windows系统双击jmeter.bat文件即可启动 使用JMeter录制脚本浏览器设置代理 打开火狐浏览器，找到选项，然后点击 拖到最下方，点击设置 设置填写 localhost 和端口8082（注意不要和系统其它程序的端口冲突） 注意： 只要你确定不再使用JMeter进行脚本录制，那么你要记得把火狐浏览器的网络代理给设置回来，点系统默认代理 设置JMeter 并录制脚本 在测试计划上点击右键，添加线程组 添加录制控制器 点击 “线程组”，然后右键，根据如下图步骤，添加一个录制控制器 添加代理服务器 点击 “测试计划”，然后右键，根据如下图步骤，添加一个代理服务器 添加之后，修改端口（这里端口和浏览器代理端口保持一致）和目标控制器 录制脚本 点击代理服务器右侧里面的启动录制按钮，弹出一个根证书的弹窗，点击确定 在火狐浏览器地址栏手动输入www.baidu.com，等页面加载完成，我们点击“新闻”这个链接，页面加载完成，我们选择停止录制，然后点击展开录制控制器，可以看到以下这些请求。 使用JMeter进行性能测试 添加聚合报告、查看结果树、用表格查看结果、图形结果，右键点击线程组，添加监听器 修改线程组参数并启动测试 选择线程组，然后修改参数，修改完成后点击开始按钮 线程数：模仿用户并发的数量 Ramp-up:运行线程的总时间，单位是秒 循环次数：每个线程循环次数 JMeter 性能测试结果分析查看结果树 请求结果（其中红色的是出错的请求，绿色的为通过） 取样器结果 相关名词解释Thread Name：线程组名称Sample Start:：启动开始时间Load time：加载时长Latency：等待时长Size in bytes：发送的数据总大小Headers size in bytes：发送数据的其余部分大小Sample Count：发送统计Error Count：交互错误统计Response code：返回码Response message：返回信息Response headers：返回的头部信息 发送的请求和响应数据 聚合报告 相关名词**解释**Sample（样本）：本次测试场景共运行多少线程；Average（平均值）：平均响应时间，单位ms；Median（中位数）：统计意义上的响应时间中值，单位ms；90% line（90%百分位）：所有线程中90%的线程响应时间都小于xx的值;Min（最小值）：响应最小时间，单位ms；Max（最大值）：响应最大时间，单位ms；Error（异常%）：出错率；Throughput（吞吐量）：以“requests/second、requests/minute、 requests /hour”来衡量Kb/sec（接收/发送 Kb/sec）：以Kb/seond来衡量的吞吐量 用表格查看结果 相关名词解释Sample：每个请求的序号Start Time：每个请求开始时间Thread Name：每个线程的名称Label：Http请求名称Sample Time：每个请求所花时间，单位毫秒Status：请求状态，如果为勾则表示成功，如果为叉表示失败。Bytes：请求的字节数 样本数目：也就是上面所说的请求个数，成功的情况下等于你设定的并发数目乘以循环次数平均：每个线程请求的平均时间最新样本：表示服务器响应最后一个请求的时间偏离：服务器响应时间变化、离散程度测量值的大小，或者，换句话说，就是数据的分布。 图形结果 清除测试数据 清除部分数据 点击左边要清除的选项，比如，清除聚合报告，点击聚合报，然后点击工具栏的小扫把图标即可 清除全部数据 点击工具栏的大扫把图标即可 JMeter 使用cookie信息浏览器登录后保存cookie信息 打开火狐浏览器，登录要保存cookie信息的网页 打开调试模式切换到存储，菜单-&gt;Web 开发者-&gt; 存储探查器 打开cookie，然后右侧红框区域内的所有数据就是cookie信息 JMeter 设置 HTTP Cookie管理器 在线程组上点击右键，然后按下图添加 cookie 管理器 把火狐浏览器里的 cookie 的名称、域名、路径、值填写到cookie管理器里 可以点击添加一项一项填写，也可以直接载入文件，将cookie 信息保存到文件方便下次使用 现在整个线程组的所有请求就都会使用这个cookie，如果只有部分请求需要使用，可以拖到对应的请求下面]]></content>
      <categories>
        <category>高性能</category>
      </categories>
      <tags>
        <tag>压力测试</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ab 进行压力测试]]></title>
    <url>%2F2019%2F03%2F11%2Fab%20%E8%BF%9B%E8%A1%8C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95.html</url>
    <content type="text"><![CDATA[安装 ab（apache bench）通过安装 httpd 的方式，顺带安装ab 1# yum -y install httpd 如果不想安装 httpd 但是又想使用ab命令的话，可以只安装 httpd-tools 1# yum -y install httpd-tools 使用 ab 进行压力测试ab 的使用入门ab的命令参数比较多，我们经常使用的是-c （并发用户数） 和 -n（请求总数），这里以https://www.baidu.com/为例进行说明 1234567891011121314151617181920212223242526272829303132333435363738# ab -c 10 -n 100 'https://www.baidu.com'This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking www.baidu.com (be patient).....doneServer Software: BWS/1.1Server Hostname: www.baidu.comServer Port: 443SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128Document Path: /Document Length: 227 bytesConcurrency Level: 10Time taken for tests: 1.777 secondsComplete requests: 100Failed requests: 0Write errors: 0Total transferred: 89300 bytesHTML transferred: 22700 bytesRequests per second: 56.29 [#/sec] (mean)Time per request: 177.650 [ms] (mean)Time per request: 17.765 [ms] (mean, across all concurrent requests)Transfer rate: 49.09 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 88 114 47.8 105 355Processing: 29 40 46.6 34 370Waiting: 29 39 36.8 34 300Total: 118 155 64.8 141 467Percentage of the requests served within a certain time (ms) 50% 141 66% 144 75% 146 80% 147 90% 163 95% 366 98% 452 99% 467 100% 467 (longest request) 主要看以下几组数据 吞吐率（Requests per second） 服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率 记住：吞吐率是基于并发用户数的。这句话代表了两个含义： a、吞吐率和并发用户数相关 b、不同的并发用户数下，吞吐率一般是不同的 计算公式： 总请求数/处理完成这些请求数所花费的时间，即 Request per second = Complete requests / Time taken for tests 用户平均请求等待时间（Time per request） 计算公式： 处理完成所有请求数所花费的时间 /（总请求数/并发用户数），即 Time per request = Time taken for tests /（ Complete requests / Concurrency Level） 服务器平均请求等待时间（Time per request:across all concurrent requests） 计算公式： 处理完成所有请求数所花费的时间/总请求数，即 Time taken for / testsComplete requests 可以看到，它是吞吐率的倒数，也等于用户平均请求等待时间/并发用户数，即 Time per request / Concurrency Level 并发连接数（The number of concurrent connections） 并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话 并发用户数（Concurrency Level） 要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数 ab 的使用进阶 发送 get 请求 1234567891011121314151617181920212223242526272829303132# ab -c 10 -n 100 'https://www.baidu.com/s?wd=ab'This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking www.baidu.com (be patient).....doneServer Software: BWS/1.1Server Hostname: www.baidu.comServer Port: 443SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128Document Path: /s?wd=abDocument Length: 227 bytesConcurrency Level: 10Time taken for tests: 1.853 secondsComplete requests: 100Failed requests: 0Write errors: 0Total transferred: 89300 bytesHTML transferred: 22700 bytesRequests per second: 53.97 [#/sec] (mean)Time per request: 185.288 [ms] (mean)Time per request: 18.529 [ms] (mean, across all concurrent requests)Transfer rate: 47.07 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 87 103 9.1 104 147Processing: 34 55 27.2 40 114Waiting: 34 54 27.2 39 113Total: 122 158 30.8 147 252Percentage of the requests served within a certain time (ms) 50% 147 66% 151 75% 188 80% 196 90% 204 95% 216 98% 233 99% 252 100% 252 (longest request) 发送 post 请求 1# ab -c 10 -n 100 -v 4 -p 'userlogin.txt' 'http://test.com/' userlogin.txt 内容如下： 1user_name=test&amp;password=test 发送带 Cookie 的请求 1# ab -c 10 -n 100 －C key1=value1;key2=value2 http://test.com/ 发送带 Header 的请求 1# ab -c 10 -n 100 -H 'Host: 10.0.40.11' 'http://test.com' 1ab -c1 -n1 -v4 -p project.txt -H 'Cookie: user_id=f3cebf17a6b14c6482ea8b618aed715c; user_name=administrator; project_id=154c5031aa3748d7a7deada6d5fce1f6; project_name=admin; acl_type=admin; hyhive_token=AjcBLwinKbn3uIpmkNsJQxmkveiZYFL46yj_csHR9TWNwm_erc77aL3fpBi7yF2Hq-zJRDvdJ9ns_7asAYWtb1ac3oAx68UiRpKw0utk3AaCdwf3Xqr56ExbJLzdqrKfuOeVWbQjpgoSLGAElUO3JQgduVIVzysPss3KiOyCo1j6NHlcBAAAAAg' 'http://10.0.40.11/api/hyhive/vm/list' 附录 ab 参数解释123456789101112131415161718192021222324252627# ab --help-n 即requests，用于指定压力测试总共的执行次数。-c 即concurrency，用于指定的并发数。-t 即timelimit，等待响应的最大时间(单位：秒)。-b 即windowsize，TCP发送/接收的缓冲大小(单位：字节)。-p 即postfile，发送POST请求时需要上传的文件，此外还必须设置-T参数。-u 即putfile，发送PUT请求时需要上传的文件，此外还必须设置-T参数。-T 即content-type，用于设置Content-Type请求头信息，例如：application/x-www-form-urlencoded，默认值为text/plain。-v 即verbosity，指定打印帮助信息的冗余级别。-w 以HTML表格形式打印结果。-i 使用HEAD请求代替GET请求。-x 插入字符串作为table标签的属性。-y 插入字符串作为tr标签的属性。-z 插入字符串作为td标签的属性。-C 添加cookie信息，例如："Apache=1234"(可以重复该参数选项以添加多个)。-H 添加任意的请求头，例如："Accept-Encoding: gzip"，请求头将会添加在现有的多个请求头之后(可以重复该参数选项以添加多个)。-A 添加一个基本的网络认证信息，用户名和密码之间用英文冒号隔开。-P 添加一个基本的代理认证信息，用户名和密码之间用英文冒号隔开。-X 指定使用的host和端口号，例如:"126.10.10.3:88"。-V 打印版本号并退出。-k 使用HTTP的KeepAlive特性。-d 不显示百分比。-S 不显示预估和警告信息。-g 输出结果信息到gnuplot格式的文件中。-e 输出结果信息到CSV格式的文件中。-r 指定接收到错误信息时不退出程序。-h 显示用法信息，其实就是ab -help。]]></content>
      <categories>
        <category>高性能</category>
      </categories>
      <tags>
        <tag>压力测试</tag>
        <tag>高性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beyond compare 4 破解]]></title>
    <url>%2F2019%2F02%2F14%2FBeyond%20compare%204%20%E7%A0%B4%E8%A7%A3.html</url>
    <content type="text"><![CDATA[密钥1w4G-in5u3SH75RoB3VZIX8htiZgw4ELilwvPcHAIQWfwfXv5n0IHDp5hv 1BM3+H1XygMtiE0-JBgacjE9tz33sIh542EmsGs1yg638UxVfmWqNLqu- Zw91XxNEiZF7DC7-iV1XbSfsgxI8Tvqr-ZMTxlGCJU+2YLveAc-YXs8ci RTtssts7leEbJ979H5v+G0sw-FwP9bjvE4GCJ8oj+jtlp7wFmpVdzovEh v5Vg3dMqhqTiQHKfmHjYbb0o5OUxq0jOWxg5NKim9dhCVF+avO6mDeRNc OYpl7BatIcd6tsiwdhHKRnyGshyVEjSgRCRY11IgyvdRPnbW8UOVULuTE Beyond Compare许可证密钥已被撤销解决办法windows 打开如下文件夹的目录：C:\Users\用户文件夹\AppData\Roaming\Scooter Software\Beyond Compare 4 然后删掉该文件夹下 BCState.xml 和 BCState.xml.bak 然后重新打开Beyond Compare（无需重新安装，还双击原来的图标） 提示：如果不行就删除所有文件，重新试用Beyond Compare 4双击后，它会提示你重新安装，然后点击下一个，下一个下一个，ok，搞定 mac 打开如下文件夹的目录： 1$cd &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/&quot; 然后删掉该文件夹下 BCState.xml、BCState.xml.bak 和 registry.dat 也可以直接用命令直接删除123$ rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/BCState.xml&quot;$ rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/BCState.xml.bak&quot;$ rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/registry.dat&quot; 然后重新打开Beyond Compare（无需重新安装，还双击原来的图标） 提示：如果不行就删除所有文件，重新试用Beyond Compare 4双击后，它会提示你重新安装，然后点击下一个，下一个下一个，ok，搞定 为了一劳永逸可以直接修改**Beyond Compare 4 启动程序，在每次启动的时候自动删除 BCState.xml 和 BCState.xml.bak** 进入Mac应用程序目录下，找到刚刚安装好的Beyond Compare，路径如下/Applications/Beyond Compare.app/Contents/MacOS 修改启动程序文件BCompare为BCompare.real 在当前目录下新建一个文件BCompare，文件内容如下： 12345#!/bin/bashrm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/BCState.xml&quot;rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/BCState.xml.bak&quot;rm &quot;/Users/$(whoami)/Library/Application Support/Beyond Compare/registry.dat&quot;&quot;`dirname &quot;$0&quot;`&quot;/BCompare.real $@ 修改文件的权限 1$ chmod a+x &quot;/Applications/Beyond Compare.app/Contents/MacOS/BCompare&quot;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>破解</tag>
        <tag>Beyond compare</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下查看网卡驱动和驱动信息]]></title>
    <url>%2F2018%2F11%2F27%2FLinux%20%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7%20tcpdump%20%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.html</url>
    <content type="text"><![CDATA[tcpdump简介tcpdump是一款 Linux 平台的抓包工具。它可以抓取涵盖整个 TCP/IP 协议族的数据包，支持针对网络层、协议、主机、端口的过滤，并提供 and、or、not 等逻辑语句来过滤无用的信息 安装tcpdump： 1# yum -y install tcpdump tcpdump命令格式 tcpdump 常用选项12345678910111213-D 列出操作系统所有可以用于抓包的接口-c 指定要抓取包的数量-i 指定监听的网卡， -i any 显示所有网卡-n 表示不解析主机名，直接用 IP 显示，默认是用 hostname 显示-nn 表示不解析主机名和端口，直接用端口号显示，默认显示是端口号对应的服务名-P 指定抓取的包是流入的包还是流出的，可以指定参数 in, out, inout 等，默认是 inout-q 快速打印输出，即只输出少量的协议相关信息-s len 设置要抓取数据包长度为 len，默认只会截取前 96bytes 的内容， -s0 的话，会截取全部内容。-S 将 TCP 的序列号以绝对值形式输出，而不是相对值-t 不要打印时间戳-vv 输出详细信息（比如 tos、ttl、checksum等）-w：将抓包数据输出到文件中而不是标准输出-r：从给定的数据包文件中读取数据，使用"-"表示从标准输入中读取。 tcpdump 过滤器123proto：可选有 ip、arp、rarp、tcp、udp、icmp、ether 等，默认是所有协议的包dir：可选有 src、dst、src or dst、src and dst，默认为 src or dsttype：可选有 host、net、port、portrange（端口范围，比如 21-42），默认为 host 表达式单元之间可以使用操作符” and（&amp;&amp;） 、 or（||）、not（!） “进行连接，使用括号”()”可以改变表达式的优先级，但需要注意的是括号会被shell解释，所以应该使用反斜线””转义为”()” 特别要记住在使用 &amp;&amp; 的时候，要用单引号或者双引号包住表达式 使用 tcpdump 的常用选项 不转换主机名、端口号等 1# tcpdump -nn 显示详细信息 123# tcpdump -v# tcpdump -vv# tcpdump -vvv 每增加一个 -v 标记，输出会包含更多信息 指定网络接口12# tcpdump -i ens33# tcpdump -i any 如果不指定网络接口， tcpdump 在运行时会选择编号最低的网络接口any 这一特定的网络接口名用来让 tcpdump 监听所有的接口 指定抓包数量 1# tcpdump -c 10 指定抓包大小 1# tcpdump -s 100 写入文件 1# tcpdump -w /var/tmp/tcpdata.pcap 读取文件 1# tcpdump -r /var/tmp/tcpdata.pcap 也可以利用 wireshark 来读取 tcpdump 保存的文件 组合使用1# tcpdump -nnvvv -i any -c 100 -s 100 使用 tcpdump 的过滤器tcpdump 可以通过各式各样的表达式，来过滤所截取或者输出的数据 查找特定主机的数据包1# tcpdump -nvvv -i any -c 3 host 10.0.3.1 只会显示源 IP 或者目的 IP 地址是 10.0.3.1 的数据包 只显示源地址为特定主机的数据包 1# tcpdump -nvvv -i any -c 3 src host 10.0.3.1 过滤源和目的端口 1# tcpdump -nvvv -i any -c 3 port 22 and port 60738 tcpdump 只输出端口号是 22 和 60738 的数据包 查找两个端口号的数据包1# tcpdump -nvvv -i any -c 20 'port 80 or port 443' 端口号 80 表示 http 连接，443 表示 https 查找两个特定端口和来自特定主机的数据包 1# tcpdump -nvvv -i any -c 20 '(port 80 or port 443) and host 10.0.3.169' 查找某协议的数据包 1# tcpdump -nnvvv -i any tcp tcpdump 的输出格式一般格式 1系统时间 源主机.端口 &gt; 目标主机.端口 数据包参数 示例 1234567# tcpdump -n -i any -c 1 host 10.0.0.210tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes22:59:04.971954 IP 10.0.0.210.ssh &gt; 10.0.0.1.49663: Flags [P.], seq 1081757770:1081757982, ack 3080549455, win 274, length 2121 packet captured2 packets received by filter0 packets dropped by kernel 可以按照 src-ip.src-port &gt; dest-ip.dest-port: Flags[S] 格式来分析。源地址位于 &gt; 前面，后面则是目的地址 通过 Flags[S] 可以判断数据包类型 [S] – SYN (开始连接) [.] – 没有标记 [P] – PSH (数据推送) [F] – FIN (结束连接) [R] – RST (重启连接)参考文档 https://mp.weixin.qq.com/s/NTkocGensdIPYL5qi5E14w https://mp.weixin.qq.com/s/2frB2Chaw2H1UitPNTYzhA]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>tcpdump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下查看网卡驱动和驱动信息]]></title>
    <url>%2F2018%2F11%2F18%2FLinux%E4%B8%8B%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1%E9%A9%B1%E5%8A%A8%E5%92%8C%E9%A9%B1%E5%8A%A8%E4%BF%A1%E6%81%AF.html</url>
    <content type="text"><![CDATA[必备设置 查看网卡驱动类型1ethtool -i 网卡名 示例： 12345678910# ethtool -i enp0s3driver: e1000version: 7.3.21-k8-NAPIfirmware-version:bus-info: 0000:00:03.0supports-statistics: yessupports-test: yessupports-eeprom-access: yessupports-register-dump: yessupports-priv-flags: no driver: e1000就是网卡类型 查查看网卡驱动信息 modinfo 网卡类型 示例： 123456789modinfo e1000结果如下：filename: /lib/modules/3.10.0-327.13.1.el7.x86_64/kernel/drivers/net/ethernet/intel/e1000/e1000.koversion: 7.3.21-k8-NAPIlicense: GPLdescription: Intel(R) PRO/1000 Network Driverauthor: Intel Corporation, linux.nics@intel.comrhelversion: 7.2srcversion: 4354B761874070384453524]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看 CentOS 的版本号]]></title>
    <url>%2F2018%2F09%2F01%2F%E6%9F%A5%E7%9C%8B%20CentOS7%20%E7%9A%84%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF.html</url>
    <content type="text"><![CDATA[查看 CentOS 的版本号CentOS的版本号信息一般存放在配置文件当中，在CentOS中，与其版本相关的配置文件中都有centos关键字，该文件一般存放在/etc/目录下，所以说我们可以直接在该文件夹下搜索相关的文件 123[root@node1 ~]# ll /etc/*centos*-rw-r--r--. 1 root root 38 Apr 28 2018 /etc/centos-release-rw-r--r--. 1 root root 51 Apr 28 2018 /etc/centos-release-upstream 其中存放其版本配置信息的文件为“centos-release”，翻译过来就是“CentOS的发行版”，所以说我们可以在这里查看CentOS相应的版本信息 12[root@node1 ~]# cat /etc/centos-releaseCentOS Linux release 7.5.1804 (Core) 查看CentOS内核版本 查看内核版本 12[root@node1 ~]# uname -r3.10.0-862.el7.x86_64 查看硬件架构 12[root@node1 ~]# uname -ix86_64 查看操作系统位数 12[root@node1 ~]# getconf LONG_BIT64]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建pip本地源]]></title>
    <url>%2F2018%2F06%2F23%2F%E6%90%AD%E5%BB%BApip%E6%9C%AC%E5%9C%B0%E6%BA%90.html</url>
    <content type="text"><![CDATA[准备工作 安装 pip 1# yum -y install python-pip 使用豆瓣pip源加快python包安装速度 123456# mkdir -p ~/.pip# vim ~/.pip/pip.conf[global]index-url = https://pypi.doubanio.com/simple[install]trusted-host=pypi.doubanio.com 下载Python包并生成索引创建软件包存放目录1# mkdir -p /home/pypi/packages 下载软件包 第一种方式：通过 pip 下载 12# pip download simplejson -d /home/pypi/packages # 单个python包下载# pip download -r requirements.txt -d /home/pypi/packages #批量下载 第二种方式：通过pip2pi下载软件包 安装 pip2pi 1# pip install pip2pi 下载软件包 12# pip2tgz /home/pypi/packages simplejson# pip2tgz /home/pypi/packages -r pip_requirements.txt 生成软件包索引 软件包下载到本地文件系统后，需要为全部软件包生成索引（Index），这样pip在安装查询时可以快速判断指定的依赖软件包是否存在于本地pip源中 1# dir2pi --normalize-package-names /home/pypi/packages dir2pi命令将会在 /home/pypi/packages 目录生成simple子目录，每个软件包在simple目录中都会生成对应子目录，目录名称为标准化后的软件包名。simple中每个以软件包名称命名的子目录下都会生成一个index.html文件 使用 pypiserver 搭建pip源pip 安装 pypiserver1# pip install pypiserver 启动 pypiserver1 # pypi-server -p 8080 /home/pypi/packages 注意，请确保端口号8080没有被占用，如被占用改用其他端口即可 升级目录下的所有包1# pypi-server -U /home/pypi/packages/ 使用本地pip源安装软件指定本地pip源安装1# pip install -i http://10.0.0.101/simple -r requirements.txt 配置本地pip源安装 配置本地pip源 12345# vim ~/.pip/pip.conf[global]index-url = http://10.0.0.101/simple[install]trusted-host=10.0.0.101 安装软件包 1# pip install -r requirements.txt]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip 离线安装]]></title>
    <url>%2F2018%2F06%2F23%2Fpip%20%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[安装 pip 指定包文件路径进行离线安装1# pip install --no-index /home/pypi/packages/simplejson-3.16.0.tar.gz –no-index：取消索引 以本地文件为pip源进行离线安装12# pip install package_name --no-index -f file:///home/pypi/packages/# pip install -r requirements.txt --no-index -f file:///home/pypi/packages/ –no-index：取消索引]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 VS Code 配置Python环境]]></title>
    <url>%2F2018%2F04%2F12%2F%E5%9C%A8%20VS%20Code%20%E9%85%8D%E7%BD%AEPython%E7%8E%AF%E5%A2%83.html</url>
    <content type="text"><![CDATA[配置Python环境 默认情况下，Python 扩展寻找并使用它在系统路径中找到的第一个 Python 解释器。 如果它没有找到解释器，它就会发出警告。 在 macOS 上，如果您使用的是安装在 os 上的 Python 解释器，扩展还会发出警告，因为您通常希望使用直接安装的解释器。 无论哪种情况，都可以通过在用户设置中将 python.disableInstallationCheck 设置为 true 来禁用这些警告。 要选择的解释器，请从命令选项板（⇧⌘P）调用Python：Select Interpreter命令 也可以单击状态栏选择解释器 Python: Select Interpreter 命令显示可用的全局环境、 conda 环境和虚拟环境的列表 注意: 在 Windows 上，VS 代码需要一点时间来检测可用的 conda 环境。 在此过程中，您可能会在环境的路径之前看到”(缓存)”。 该标签表明 VS Code 目前正在处理该环境的缓存信息。 从列表中选择的解释器后会自动添加 python.pythonPath （解释器的路径）条目到工作区设置中。 状态栏始终显示当前解释器 激活终端中的Python环境在编辑器中打开一个 .py 文件，并用 Terminal: Create New Integrated Terminal 命令打开终端，VS Code 会自动激活选定的Python环境。 提示: 为了防止自动激活选定的环境，可以在 settings.json 文件中添加”python.terminal.activateEnvironment”: false 使用 Python: Select Interpreter 命令更改解释器不会影响已经打开的终端面板。 提示: 在某个 Python 环境被激活的 shell 中启动 VS Code 并不会自动激活默认集成终端中选定的环境。 使用终端: 在运行 VS Code后创建新的集成终端命令即可自动激活选定的Python环境 选择Python调试环境默认情况下，Python.pythonPath 设置指定用于调试的 Python 解释器。 但是，如果在 launch.json 的调试配置中有 pythonPath 属性，则使用该解释器。 在决定使用哪个解释器进行调试时，VS Code 应用以下优先顺序: launch.json 中选定的调试配置 pythonPath 属性 工作区 settings.json 中的 python.pythonPath 属性 用户 settings.json 中的 python.pythonPath 属性查找Python环境的位置 Python扩展程序会自动在以下位置查找解释器 标准安装路径，例如/usr/local/bin，/usr/sbin，/sbin，c:\python27，c:\python36，等 工作空间（项目）文件夹下的虚拟环境 工作空间（项目）文件夹下的 .direnv 中的解释器 工作空间（项目）文件夹下的 pipenv 环境。如果找到一个解释器，那么就不会搜索其他解释器，因为pipenv希望管理环境的所有方面 pyenv 安装的解释器 conda环境中的Python解释器 python.venvPath设置的文件夹中的虚拟环境，可以包含多个虚拟环境。 该扩展程序在venvPath的第一级子文件夹中查找虚拟环境 如果VS Code未自动找到要使用的解释器，则可以在工作区 settings.json文件中手动设置路径 打开设置，选择工作区 添加或修改python.pythonPath的条目，填写Python可执行文件的完整路径（如果直接编辑settings.json，请将以下行添加到设置中）：1&quot;python.pythonPath&quot;: &quot;/home/python36/python&quot;, 可以使用 ${ env: VARIABLE }的语法在路径设置中使用环境变量 例如，如果你创建了一个名为 PYTHON_INSTALL_LOC 的变量，它有一个解释器的路径，你可以使用下面的设置值: 1&quot;python.pythonPath&quot;: &quot;$&#123;env:PYTHON_INSTALL_LOC&#125;&quot;, 通过使用环境变量，你可以很容易地使用不同路径在操作系统之间转移一个项目，只是在操作系统上设置环境变量即可。 环境变量定义文件环境变量定义文件是一个简单的文本文件，定义环境变量采用键值对的形式environment_variable=value，不支持多行值，并用 # 注释 扩展会加载由 python.envFile 设置的环境变量定义文件。 此设置的默认值为 ${workspaceFolder}/.env，即当前工作空间（项目）中的.env文件 可以修改用户设置settings.json 中的 python.envFile 配置 调试配置还包含一个envFile属性，也默认为当前工作空间中的.env文件 在开发 web 应用程序时，可能在开发服务器和生产服务器之间切换 可以将 python.envFile 设置为 ${workspaceolder}/prod.env 在调试配置中将 envFile 属性设置为 ${workspaceolder}/dev.env变量替换 在定义文件中定义一个环境变量时，你可以使用任何现有环境变量的值，使用以下一般语法: 1&lt;VARIABLE&gt;=...$&#123;EXISTING_VARIABLE&#125;... 其中… 表示值中的包含的其他文本适用以下规则 使用前必须先定义变量 单引号或双引号不会影响替换值，并包含在定义的值中 $字符可以使用反斜杠进行转义，如\ $ 只能使用简单的替换; 不支持嵌套 例如${_${OTHERVAR}_EX} 可以使用递归替换 例如PYTHONPATH=${PROJ_DIR}:${PYTHONPATH}（其中PROJ_DIR是任何其他环境变量） 语法不支持的条目保持原样PYTHONPATH 变量的使用 PYTHONPATH 环境变量指定了 Python 解释器应该寻找模块的其他位置。 PYTHONPATH 的值可以包含由 os.pathsep (Windows 上的分号，linux / macos 上的冒号)分隔的多个路径值，并且会忽略无效路径 注意: 必须通过操作系统设置 PYTHONPATH 变量，因为 VS Code 没有提供直接设置环境变量的方法。 建议将 PYTHONPATH 变量设置在环境变量定义文件中 注意: PYTHONPATH 不指定 Python 解释器本身的路径，因此不能在 Python.PYTHONPATH 设置中使用它]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查询端口被占用的情况]]></title>
    <url>%2F2018%2F04%2F02%2FLinux%20%E6%9F%A5%E8%AF%A2%E7%AB%AF%E5%8F%A3%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E6%83%85%E5%86%B5.html</url>
    <content type="text"><![CDATA[lsof -i:端口号 用于查看某一端口的占用情况123456[root@node1 ~]# lsof -i:22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 6622 root 3u IPv4 36215 0t0 TCP *:ssh (LISTEN)sshd 6622 root 4u IPv6 36224 0t0 TCP *:ssh (LISTEN)sshd 31358 root 3u IPv4 122192 0t0 TCP node1:ssh-&gt;192.168.46.1:64212 (ESTABLISHED)sshd 31914 root 3u IPv4 126124 0t0 TCP node1:ssh-&gt;192.168.46.1:62861 (ESTABLISHED) 如果提示 bash: lsof: command not found 则通过yum 安装后重试即可 1# yum install lsof -y lsof -i 查看所有被TCP和UDP使用的端口 123456789[root@node1 ~]# lsof -iCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 6622 root 3u IPv4 36215 0t0 TCP *:ssh (LISTEN)sshd 6622 root 4u IPv6 36224 0t0 TCP *:ssh (LISTEN)master 6965 root 13u IPv4 36605 0t0 TCP localhost:smtp (LISTEN)master 6965 root 14u IPv6 36606 0t0 TCP localhost:smtp (LISTEN)dhclient 10738 root 6u IPv4 44971 0t0 UDP *:bootpcsshd 31358 root 3u IPv4 122192 0t0 TCP node1:ssh-&gt;192.168.46.1:64212 (ESTABLISHED)sshd 31914 root 3u IPv4 126124 0t0 TCP node1:ssh-&gt;192.168.46.1:62861 (ESTABLISHED) netstat -tuln/tuan 查看所有被TCP和UDP使用的端口 1234567891011121314151617[root@node1 ~]# netstat -tulnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 0.0.0.0:22 0.0.0.0:* LISTENtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTENtcp6 0 0 :::22 :::* LISTENtcp6 0 0 ::1:25 :::* LISTENudp 0 0 0.0.0.0:68 0.0.0.0:*[root@node1 ~]# netstat -tuanActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 0.0.0.0:22 0.0.0.0:* LISTENtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTENtcp 0 0 192.168.46.133:22 192.168.46.1:64212 ESTABLISHEDtcp 0 0 192.168.46.133:22 192.168.46.1:62861 ESTABLISHEDtcp6 0 0 :::22 :::* LISTENtcp6 0 0 ::1:25 :::* LISTENudp 0 0 0.0.0.0:68 0.0.0.0:* netstat -tuln/tuan | grep 端口号，查看指定端口是否被TCP和UDP使用 1234567[root@node1 ~]# netstat -tuln | grep 22tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTENtcp6 0 0 :::22 :::* LISTEN[root@node1 ~]# netstat -tuan | grep 22tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTENtcp 0 0 192.168.46.133:22 192.168.46.1:64212 ESTABLISHEDtcp 0 0 192.168.46.133:22 192.168.46.1:62861 ESTABLISHED tcp6 0 0 :::22 ::: LISTEN*附录 lsof -i 常用参数介绍 123456-i 4 #ipv4地址-i 6 #ipv6地址-i tcp #tcp连接-i udp #udp连接-i :3306 #端口-i @ip #查看与某个ip地址建立的连接 netstat 常用的两组命令 12netstat -tulnnetstat -tuan netstat 常用参数介绍 12345-t (tcp) 仅显示tcp相关选项-u (udp)仅显示udp相关选项-n 拒绝显示别名，能显示数字的全部转化为数字-l 仅列出在Listen(监听)的服务状态-p 显示建立相关链接的程序名]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看 Linux 文件打开情况]]></title>
    <url>%2F2018%2F04%2F02%2F%E6%9F%A5%E7%9C%8B%20Linux%20%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E6%83%85%E5%86%B5.html</url>
    <content type="text"><![CDATA[Linux 下有哪些文件在介绍lsof命令之前，先简单说一下，linux主要有哪些文件： 普通文件 目录 符号链接 面向块的设备文件 面向字符的设备文件 管道和命名管道 套接字 lsof 命令实用用法介绍lsof，是list open files的简称 lsof输出各列信息的意义如下 123456789COMMAND：进程的名称 PID：进程标识符USER：进程所有者FD：文件描述符，应用程序通过文件描述符识别该文件。cwd 值表示应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改,txt 类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序。其次数值表示应用程序的文件描述符，这是打开该文件时返回的一个整数。u表示该文件被打开并处于读写模式，r表示该文件被打开并处于读模式，w表示该文件被打开并处于写模式，同时还有大写的W表示该应用程序具有对整个文件的写锁。初始打开每个应用程序时，都具有三个文件描述符，从 0 到 2，分别表示标准输入、输出和错误流。所以大多数应用程序所打开的文件的 FD 都是从 3 开始。TYPE：文件类型，文件和目录分别称为 REG 和 DIR。而CHR 和 BLK，分别表示字符和块设备；或者 UNIX、FIFO 和 IPv4，分别表示 UNIX 域套接字、先进先出 (FIFO) 队列和网际协议 (IP) 套接字。DEVICE：指定磁盘的名称SIZE：文件的大小NODE：索引节点（文件在磁盘上的标识）NAME：打开文件的确切名称 查看当前打开的所有文件一般来说，直接输入lsof命令产生的结果实在是太多，可能很难找到我们需要的信息。不过借此说明一下一条记录都有哪些信息。 123$ lsof（这里选取一条记录显示）COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEvi 27940 hyb 7u REG 8,15 16384 137573 /home/hyb/.1.txt.swp 从左往右分别代表：打开该文件的程序名，进程id，用户，文件描述符，文件类型，设备，大小，iNode号，文件名。这条记录，表明进程id为27940的vi程序，打开了文件描述值为7，且处于读写状态的，在/home/hyb目录下的普通文件(REG regular file).1.txt.swap，当前大小16384字节。 列出被删除但占用空间的文件在生产环境中，我们可能会使用df命令看到磁盘空间占满了，然而实际上又很难找到占满空间的文件，这常常是由于某个大文件被删除了，但是它却被某个进程打开，导致通过普通的方式找不到它的踪迹，最常见的就是日志文件。我们可以通过lsof来发现这样的文件： 123456$ lsof | grep deletedtuned 6621 root 8u REG 253,0 4096 17581562 /tmp/ffiLIRq9l (deleted)gmain 6621 7082 root 8u REG 253,0 4096 17581562 /tmp/ffiLIRq9l (deleted)tuned 6621 7083 root 8u REG 253,0 4096 17581562 /tmp/ffiLIRq9l (deleted)tuned 6621 7084 root 8u REG 253,0 4096 17581562 /tmp/ffiLIRq9l (deleted)tuned 6621 7097 root 8u REG 253,0 4096 17581562 /tmp/ffiLIRq9l (deleted) 可以看到这些被删除的但仍然被打开文件。这个时候就可以根据实际情况分析，到底哪些文件可能过大但是却被删除了，导致空间仍然占满。 恢复打开但被删除的文件我们可以找到被删除但是仍然被打开的文件，实际上文件并没有真正的消失，如果是意外被删除的，我们还有手段恢复它。以/var/log/cat文件为例，我们先删除它 1$ rm /var/log/syslog 使用lsof查看那个进程打开了该文件： 12$ lsof | grep syslogrs:main 993 1119 syslog 5w REG 8,10 78419 528470 /var/log/syslog (deleted) 可以找到进程id为993的进程打开了该文件，我们知道每个进程在/proc下都有文件描述符打开的记录： 12345678$ ll /proc/993/fdlr-x------ 1 root root 64 3月 5 18:30 0 -&gt; /dev/nulll-wx------ 1 root root 64 3月 5 18:30 1 -&gt; /dev/nulll-wx------ 1 root root 64 3月 5 18:30 2 -&gt; /dev/nulllrwx------ 1 root root 64 3月 5 18:30 3 -&gt; socket:[15032]lr-x------ 1 root root 64 3月 5 18:30 4 -&gt; /proc/kmsgl-wx------ 1 root root 64 3月 5 18:30 5 -&gt; /var/log/syslog (deleted)l-wx------ 1 root root 64 3月 5 18:30 6 -&gt; /var/log/auth.log 这里就找到了被删除的syslog文件，文件描述符是５，我们把它重定向出来： 123$ cat /proc/993/fd/5 &gt; syslog$ ls -al /var/log/syslog-rw-r--r-- 1 root root 78493 3月 5 19:22 /var/log/syslog 这样我们就恢复了syslog文件。 查看当前文件被哪些进程打开Windows下经常遇到要删除某个文件，然后告诉你某个程序正在使用，然而不告诉你具体是哪个程序。我们可以在资源管理器-性能-资源监视器-cpu-关联的句柄处搜索文件，即可找到打开该文件的程序，但是搜索速度感人。 linux就比较容易了，使用lsof命令就可以了，例如要查看当前哪些程序打开了hello.c: 123$ lsof hello.cCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEtail 28731 hyb 3r REG 8,15 228 138441 hello.c 但是我们会发现，使用vi打开的hello.c并没有找出来，这是因为vi打开的是一个临时副本。我们换一种方式查找： 123$ lsof | grep hello.ctail 28906 hyb 3r REG 8,15 228 138441 /home/hyb/workspaces/c/hello.cvi 28933 hyb 9u REG 8,15 12288 137573 /home/hyb/workspaces/c/.hello.c.swp 这样我们就找到了两个程序和hello.c文件相关。这里grep的作用是从所有结果中只列出符合条件的结果。 查看某个目录文件被打开情况1$ lsof +D ./ 查看当前进程打开了哪些文件使用方法：lsof -c 进程名 通常用于程序定位问题，例如用于查看当前进程使用了哪些库，打开了哪些文件等等。假设有一个循环打印字符的hello程序： 12345678910$ lsof -c helloCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEhello 29190 hyb cwd DIR 8,15 4096 134538 /home/hyb/workspaces/chello 29190 hyb rtd DIR 8,10 4096 2 /hello 29190 hyb txt REG 8,15 9816 138314 /home/hyb/workspaces/c/hellohello 29190 hyb mem REG 8,10 1868984 939763 /lib/x86_64-linux-gnu/libc-2.23.sohello 29190 hyb mem REG 8,10 162632 926913 /lib/x86_64-linux-gnu/ld-2.23.sohello 29190 hyb 0u CHR 136,20 0t0 23 /dev/pts/20hello 29190 hyb 1u CHR 136,20 0t0 23 /dev/pts/20hello 29190 hyb 2u CHR 136,20 0t0 23 /dev/pts/20 我们可以从中看到，至少它用到了/lib/x86_64-linux-gnu/libc-2.23.so以及hello文件。也可以通过进程id查看，可跟多个进程id，使用逗号隔开： 12345678910$ lsof -p 29190COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEhello 29190 hyb cwd DIR 8,15 4096 134538 /home/hyb/workspaces/chello 29190 hyb rtd DIR 8,10 4096 2 /hello 29190 hyb txt REG 8,15 9816 138314 /home/hyb/workspaces/c/hellohello 29190 hyb mem REG 8,10 1868984 939763 /lib/x86_64-linux-gnu/libc-2.23.sohello 29190 hyb mem REG 8,10 162632 926913 /lib/x86_64-linux-gnu/ld-2.23.sohello 29190 hyb 0u CHR 136,20 0t0 23 /dev/pts/20hello 29190 hyb 1u CHR 136,20 0t0 23 /dev/pts/20hello 29190 hyb 2u CHR 136,20 0t0 23 /dev/pts/20 当然这里还有一种方式，就是利用proc文件系统，首先找到hello进程的进程id: 123$ ps -ef | grep hellohyb 29190 27929 0 21:14 pts/20 00:00:00 ./hello 2hyb 29296 28848 0 21:18 pts/22 00:00:00 grep --color=auto hello 可以看到进程id为29190，查看该进程文件描述记录目录：1234$ ls -l /proc/29190/fdlrwx------ 1 hyb hyb 64 3月 2 21:14 0 -&gt; /dev/pts/20lrwx------ 1 hyb hyb 64 3月 2 21:14 1 -&gt; /dev/pts/20lrwx------ 1 hyb hyb 64 3月 2 21:14 2 -&gt; /dev/pts/20 这种方式能够过滤很多信息，因为它只列出了该进程实际打开的，这里它只打开了1,2,3，即标准输入，标准输出和标准错误。 查看某个用户打开了哪些文件linux是一个多用户操作系统，怎么知道其他普通用户打开了哪些文件呢？可使用-u参数 12$ lsof -u hyb（内容太多，省略） 列出除了某个进程或某个用户打开的文件实际上和前面使用方法类似，只不过，在进程id前面或者用户名前面加^，例如： 12$ lsof -p ^1 #列出除进程id为１的进程以外打开的文件$ lsof -u ^root #列出除root用户以外打开的文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH 常用操作]]></title>
    <url>%2F2018%2F03%2F01%2FSSH%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C.html</url>
    <content type="text"><![CDATA[CentOS的版本号信息一般存放在配置文件当中，在CentOS中，与其版本相关的配置文件中都有centos关键字，该文件一般存放在/etc/目录下，所以说我们可以直接在该文件夹下搜索相关的文件 口令登录1# ssh user@host 如：ssh pika@192.168.0.111 SSH的publish key和private key都是自己生成的，没法公证。只能通过Client端自己对公钥进行确认。通常在第一次登录的时候，系统会出现下面提示信息： 1Are you sure you want to continue connecting (yes/no)? yes 如果输入yes后，会出现下面信息： 12Warning: Permanently added 'ssh-server.example.com,12.18.429.21' (RSA) to the list of known hosts. Password: (enter password) 该host已被确认，并被追加到文件known_hosts中，然后就需要输入密码进行登录 免密登录12# ssh-keygen -t rsa# ssh-copy-id -i ~/.ssh/id_rsa.pub user@host 然后输入密码即可，其实就是将本地的公钥写入到远程主机的~/.ssh/authorized_keys文件中替代方法1 12# cat ~/.ssh/id_rsa.pub # 本地主机查看公钥# echo &lt;paste-your-key-here&gt; &gt;&gt; ~/.ssh/authorized_keys # 远程主机写入公钥 替代方法2 12# scp ~/.ssh/id_rsa.pub user@host:/root # 本地主机拷贝公钥搭到远程主机# cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys # 远程主机写入公钥 远程主机重装系统后，需要删除known_hosts保存的host key12# vim ~/.ssh/known_hosts# 找到对应的记录，然后按dd known_hosts中存储是已认证的远程主机host key，每个SSH Server都有一个secret, unique ID, called a host key。 复制文件到远程主机1# scp ./ubuntu/text.txt user@host:/home/ -r 递归复制整个目录 参考 图解SSH原理 https://www.jianshu.com/p/33461b619d53]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门08 — 模块]]></title>
    <url>%2F2018%2F01%2F22%2FPython%E5%85%A5%E9%97%A808%20%E2%80%94%E6%A8%A1%E5%9D%97.html</url>
    <content type="text"><![CDATA[模块是一个包含所有你定义的函数和变量的文件，其后缀名是.py。模块可以被别的程序引入，以使用该模块中的函数等功能。 创建模块要创建模块，可创建一个.py文件，在其中包含用于完成任务的函数。 案例（保存为 mymodule.py）： 1234def say_hi(): print('Hi, this is mymodule speaking.')__version__ = '0.1 正如你所看见的，与我们一般所使用的 Python 的程序相比其实并没有什么特殊的区别。 导入模块import 语句想使用 Python 源文件，只需在另一个源文件里执行 import 语句，语法如下： 1import module1[, module2[,... moduleN] 另一个模块（保存为 mymodule_demo.py）： 1234import mymodulemymodule.say_hi()print('Version', mymodule.__version__) 输出： 123$ python mymodule_demo.pyHi, this is mymodule speaking.Version 0.1 Python解释器是怎样找到对应的文件的呢？ Python 解释器将从它的 sys.path 变量所提供的目录中进行搜索。如果找到了对应模块，则该模块中的语句将在开始运行，并能够为你所使用。 sys.path 内包含了导入模块的字典名称列表。你能观察到 sys.path 的第一段字符串是空的——这一空字符串代表当前目录也是 sys.path 的一部分，它与 PYTHONPATH 环境变量等同。这意味着你可以直接导入位于当前目录的模块。否则，你必须将你的模块放置在 sys.path 内所列出的目录中。 另外要注意的是当前目录指的是程序启动的目录。你可以通过运行 import os; print(os.getcwd()) 来查看你的程序目前所处在的目录。 from…import 语句Python的from语句让你从模块中导入一个指定的部分到当前命名空间中，语法如下： 1from modname import name1[, name2[, ... nameN]] 下面是一个使用 from...import 语法的范本（保存为 mymodule_demo2.py）： 1234from mymodule import say_hi, __version__say_hi()print('Version', __version__) mymodule_demo2.py 所输出的内容与 mymodule_demo.py 所输出的内容是一样的。 在这里需要注意的是，如果导入到 mymodule 中的模块里已经存在了 __version__ 这一名称，那将产生冲突。这可能是因为每个模块通常都会使用这一名称来声明它们各自的版本号。因此，我们大都推荐最好去使用 import 语句，尽管这会使你的程序变得稍微长一些。 警告：一般来说，你应该尽量避免使用 from...import 语句，而去使用 import 语句。这是为了避免在你的程序中出现名称冲突，同时也为了使程序更加易读。 你还可以使用： 1from mymodule import * 这将导入诸如 say_hi 等所有公共名称，但不会导入 __version__ 名称，因为后者以双下划线开头。 警告：要记住你应该避免使用 import-star 这种形式，即 from mymodule import *。 Python 之禅 Python 的一大指导原则是“明了胜过晦涩”。你可以通过在 Python 中运行 import this 来了解更多内容。 按字节码编译的 .pyc 文件导入一个模块是一件代价高昂的事情，因此 Python 引入了一些技巧使其能够更快速的完成。其中一种方式便是创建按字节码编译的（Byte-Compiled）文件，这一文件以 .pyc 为其扩展名，是将 Python 转换成中间形式的文件。这一 .pyc 文件在你下一次从其它不同的程序导入模块时非常有用——它将更加快速，因为导入模块时所需要的一部分处理工作已经完成了。同时，这些按字节码编译的文件是独立于运行平台的。 注意：这些 .pyc 文件通常会创建在与对应的 .py 文件所处的目录中。如果 Python 没有相应的权限对这一目录进行写入文件的操作，那么 .pyc 文件将不会被创建。 模块的 __name__模块除了函数和和变量外，还可以包括可执行的代码，一般用来初始化这个模块。当模块第一次被导入时，它所包含的代码将被执行。 每个模块都有一个名称，而模块中的语句可以找到它们所处的模块的名称。默认情况下当模块第一次被导入时，它所包含的代码将被执行。如果我们想在模块被引入时，模块中的某一程序块不执行，我们可以用__name__属性来使该程序块仅在该模块自身运行时执行。 案例（保存为 module_using_name.py）： 1234if __name__ == '__main__': print('This program is being run by itself')else: print('I am being imported from another module') 输出： 1234567$ python module_using_name.pyThis program is being run by itself$ python&gt;&gt;&gt; import module_using_nameI am being imported from another module&gt;&gt;&gt; 每一个 Python 模块都定义了它的 __name__ 属性。如果它与 __main__ 属性相同则代表这一模块是由用户独立运行的，因此我们便可以采取适当的行动。 dir 函数内置的 dir() 函数能够返回由对象所定义的名称列表。 如果这一对象是一个模块，则该列表会包括函数内所定义的函数、类与变量。 如果参数是模块名称，函数将返回这一指定模块的名称列表。 如果没有提供参数，函数将返回当前模块的名称列表。 案例： 1234567891011121314151617181920212223$ python&gt;&gt;&gt; import sys# 给出 sys 模块中的属性名称&gt;&gt;&gt; dir(sys)['__displayhook__', '__doc__', '__excepthook__', '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__', '__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames', '_debugmallocstats', '_enablelegacywindowsfsencoding', '_getframe', '_git', '_home', '_xoptions', 'api_version', 'argv', 'base_exec_prefix', 'base_prefix', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dllhandle', 'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info', 'float_repr_style', 'get_asyncgen_hooks', 'get_coroutine_wrapper', 'getallocatedblocks', 'getcheckinterval', 'getdefaultencoding', 'getfilesystemencodeerrors', 'getfilesystemencoding', 'getprofile', 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval', 'gettrace', 'getwindowsversion', 'hash_info', 'hexversion', 'implementation', 'int_info', 'intern', 'is_finalizing', 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'set_asyncgen_hooks', 'set_coroutine_wrapper', 'setcheckinterval', 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr', 'stdin', 'stdout', 'thread_info', 'version', 'version_info', 'warnoptions', 'winver']# only few entries shown here# 给出当前模块的属性名称&gt;&gt;&gt; dir()['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'sys']# 创建一个新的变量 'a'&gt;&gt;&gt; a = 5&gt;&gt;&gt; dir()['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'a', 'sys']# 删除或移除一个名称&gt;&gt;&gt; del a&gt;&gt;&gt; dir()['__annotations__', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'sys'] 要注意被导入进来的模块所能生成的列表也会是这一列表的一部分。 关于 del 的一个小小提示——这一语句用于删除一个变量或名称，当这一语句运行后，在本例中即 del a，你便不再能访问变量 a——它将如同从未存在过一般。 包现在，你必须开始遵守用以组织你的程序的层次结构。变量通常位于函数内部，函数与全局变量通常位于模块内部。如果你希望组织起这些模块的话，应该怎么办？这便是包（Packages）应当登场的时刻。 包是指一个包含模块与一个特殊的 __init__.py 文件的文件夹，后者向 Python 表明这一文件夹是特别的，因为其包含了 Python 模块。 建设你想创建一个名为“world”的包，其中还包含着 ”asia“、”africa“等其它子包，同时这些子包都包含了诸如”india“、”madagascar“等模块。 下面是你会构建出的文件夹的结构： 12345678910111213- &lt;some folder present in the sys.path&gt;/ - world/ - __init__.py - asia/ - __init__.py - india/ - __init__.py - foo.py - africa/ - __init__.py - madagascar/ - __init__.py - bar.py 包是一种能够方便地分层组织模块的方式。你将在 标准库中看到许多有关于此的实例。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门07 — 函数]]></title>
    <url>%2F2018%2F01%2F21%2FPython%E5%85%A5%E9%97%A807%20%E2%80%94%20%E5%87%BD%E6%95%B0.html</url>
    <content type="text"><![CDATA[函数（Functions）是指可重复使用的程序片段。它是有名字的代码块，接受输入、提供输出并可存储在文件中供以后使用。你通过这一特殊的名字在你的程序任何地方来运行代码块，并可重复任何次数。 定义函数Python 定义函数使用 def 关键字，一般格式如下： 12def 函数名 (参数列表): 函数体 函数头 第1行（以def打头的那行）被称为函数头。 函数头总是以关键字def（definition的缩写）打头，接下来是一个空格，然后是函数名。 函数名后面是一对圆括号，其中可以包括参数列表，也可以不包括参数列表。 与循环和if语句一样，函数头也以冒号:结尾。 给函数命名 与变量名一样，函数名也只能包含字母、数字和下划线_，且不能以数字打头。 函数体 函数头后面所有缩进的代码被称为函数体。 可选的文档字符串，用三引号标识文档字符串的开始和结束位置。 你需要完成的工作的代码块。在这个代码块中，可使用函数头中的变量。 最后，函数应使用关键字return返回一个值。 文档字符串一种格式约定 Python文档字符串通常遵循一种标准格式约定：用三引号标识文档字符串的开始和结束位置；第1行是函数的简要描述，对程序员很有帮助；接下来是详情和示例。 文档字符串的其他好处 与内置函数一样，你也可轻松地查看自己编写的函数的文档字符串。如查看下面我们定义的计算圆面积的函数 area： 123456&gt; &gt;&gt;&gt; print(area.__doc__)&gt; Returns the area of a circle with the given radius.&gt; For example:&gt; &gt;&gt;&gt; area(5.5)&gt; 95.033177771091246&gt; Python还有一个很有用的工具——doctest，可用于自动运行文档字符串中的Python示例代码。这是一种不错的代码测试方式，还可帮助确保文档准确地描绘了函数。更详细的信息请参阅http://docs.python.org/3/ library/ doctest.html。 提示 函数并非必须包含return语句，如果函数没有包含return语句，Python将认为它以return None结束。这很常见：函数常被用于执行返回值无关紧要的任务，如在屏幕上打印输出。 下面是一个计算圆面积的函数： 123456789# area.pydef area(radius): """ Returns the area of a circle with the given radius. For example: &gt;&gt;&gt; area(5.5) 95.033177771091246 """ return 3.14 * radius ** 2 上面这个函数是带有参数的，下面我们再举一个不带参数的函数： 123# say_hello.pydef say_hello(): print('hello world') 调用函数文章开头我们在说明什么是函数的时候说过，函数是有名字的代码块，允许你通过函数名在你的程序任何地方来运行函数，这就是所谓的调用（Calling）函数。 请看内置函数pow(x, y)，它计算x ** y，即x的y次方： 12&gt;&gt;&gt; pow(2, 5)32 其中，pow是函数名，2和5是传递给pow的实参，32是返回值。当你在表达式中调用函数时，Python将函数调用替换为其返回值，例如，表达式pow(2, 5) + 8与32 + 8等价，结果为40。 计算幂 pow(x, y)与x ** y等价。在Python中，pow(0, 0)（还有0 ** 0）的值为1。这一点一直存在争议，有些数学家认为，pow(0, 0)的值应该不确定或未定义；但其他一些数学家认为，将pow(0, 0)定义为1更合乎逻辑。Python显然支持后一种观点。 即便函数不接受任何输入（即没有参数），也必须在函数名后添加圆括号()： 12&gt;&gt;&gt; dir()['__builtins__', '__doc__', '__name__', '__package__'] ()让Python执行指定的函数，如果省略()，输出将如下： 12&gt;&gt;&gt; dir&lt;built-in function dir&gt; 省略了()时，Python不执行函数，而告诉你dir指向一个函数。 不返回值的函数 有些函数（如print）不返回值。请看下述代码： 12345&gt;&gt;&gt; x = print('hello')hello&gt;&gt;&gt; x&gt;&gt;&gt; print(x)None 这里将特殊值None赋给了变量x。None表明“无返回值”：它既不是字符串，也不是数字，因此你不能用它来做任何有意义的计算。 给函数名赋值 你必须小心，以避免无意间让内置函数名指向其他函数或值。不幸的是，Python并不会阻止你编写类似下面的代码： 12345678&gt;&gt;&gt; dir = 3&gt;&gt;&gt; dir3&gt;&gt;&gt; dir()Traceback (most recent call last): File "&lt;pyshell#28&gt;", line 1, in &lt;module&gt; dir()TypeError: 'int' object is not callable 这里让dir指向了数字3，导致你再也无法访问dir原来指向的函数！要恢复原样，需要重启Python。 函数参数函数中的参数通过将其放置在用以定义函数的一对圆括号中指定，并通过逗号予以分隔。当我们调用函数时，我们以同样的形式提供需要的值。要注意在此使用的术语——在定义函数时给定的名称称作“形参”（Parameters），在调用函数时你所提供给函数的值称作“实参”（Arguments）。 参数传递向函数传递参数时，Python采用按引用传递的方式。这意味着当你传递参数时，函数将使用新变量名来引用原始值。 案例（保存为 reference.py）： 123456# reference.pydef add(a, b): return a + bx, y = 3, 4print(add(x, y)) 输出： 12$ python reference.py7 在设置x和y后，内存类似于下图1所示。当调用add(x,y)时，Python创建两个新变量——a和b，它们分别指向x和y的值，如图2所示。注意到没有复制实参的值，而只是给它们指定新名称，而函数将使用这些新名称来引用它们。将a和b相加后，函数返回，而a和b被自动删除。在整个函数调用过程中，x和y未受影响。 图1 将x和y分别设置为3和4后的内存状态 图2 刚调用add(x,y)后的内存状态：a和b分别指向x和y指向的值 按值传递 有些编程语言（如C++）可按值传递参数。按值传递参数时，将创建其拷贝，并将该拷贝传递给函数。如果传递的值很大，复制可能消耗大量时间和内存。Python不支持按值传递。 按引用传递简单而高效，但有些事情它做不了。例如，请看下面这个名不副实的函数： 1234567# reference.pydef set1(x): x = 1m = 5set1(m)print(m) # 输出 5 输出： 12$ python reference.py5 函数set1想将传入的变量的值设置为1，但如果你尝试运行它，结果并不符合预期： m的值根本没变，太令人意外了。这都是按引用传递导致的。为帮助理解，将这个示例分解成下面几步： 将5赋给m。 调用set1(m)：将m的值赋给x，这样m和x都指向5。 将1赋给x，结果如下图所示。 函数set1结束后，x被删除。 参数类型必选参数 在函数调用的时候必需传入与函数定义时数量相同的参数，并且参数顺序也要一致。 案例（保存为 function_require.py）： 1234567# function_require.pydef add(x, y): # x, y 是必选参数 return x + yprint(add(1, 2)) # 数量一致，通过print(add()) # 一个参数都不传，报错# print(add(1)) # 只传了一个参数，报错 输出： 123456$ python function_require.py3Traceback (most recent call last): File "reference.py", line 6, in &lt;module&gt; print(add()) # 一个参数都不传，报错TypeError: add() missing 2 required positional arguments: 'x' and 'y' 默认参数 默认参数是指在定义函数的时候提供一些默认值，如果在调用函数的时候没有传递该参数，则自动使用默认值，否则使用传递时该参数的值。你可以通过在函数定义时附加一个赋值运算符（=）来为参数指定默认参数值。 提示 默认参数要放在所有必选参数的后面。这是因为值是按参数所处的位置依次分配的。 默认参数应该使用不可变对象。 案例（保存为 function_default.py）： 123456# function_require.pydef say(message, times=1): print(message * times)say('Hello')say('World', 5) 输出： 123$ python function_default.pyHelloWorldWorldWorldWorldWorld 可变参数 在某些情况下，我们在定义函数的时候，无法预估函数应该有多少个参数，也就是参数数量是可变的。为了能让一个函数接受任意数量的位置参数，可以使用一个* 参数。 案例（保存为 function_varargs.py）： 12345def avg(first, *rest): return (first + sum(rest)) / (1 + len(rest)) print(avg(1, 2)) print(avg(1, 2, 3, 4)) 输出： 123$ python function_varargs.py1.52.5 关键字参数 关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。 案例（保存为 function_keyword.py）： 12345678# function_keyword.pydef func(a, b): print('a is', a, 'and b is', b)func(3, 7)func(67, b=12)func(a=15, b=42)func(b=50, a=100) 输出： 12345$ python function_keyword.pya is 3 and b is 7a is 67 and b is 12a is 15 and b is 42a is 100 and b is 50 关键字参数有两大好处 首先，它们清晰地指出了参数值，有助于提高程序的可读性；其次，关键字参数的顺序无关紧要。 提示 关键参数要放在所有必选参数的后面。 变量作用域函数带来的一个重要问题是作用域。变量的作用域指的是它在程序的哪些地方可访问或可见。 局部变量 首次赋值发生在函数内的变量被称为局部变量，同时函数的参数也被视为局部变量。 下面就是一个局部变量的例子： 1234# function_local.pydef add(x, y): sum = x + y return sum 函数add有3个局部变量——x、y、sum。 全局变量 在函数外面声明的变量称为全局变量，程序中的任何函数或代码都可读取它。要访问全局变量，必须使用关键字global ，因为在不使用 global 语句的情况下，不可能为一个定义于函数之外的变量赋值。 案例（保存为 function_global.py）： 123456789101112# function_global.pyx = 50def func(): global x print('x is', x) x = 2 print('Changed global x to', x)func()print('Value of x is', x) 输出： 1234$ python function_global.pyx is 50Changed global x to 2Value of x is 2 要在函数func中范围全局变量x必须使用关键字global 。 如果不使用关键字global ，访问的将会是局部变量。 案例（保存为 function_local.py）： 12345678910# function_local.pyx = 50def func(x): print('local x is', x) x = 2 print('Changed local x to', x)func(x)print('global x is still', x) 输出： 1234$ python function_local.pylocal x is 50Changed local x to 2global x is still 50]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门05 — 运算符与表达式]]></title>
    <url>%2F2018%2F01%2F19%2FPython%E5%85%A5%E9%97%A805%20%E2%80%94%20%E8%BF%90%E7%AE%97%E7%AC%A6%E4%B8%8E%E8%A1%A8%E8%BE%BE%E5%BC%8F.html</url>
    <content type="text"><![CDATA[运算符是进行某些操作，并且可以用诸如 + 等符号或特殊关键词加以表达的功能。运算符需要一些数据来进行操作，这些数据就被称作操作数。表达式可以拆分成运算符与操作数。一个表达式的简单例子便是 2+3，其中 2 和 3 被称为操作数，”+“ 称为运算符。 算术运算符 +（加） 两个对象相加。 3+5 则输出 8。&#39;a&#39; + &#39;b&#39; 则输出 &#39;ab&#39;。 -（减） 从一个数中减去另一个数，如果第一个操作数不存在，则假定为零。 -5.2 将输出一个负数，50 - 24 输出 26。 *（乘） 给出两个数的乘积，或返回字符串重复指定次数后的结果。 2 * 3 输出 6。&#39;la&#39; * 3 输出 &#39;lalala&#39;。 ** （乘方） 返回 x 的 y 次方。 3 ** 4 输出 81 （即 3 * 3 * 3 * 3）。 / （除） x 除以 y 13 / 3 输出 4.333333333333333。 -13.5 / 3 输出 -4.5。 // （整除） x 除以 y 并对结果 向下取整 至最接近的整数。 13 // 3 输出 4。 -13 // 3 输出 -5。 -13.5 / 3 输出 -5.0。 % （取模） 返回除法运算后的余数，被除数-(除数*整除的商)。 13 % 3 输出 1。-25.5 % 2.25 输出 1.5。 -13.5 % 3 输出 1.5。1.5 = -13.5-(3*-5) 关系运算符 &lt; （小于） 返回 x 是否小于 y。 5 &lt; 3 输出 False，3 &lt; 6 输出 True。 &gt; （大于） 返回 x 是否大于 y。 5 &gt; 3 返回 True。 &lt;= （小于等于） 返回 x 是否小于或等于 y。 x = 3; y = 6; x&lt;=y 返回 True。 &gt;= （大于等于） 返回 x 是否大于或等于 y。 x = 4; y = 3; x&gt;=3 返回 True。 == （等于） 比较两个对象是否相等。 x = 2; y = 2; x == y 返回 True。 x = &#39;str&#39;; y = &#39;stR&#39;; x == y 返回 False。 x = &#39;str&#39;; y = &#39;str&#39;; x == y 返回 True。 != （不等于） 比较两个对象是否不相等。 x = 2; y = 3; x != y 返回 True。 提示 所有的比较运算符返回的结果均为 True 或 False。 提示 比较可以任意组成组成链接。 123456789101112&gt;&gt;&gt; 3 &lt; 5 &lt; 7True&gt;&gt;&gt; 3 &lt; 5 &gt; 7False&gt;&gt;&gt; 3 &lt; 5 &gt; 4True&gt;&gt;&gt; 7 &lt;= 6 &gt;= 5False&gt;&gt;&gt; 7 &gt;= 6 == 6True&gt;&gt;&gt; 7 &gt;= 6 == 6 &lt; 9 &gt; 2True 赋值运算符 = （赋值） 简单的赋值运算符。 x = 2; y = 3; 。 += （加法赋值） 加法赋值运算符。 x += 2; 等价于 x = x + 2 。 -= （减法赋值） 减法赋值运算符。 x -= 2; 等价于 x = x - 2 。 *= （乘法赋值） 乘法赋值运算符。 x *= 2; 等价于 x = x * 2 。 /= （除法赋值） 除法赋值运算符。 x /= 2; 等价于 x = x / 2 。 //= （整除赋值） 整除赋值运算符。 x //= 2; 等价于 x = x // 2 。 %= （取模赋值） 取模赋值运算符。 x %= 2; 等价于 x = x % 2 。 **= （幂赋值） 幂赋值运算符。 x **= 2; 等价于 x = x ** 2 。 提示 变量 = 变量 运算 表达式 等价于 变量 运算 = 表达式。 逻辑运算符 not （逻辑“非”） 如果 x 是 True，则返回 False。如果 x 是 False，则返回 True。 x = True; not x 返回 False。 and （逻辑“与”） 如果 x 是 False，则 x and y 返回 False，否则返回 y 的计算值。 当 x 是 False 时，x = False; y = True; x and y将返回 False。 or（逻辑“或”） 如果 x 是 True，则返回 True，否则它将返回 y 的计算值。 x = True; y = False; x or y 将返回 True。 提示 逻辑运算 存在中“短路”现象：仅计算逻辑表达式中的一部分便能确定结果，而不对整个表达式进行计算的现象。逻辑与和逻辑或都存在短路现象，比如x = False; x and y将返回 False，而不会计算 y，因为它已经能确定整个表达式将是 False 而不会是别的值。同理x = True; x or y 将返回 Ture，而不会计算 y。 位运算符 &amp; （按位与） 对数字进行按位与操作。 5 &amp; 3 输出 1。 5 用二进制数表示为 0101， 3 用二进制数表示为 0011，按位与会得到 0001 ，表示成十进制为 1。 | （按位或） 对数字进行按位或操作。 5 | 3 输出 7。5 用二进制数表示为 0101， 3 用二进制数表示为 0011，按位与会得到 0111 ，表示成十进制为 7。 ^（按位异或） 对数字进行按位异或操作。 5 ^ 3 输出 6。5 用二进制数表示为 0101， 3 用二进制数表示为 0011，按位与会得到 0110 ，表示成十进制为 6。 ~ （按位取反） x 的按位取反结果为 -(x+1)。 ~5 输出 -4。有关本例的更多细节可以参阅：http://stackoverflow.com/a/11810203 。 &lt;&lt; （左移） 将数字的位向左移动指定的位数。（每个数字在内存中以二进制数表示，即 0 和1） 2 &lt;&lt; 2 输出 8。 2 用二进制数表示为 10，向左移 2 位会得到 1000 ，表示成十进制为 8。 &gt;&gt; （右移） 将数字的位向右移动指定的位数。 11 &gt;&gt; 1 输出 5。11 在二进制中表示为 1011，右移一位后输出 0101 这一结果，表示成十进制为5。 成员运算符 in （包含） 如果在指定的序列中找到值返回 True，否则返回 False。 &#39;a&#39; in &#39;abc&#39; 输出为True，&#39;d&#39; in &#39;abc&#39; 输出为False。 not in （不包含） 如果在指定的序列中没有找到值返回 True，否则返回 False。 &#39;a&#39; not in &#39;abc&#39; 输出为False，&#39;d&#39; not in &#39;abc&#39; 输出为True。 身份运算符 is 判断两个标识符是不是引用自同一个对象。 a = 20; b = 20; a is b; 输出为 True，引用自同一个对象。 is not 判断两个标识符是不是引用自不同对象。 a = [1, 2, 3]; b = a[:]; b is not a; ， 输出为 True，不是引用自同一个对象。 提示 is 与 == 区别：is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等。 1234567891011&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; b is aTrue&gt;&gt;&gt; b == aTrue&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; b is aFalse&gt;&gt;&gt; b == aTrue 运算符优先级为了保持完整，下表是从 Python 参考手册 中引用而来。你最好使用圆括号操作符来对运算符与操作数进行分组，以更加明确地指定优先级。这也能使得程序更加可读。 lambda：Lambda 表达式 if - else ：条件表达式 or：布尔“或” and：布尔“与” not x：布尔“非” in, not in, is, is not, &lt;, &lt;=, &gt;, &gt;=, !=, ==：比较，包括成员资格测试（Membership Tests）和身份测试（Identity Tests）。 |：按位或 ^：按位异或 &amp;：按位与 &lt;&lt;, &gt;&gt;：移动 +, -：加与减 *, /, //, %：乘、除、整除、取余 +x, -x, ~x：正、负、按位取反 **：求幂 x[index], x[index:index], x(arguments...), x.attribute：下标、切片、调用、属性引用 (expressions...), [expressions...], {key: value...}, {expressions...}：显示绑定或数组、显示列表、显示字典、显示设置 在上表中位列同一行的运算符具有相同优先级。例如 + 和 -就具有相同的优先级。 改变运算顺序为了使表达式更加易读，我们可以使用括号。举个例子，2 + (3 * 4) 自是要比 2 + 3 * 4 要更加容易理解，因为后者还要求你要了解运算符的优先级。和其它的一切一样，使用括号同样也要适度（而不要过度），同时亦应不要像 (2 + (3 * 4))这般冗余。 使用括号还有一个额外的优点——它能帮助我们改变运算的顺序。同样举个例子，如果你希望在表达式中计算乘法之前应先计算加法，那么你可以将表达式写作 (2 + 3) * 4。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门04 — Python基础知识]]></title>
    <url>%2F2018%2F01%2F18%2FPython%E5%85%A5%E9%97%A804%20%E2%80%94%20Python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%20.html</url>
    <content type="text"><![CDATA[打印出 hello world 只是我们学习Python的第一步，但是仅仅打印出 hello world 肯定不能满足我们的需求，你可能会希望做得更多，比如写一个小脚本帮你抢火车票，接下来我们会介绍一些基本概念。 注释任何时候，我们都可以给程序加上注释来解释代码，这样当自己或别人阅读的时候可以很容易的理解你的程序是做什么的。而程序运行的时候，Python解释器会直接忽略掉所有的注释。虽然有没有注释都不影响程序的执行结果，但是影响到别人能不能看懂你的代码。 Python的注释以#开头，后面的文字直到行尾都算注释 举个例子： 1print('hello world') #注意到 print 是一个函数 或者： 12# 注意到 print 是一个函数print('hello world') 你应该在你的程序中尽可能多地使用 有用 的注释： 解释假设 说明重要的决定 解释重要的细节 说明你想要解决的问题 说明你想要在程序中克服的问题，等等。 代码会告诉你怎么做，注释会告诉你为何如此。 缩进Python的一个与众不同之处是，使用缩进来 标识代码块。要在Python中标识代码块，必须以同样程度缩进代码块的每一行。在其他大多数编程语言中，缩进只用于让代码更美观；但在Python中，必须使用缩进来指出语句所属的代码块。 下面是一个例子： 1234i = 5# 下面将发生错误，注意行首有一个空格 print('Value is', i)print('I repeat, the value is', i) 当你运行这一程序时，你将得到如下错误： 12345 File "whitespace.py", line 3 print('Value is', i) ^IndentationError: unexpected indent# 缩进错误：意外缩进 提示 缩进量很重要，在Python语句块中，多一个或少一个空格都可能导致错误或意外行为。在同一个代码块中，所有语句的缩进量必须相同。 提示 Python 语言官方的建议使用四个空格来缩进。 标识符命名标识符（Identifiers） 是为 某些东西 提供的给定名称，比如变量，函数、模块和类等。在你命名标识符时，你需要遵守以下规则： 第一个字符必须是字母或下划线（_）。 标识符的其它部分可以由字母、下划线（_）、数字（0~9）组成。 标识符名称区分大小写。例如，myname 和 myName 并不等同。 不能将Python关键字用作变量名。例如，if、else、while、def、or、and、not、in和is都是Python关键字。 合法和非法的变量名 合法变量名 非法变量名 M m x1 1x tax_rate tax rate taxRate taxRate! Else else 变量在Python中，变量的概念基本上和初中代数的方程变量是一致的。 例如，对于方程式 y=x*x，x就是变量。当x=2时，计算结果是4，当x=5时，计算结果是25。 只是在计算机程序中，变量不仅可以是数字，还可以是任意数据类型。 比如： 1a = 1 变量a是一个整数。 1b = 'T007' 变量b是一个字符串。 1c = True 变量c是一个布尔值True。 变量名的命名规则参考 标识符命名。 常量常量就是不能改变的变量，比如数学常数π就是一个常量。在Python中，通常用全部大写的变量名表示常量： 1PI = 3.14 但事实上PI仍然是一个变量，Python根本没有任何机制保证PI不会被改变，只能由我们自己保证，如果我们不小心改变了常量的值将会导致意想不到的错误。 字面常量（Literal Constants）—— 故名思议就是它字面意义上的值或是内容，比如 5、1.23这样的数字，或者是如 &#39;This is a string&#39; 这样的文本。 基本数据类型计算机顾名思义就是可以做数学计算的机器，因此，计算机程序理所当然地可以处理各种数值。但是，计算机能处理的远不止数值，还可以处理文本、图形、音频、视频、网页等各种各样的数据，不同的数据，需要定义不同的数据类型。下面将介绍几种基本的数据类型。 整数整数是不带小数部分的数字，如25、-86 和 0。 Python对整数的长度没有限制，你可以执行数十位甚至数百数千位的整数运算 12&gt;&gt;&gt; 27 ** 100136891479058588375991326027382088315966463695625337436471480190078368997177499076593800206155688941388250484440597994042813512732765695774566001 针对有经验的程序员的提示 没有单独的 long 类型。int 类型可以指任何大小的整数。 浮点数在Python中，浮点数是带小数点的数字，例如 3.23 或 52.3E4。其中，E 表示 10 的幂。在这里，52.3E4 表示 52.3 * 10^4。 与整数不同，浮点数存在上限和下限，超出上限或下限将导致溢出错误。溢出错误意味着计算结果太大或太小，Python无法将其表示为浮点数。面对溢出错误，Python可能沉默不语，即继续执行错误的计算，而不告诉你出了问题。一般而言，避免溢出错误的职责由程序员承担。 12345&gt;&gt;&gt; 500.0 ** 10000Traceback (most recent call last): File "&lt;pyshell#7&gt;", line 1, in &lt;module&gt; 500.0 ** 10000OverflowError: (34, 'Result too large') 无论在哪种计算机上，浮点数都可能存在精度损失。在计算机中，数字用二进制（基数为2）表示，但并非所有浮点数都可用二进制精确地表示。例如： 12&gt;&gt;&gt; 1 - 2 / 30.33333333333333337 结果应该是小数点后面有无穷个3，但这里只包含17位。另外，最后一位也不对——应该是3而不是7。 提示 一般而言，应优先考虑使用整数而不是浮点数，因为它们更精确且绝不会溢出。 字符串字符串是一系列字符，如&quot;cat!&quot;、&quot;567-45442&quot;和&quot;Up and Down&quot;。字符包括字母、数字、标点符号以及数百个其他的特殊符号和不可打印的字符。 表示字符串字面量 在Python中，可使用下列3种主要方式来表示字符串字面量。 单引号，如&#39;openhouse&#39;。 双引号，如&quot;What&#39;s your name?&quot;。 三引号，&quot;&quot;&quot;http&quot;&quot;&quot; 或 &#39;&#39;&#39;http&#39;&#39;&#39; 来指定多行字符串。 提示 单引号和双引号的一个主要用途是，让你能够在字符串中包含字符&quot;和&#39;。 123&gt; "It's great"&gt; 'She said "Yes!"'&gt; 提示 在需要创建多行的长字符串时，三引号很有用。在使用三引号括起的字符串中，还可包含字符&quot;和&#39;。 123456&gt; '''这是一段多行字符串。这是它的第一行。&gt; 这是它的第二行.&gt; "What's your name?," I asked.&gt; He said "Bond, James Bond."&gt; '''&gt; 提示 &#39;&#39;、&quot;&quot; 、 &quot;&quot;&quot; 或 &#39;&#39;&#39;本身只是一种表示方式，不是字符串的一部分 转义字符 并非所有字符都有可视的标准符号。例如，换行字符、回车字符和制表符都是不可见的，虽然它们带来的效果可见。这些字符属于空白字符——在印刷页面上显示为空白。 为处理空白字符以及其他不可打印的字符，Python使用一种特殊表示法——转义字符。下表列出了最常用的转义字符。 字符 含义 \\ 反斜杠 \&#39; 单引号 \&quot; 双引号 \n 换行符 \r 回车 \t 水平制表符 要在字符串中包含反斜杠、单引号和双引号，通常需要使用对应的转义字符。例如： 1234&gt;&gt;&gt; print('\' and \" are quotes')' and " are quotes&gt;&gt;&gt; print('\\ must be written \\\\')\ must be written \\ 在Python中，表示换行的标准方式是使用字符\n： 1234&gt;&gt;&gt; print('one\ntwo\nthree')onetwothree 提示 转义字符是单个字符，只是为让Python知道下一个字符是特殊字符，所以必须使用\，但在计算字符串的长度时，并不将\视为额外的字符。 原始字符串 如果你需要指定一些未经过特殊处理的字符串，比如转义序列，那么你需要在字符串前增加 r 或 R 来指定一个 原始（Raw） 字符串。下面是一个例子： 1234&gt;&gt;&gt; print('\\\t\\')\ \&gt;&gt;&gt; print(r'\\\t\\')\\\t\\ 针对正则表达式用户的提示 在处理正则表达式时应全程使用原始字符串。否则，将会有大量 Backwhacking 需要处理。 举例说明的话，反向引用可以通过 &#39;\\1&#39; 或 r&#39;\1&#39; 来实现。 针对 C/C++ 程序员的提示 Python 中没有单独的 char 数据类型，它并非切实必要。 针对 Perl/PHP 程序员的提示 记住单引号括起的字符串和双引号括起的字符串是一样的——它们不存在任何区别。 布尔值布尔值和布尔代数的表示完全一致，一个布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来。 12345678&gt;&gt;&gt; TrueTrue&gt;&gt;&gt; FalseFalse&gt;&gt;&gt; 3 &gt; 2True&gt;&gt;&gt; 3 &gt; 5False 空值空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 赋值语句赋值语句包含3个主要部分：左值、赋值运算符和右值。如下图所示 提示 左值必须是变量，而右值可以是变量、值或结果为值的任何表达式。 赋值语句有两个用途： 定义新的变量； 让已定义的变量指向特定值。 例如： 1234&gt;&gt;&gt; x = 5&gt;&gt;&gt; 2 * x + 111&gt;&gt;&gt; x = 'ABC' 第一条赋值语句（x = 5）完成了两项职责，是一条初始化语句。它让Python创建新变量x，并将值5赋给它。然后，在可以使用整数的任何地方，都可使用变量x了。 第二条赋值语句（x = ABC）给x重新赋值，让它指向另一个值。它没有创建变量x，因为这个变量已经存在，这是前一条赋值语句的功劳。 针对 C/C++ 程序员的提示 Python 是动态语言，变量本身类型不固定的，所以同一个变量可以反复赋值，而且可以是不同类型。C/C++ 是静态语言。静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。 变量如何引用值对于x = expr这样的Python赋值语句，可以这样解读：让x指向表达式expr的值。expr可以是任何结果为值的Python表达式。 为帮助理解一系列赋值语句，一种不错的方式是绘制示意图。 例如： 12345678&gt;&gt;&gt; x = 'ABC'&gt;&gt;&gt; y = x&gt;&gt;&gt; x = '123'&gt;&gt;&gt; print(x)123&gt;&gt;&gt; print(y)ABC&gt;&gt;&gt; 执行语句 x = &#39;ABC&#39; 后，可以认为计算机的内存类似于图1所示。接下来，执行语句 y = x 后，计算机内存类似于图2所示。最后，执行语句 x = &#39;123&#39; 后，计算机内存类似于图3所示。 对于没有任何变量指向的值，Python自动将其删除。一般而言，Python跟踪所有的值，并自动删除不再有变量指向的值。这称为垃圾收集，因此Python程序员很少需要为删除值操心。 赋值时不复制赋值语句并不会复制指向的值，而只是标记和重新标记既有值。因此，无论变量指向的对象有多大、多复杂，赋值语句的效率都非常高。 数字和字符串是不可变的在Python中，数字和字符串的一个重要特征是不可变，即不能以任何方式修改它们。在看起来是修改数字或字符串的情况下，Python实际上是在创建修改版本的拷贝。 1234567&gt;&gt;&gt; s = 'apple'&gt;&gt;&gt; s + 's''apples'&gt;&gt;&gt; s'apple'&gt;&gt;&gt; 5 = 1SyntaxError: can't assign to literal 多重赋值在Python中，有一种便利的技巧，让你能够同时给多个变量赋值： 123456789&gt;&gt;&gt; x, y, z = 1, 'two', 3.0&gt;&gt;&gt; x1&gt;&gt;&gt; y'two'&gt;&gt;&gt; z3.0&gt;&gt;&gt; x, y, z(1, 'two', 3.0) 还可以在一行显示多个值，方法是将它们作为元组。元组总是以左圆括号(开始，以右圆括号)结尾。 交换变量的值 多重赋值的一个很实用的用途是交换两个变量的值： 123456&gt;&gt;&gt; a, b = 5, 9&gt;&gt;&gt; a, b(5, 9)&gt;&gt;&gt; a, b = b, a&gt;&gt;&gt; a, b(9, 5) 语句a, b = b, a的含义是，同时给变量a和b赋值。 如果不使用多重赋值，将两个变量的值互换的标准方式如下： 123456&gt;&gt;&gt; a, b = 5, 9&gt;&gt;&gt; temp = a&gt;&gt;&gt; a = b&gt;&gt;&gt; b = temp&gt;&gt;&gt; a, b(9, 5) 多重赋值的功能并不比常规赋值多，它只是一种偶尔使用的比较便利的快捷方式。 对象需要记住的是，Python 将程序中的任何内容统称为 对象（Object）。这是一般意义上的说法。我们以“某某对象（object）”相称，而非“某某东西（something）”。 针对面向对象编程语言用户的提示： Python 是强（Strongly）面向对象的，因为所有的一切都是对象， 包括数字、字符串与函数。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门03 — Hello World]]></title>
    <url>%2F2018%2F01%2F11%2FPython%E5%85%A5%E9%97%A803%20%E2%80%94%20Hello%20World.html</url>
    <content type="text"><![CDATA[现在让我们开始学习如何运行一个传统的“Hello World”程序，这基本上是学习任何编程语言的需要做的第一步。下面将会告诉你如何编写、保存与运行 Python 程序。 通过 Python 来运行的你的程序有两种方法 使用交互式解释器提示符 直接运行一个源代码文件 使用解释器提示符在你的操作系统中打开终端（Terminal）程序，然后通过输入 python3 并按下 [enter] 键来打开 Python 提示符（Python Prompt）。 当你启动 Python 后，你会看见在你能开始输入内容的地方出现了 &gt;&gt;&gt; 。这个被称作 Python 解释器提示符（Python Interpreter Prompt） 。 在 Python 解释器提示符，输入print(&quot;Hello World&quot;)，在输入完成后按下 [enter] 键。你将会看到屏幕上打印出 Hello World 字样。 1234567xuepengdeMacBook-Pro:~ geekspeng$ python3Python 3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28)[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print("Hello World")Hello World&gt;&gt;&gt; 如何退出解释器提示符 如果你正在使用一款 GNU/Linux 或 OS X 上的 Shell 程序，你可以通过按下 [ctrl + d] 组合键或是输入 exit() （注意：要记住要包含括号 ()）并敲下 [enter] 来退出解释器提示符。 如果你使用的是 Windows 命令提示符，可以按下 [ctrl + z]组合键并敲击 [enter] 键来退出。 直接运行一个源代码文件选择一款编辑器当我们希望运行某些程序时，总不能每次都在解释器提示符中输入我们的程序。因此我们需要将它们保存为文件，从而我们便可以多次地运行这些程序。要想创建我们的 Python 源代码文件，我们需要一款能够让你输入并保存代码的编辑器软件。 对编辑器的两项基本要求 语法高亮 通过标以不同颜色来帮助你区分 Python 程序中的不同部分，从而能够让你更好 看清 你的程序，并使它的运行模式更加形象化。 文本自动缩进 Python的一个与众不同之处是，使用缩进来 标识代码块。要在Python中标识代码块，必须以同样程度缩进代码块的每一行。在其他大多数编程语言中，缩进只用于让代码更美观；但在Python中，必须使用缩进来指出语句所属的代码块。所以编辑器如果支持文本自动缩进的话，能减少大量我们花在手动缩进上的时间。 编辑器推荐 初学者 推荐你使用 PyCharm 教育版 软件，它在 Windows、Mac OS X、GNU/Linux 上都可以运行，从而你只需要专注于学习 Python 而不是编辑器。 熟悉Vim 或 Emacs的程序员 那你一定在用 Vim 或 Emacs 了。无需多言，它们都是最强大的编辑器之一，用它们来编写你的 Python 程序自是受益颇多。 1. PyCharm PyCharm 教育版是一款能够对你编写 Python 程序的工作有所帮助的免费编辑器。 当你打开 PyCharm 时，你会看见如下界面，点击 Create New Project ： 选择 Pure Python ： 将你的项目路径位置中的 untitled 更改为 helloworld ，你所看到的界面细节应该类似于下方这番： 点击 Create 按钮。 对侧边栏中的 helloworld 右击选中，并选择 New -&gt; Python File ： 你会被要求输入名字，现在输入 hello ： 现在你便可以看见一个新的文件已为你开启： 删除那些已存在的内容，现在由你自己输入以下代码： 1print("hello world") 现在右击你所输入的内容（无需选中文本），然后点击 Run &#39;hello&#39; 。 此刻你将会看到你的程序所输出的内容（它所打印出来的内容）： 虽然只是刚开始的几个步骤，但从今以后，每当我们要求你创建一个新的文件时，记住只需在 helloworld 上右击并选择 -&gt; New -&gt; Python File 并继续如上所述步骤一般输入内容并运行即可。 2. Vim 安装 Vim Mac OS X 应该通过 HomeBrew 来安装 macvim 包。 Windows 用户应该通过 Vim 官方网站 下载“自安装可执行文件”。 GNU/Linux 用户应该通过他们使用的发行版的软件仓库获取 Vim。例如 Debian 与 Ubuntu 用户可以安装 vim 包。 安装 jedi-vim 插件为 Vim 增添自动完成功能。 安装与之相应的 jedi Python 包：pip install -U jedi 3. Emacs 安装Emacs 24+ Mac OS X 用户应该从 http://emacsformacosx.com 获取 Emacs。 Windows 用户应该从 http://ftp.gnu.org/gnu/emacs/windows/ 获取 Emacs。 GNU/Linux 用户应该从他们使用的发行版的软件仓库获取 Emacs。如 Debian 和 Ubuntu 用户可以安装 emacs24 包。 安装 ELPY。 使用终端运行源代码文件要想运行你的 Python 程序： 打开终端窗口 使用 cd 命令来改变目录到你保存文件的地方。 通过输入命令 python3 hello.py 来运行程序。程序的输出结果应如下方所示： 12$ python3 hello.pyhello world]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Mac</tag>
        <tag>Python</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门02 — Python安装及开发环境配置]]></title>
    <url>%2F2018%2F01%2F10%2FPython%E5%85%A5%E9%97%A802%20%E2%80%94%20Python%E5%AE%89%E8%A3%85%E5%8F%8A%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE.html</url>
    <content type="text"><![CDATA[Python 是一款易于学习且功能强大的编程语言。 它具有高效率的数据结构，能够简单又有效地实现面向对象编程。Python 简洁的语法与动态输入之特性，加之其解释性语言的本质，使得它成为一种在多种领域与绝大多数平台都能进行脚本编写与应用快速开发工作的理想语言。这篇文章主要介绍Python在Mac OS X、Windows和Linux系统的安装，为以后python的学习做准备。 在Mac OS X 系统中安装Mac OS X自带并安装了一个Python版本，但该版本没有IDLE编辑器，通常也不是最新版本，需要安装最新版本 对于 Mac OS X 用户，你可以使用 Homebrew 并通过命令 brew install python3 进行安装，如果你还没有安装Homebrew，可以参考Mac OS X 包管理工具 Homebrew 安装与使用 也可以下载一个安装程序并运行它 要想验证安装是否成功，你可以通过按键 [Command + Space]（以启动 Spotlight 搜索），输入 Terminal 并按下 [enter]键来启动终端程序。现在，试着运行 python3 来确保其没有任何错误 12345xuepengdeMacBook-Pro:~ geekspeng$ python3Python 3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28)[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; 在Windows系统中安装 访问Python下载页面www.python.org/download并下载最新的版本python（32位选择Windows x86 executable installer，64位选择 Windows x86-64 executable installer），目前最新版本为3.6.4 双击安装程序安装python，其安装过程与其它 Windows 平台的软件的安装过程无异，请务必确认勾选了Add Python 3.5 to PATH 选项 要想验证安装是否成功，你可以通过点击开始并点击 运行 。在对话中输入 cmd 并按下回车键。然后，输入 python 以确保其没有任何错误。如果输出与Mac一样，说明Python运行正常 补充说明 如未勾选相关选项，你可以点击 Add Python to environment variables 。它和安装程序第一屏的 Add Python 3.5 to PATH能起到相同效果。如果这个也忘记勾选也不要紧，只需要参考下面步骤手动添加环境变量即可 若要想改变安装位置，勾选 Customize installation 选项，点击 Next 后在安装位置中输入 C:\python36 手动添加环境变量 对于 Windos 7 与 8： 在桌面右击计算机并选择 属性 或点击 开始 并选择 控制面板 → 系统与安全 → 系统 。点击左侧的 高级系统设置 并选择 高级 标签。点击底部 系统变量 下的 环境变量 ，找到 PATH 属性，将其选中并点击 编辑 在最后一行并添加Python安装的路径，比如;C:\Python36 点击 确定 以完成操作。你不需要进行重启，不过你可能需要关闭并重启命令提示符 ​ 在Linux系统中安装如果你使用的是Linux，很可能已经安装了Python。要确认这一点，可打开命令行窗口并输入python验证。对于 GNU/Linux 用户，你可以使用发行版的包管理器来安装 Python 3，例如在 Debian 与 Ubuntu 平台下，你可以输入命令：sudo apt-get update &amp;&amp; sudo apt-get install python3 要想验证安装是否成功，你可以通过打开 Terminal 应用或通过按下 Alt + F2 组合键并输入 gnome-terminal 来启动终端程序。如果这不起作用，请查阅你所使用的的 GNU/Linux 发行版的文档。现在，运行 python3 命令来确保其没有任何错误。如果输出与Mac一样，说明Python运行正常]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Mac</tag>
        <tag>Python</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python入门01 — Python语言简介]]></title>
    <url>%2F2018%2F01%2F09%2FPython%E5%85%A5%E9%97%A801%20%E2%80%94%20Python%E8%AF%AD%E8%A8%80%E7%AE%80%E4%BB%8B.html</url>
    <content type="text"><![CDATA[Python 是一种极少数能兼具 简单 与 功能强大 的编程语言。你将惊异于发现你正在使用的这门编程语言是如此简单，它专注于如何解决问题，而非拘泥于语法与结构。 官方对 Python 的介绍如下： Python 是一款易于学习且功能强大的编程语言。 它具有高效率的数据结构，能够简单又有效地实现面向对象编程。Python 简洁的语法与动态输入之特性，加之其解释性语言的本质，使得它成为一种在多种领域与绝大多数平台都能进行脚本编写与应用快速开发工作的理想语言。 名字的由来Python是Guido van Rossum（吉多·范罗苏姆）在1989年圣诞节期间，为了打发无聊的圣诞节而编写的一个编程语言，他采用 BBC 电视节目《蒙提·派森的飞行马戏团（Monty Python’s Flying Circus，一译巨蟒剧团）》的名字来为这门编程语言命名。 Python 的特点 简单 Python 是一门简单且简约的语言。阅读一份优秀的 Python 程序代码就如同在阅读英语文章一样，Python 这种伪代码式的特质正是它的一大优势。它能够让你专注于解决问题的方案，而不是语言本身。 易于学习 Python 是一门非常容易入门的语言，Python 有一套极其简单的语法体系。 免费开源 Python 是 FLOSS （自由/开放源代码软件）的成员之一。简单来说，你可以自由地分发这一软件的拷贝，阅读它的源代码，并对其作出改动，或是将其的一部分运用于一款新的自由程序中。FLOSS 基于一个可以分享知识的社区理念而创建。 高级语言 当你在用 Python 编写程序时，你不必考虑诸如你的程序应当如何使用内存等底层细节。 跨平台 由于其开放源码的特性，Python 已被移植到其它诸多平台（意即它们已经过改动以保证其能正常工作）。如果你小心地避开了所有系统依赖型的特性，那么你所有的 Python 程序不必作任何改动就可以在其中任何一个平台上工作。 解释性 一个用编译性语言比如C/C++写的程序在运行前需要通过编译器翻译成计算机能执行的机器码。而解释性语言比如Python写的程序在运行前不需要编译成机器码，而是先由Python解释器将源代码转换成称为字节码的中间形式，在运行时再把它翻译成计算机能理解的机器码。这一流程使得 Python 更加易于使用，你不必再担心该如何编译程序，或如何保证适当的库被正确的链接并加载等等步骤。这也同样使得 Python 程序更便携且易于移植，你只需要将 Python 程序拷贝到另一台电脑便可让它立即开始工作！ 面向对象 Python 同时支持面向过程编程与面向对象编程。在面向过程的语言中，程序是由过程或仅仅是可重用代码的函数构建起来的。在面向对象的语言中，程序是由数据和功能组合而成的对象构建起来的。 可扩展性 如果你需要代码的某一重要部分能够快速地运行，或希望算法的某些部分不被公开，你可以在 C/C++ 语言中编写这些程序，然后再将其运用于你的 Python 程序中。 可嵌入性 你可以在你的 C/C++ 程序中嵌入 Python，从而向你的程序用户提供 脚本 功能 丰富的库 实际上 Python 标准库的规模非常庞大。它能够帮助你完成诸多事情，包括正则表达式、文档生成、单元测试、多线程、数据库、网页浏览器、CGI、FTP、邮件、XML、XML-RPC、HTML、WAV 文件、密码系统、GUI（图形用户界面），以及其它系统依赖型的活动。 Python的缺点 运行速度慢 和 C/C++ 程序相比非常慢，因为Python是解释型语言，你的代码在执行时会一行一行地翻译成计算机能理解的机器码，这个翻译过程非常耗时，所以很慢。而 C/C++ 程序是运行前直接编译成CPU能执行的机器码，所以非常快。但是，除了像视频高清解码等计算密集型任务对运行速度有较高的要求外，在大部分时候，我们可能并不需要非常快的运行速度。 代码不能加密 如果要发布你的Python程序，实际上就是发布源代码，这一点跟C/C++语言不同，C/C++语言不用发布源代码，只需要把编译后的机器码（也就是你在Windows上常见的xxx.exe文件）发布出去。要从机器码反推出C代码是不可能的，所以，凡是编译型的语言，都没有这个问题，而解释型的语言，则必须把源码发布出去。这个缺点仅限于你要编写的软件需要卖给别人挣钱的时候。好消息是目前的互联网时代，靠卖软件授权的商业模式越来越少了，靠网站和移动应用卖服务的模式越来越多了，后一种模式不需要把源码给别人。 ​ Python 适合做什么 脚本开发 这些简短的程序自动执行常见的管理任务，如在系统中新增用户、将文件上传到网站、在不使用浏览器的情况下下载网页等。 网站开发 不少大型网站都是使用 Python 作为后台开发语言的，比如 YouTube、Pinterest、国内的豆瓣和知乎等。 文本处理 Python在字符串和文本文件处理方面提供了强大的支持，包括正则表达式和Unicode。 科学计算 网上有很多卓越的Python科学计算库，提供了用于统计、数学计算和绘图的函数。 机器学习 有不少知名的机器学习库也是使用 Python 开发的，比如，scikit-learn 是一个强大的机器学习库，Theano 是一个成熟的深度学习库。 教育 鉴于Python简洁实用，越来越多的学校将其作为第一门编程教学语言。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac OS X 包管理工具 Homebrew 安装与使用]]></title>
    <url>%2F2018%2F01%2F08%2FMac%20OS%20X%20%E5%8C%85%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[Homebrew 是Mac OS 下的包管理工具，类似于Ubuntu下的apt-get命令，通过这个工具我们可以快速获取所需要的软件而不需要像在Windows系统中那样打开浏览器，找到需要下载的安装包，然后才能进行下载。Homebrew拥有安装、卸载、更新、查看、搜索等很多实用的功能。通过一条简单的指令，就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。 Homebrew 能干什么? 使用 Homebrew 安装 Apple 没有预装但 你需要的东西 Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local Homebrew 不会将文件安装到它本身目录之外，所以您可将 Homebrew 安装到任意位置 轻松创建你自己的 Homebrew 包 完全基于 git 和 ruby，所以自由修改的同时你仍可以轻松撤销你的变更或与上游更新合并 Homebrew 的配方都是简单的 Ruby 脚本 Homebrew 使 macOS 更完整。使用 gem 来安装 gems、用 brew 来安装那些依赖包 Homebrew 安装1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 安装homebrew后报错-bash: brew: command not found 的解决方法 其实解决这个问题真的很简单。如下： 1vim ~/.bash_profile 添加下面一行 1export PATH=/usr/local/bin:$PATH 保存，执行下面命令使配置生效 1source ~/.bash_profile 重新打开命令行工具，再次使用brew 命令就ok了 Homebrew 基本使用安装任意包 1$ brew install &lt;package_name&gt; 卸载任意包 1$ brew uninstall &lt;packageName&gt; 更新 Homebrew 在服务器端上的包目录 1$ brew update 查看你的包是否需要更新 1$ brew outdated 更新包 1$ brew upgrade &lt;package_name&gt; 查询可用的包 1$ brew search &lt;packageName&gt; 查看你安装过的包列表（包括版本号） 1$ brew list --versions 查看任意包信息 1$ brew info &lt;packageName&gt; 查看帮助信息 1$ brew -h Homebrew 将会把老版本的包缓存下来，以便当你想回滚至旧版本时使用。但这是比较少使用的情况，当你想清理旧版本的包缓存时，可以运行： 1$ brew cleanup 使用 homebrew-bundle 备份软件列表备份软件列表 1$ brew bundle dump --describe --force --file="~/Desktop/Brewfile" 参数说明： --describe：为列表中的命令行工具加上说明性文字。 --force：直接覆盖之前生成的Brewfile文件。如果没有该参数，则询问你是否覆盖。 --file=&quot;~/Desktop/Brewfile&quot;：在指定位置生成文件。如果没有该参数，则在当前目录生成 Brewfile 文件。 批量安装软件 1$ brew bundle --file="~/Desktop/Brewfile" 替换 Homebrew 源默认官方的更新源都是存放在GitHub上的，这也是中国大陆用户访问缓慢的原因，一般来说我们会更倾向选择国内提供的更新源，在此推荐中国科大以及清华大学提供的更新源。Homebrew的更新源由三部分组成：本体（brew.git）、核心（homebrew-core.git）以及二进制预编译包（homebrew-bottles）。从.git的后缀名可以看出，Homebrew的更新源是以Git仓库的形式存在的，所以需要用到Git。也正是如此，使得可以对其进行克隆，成为新源。 配置镜像源 123456789101112131415161718192021222324# 替换brew.git:$ cd "$(brew --repo)"# 中国科大:$ git remote set-url origin https://mirrors.ustc.edu.cn/brew.git# 清华大学:$ git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git# 替换homebrew-core.git:$ cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"# 中国科大:$ git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git# 清华大学:$ git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git# 替换homebrew-bottles:# 中国科大:$ echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles' &gt;&gt; ~/.bash_profile$ source ~/.bash_profile# 清华大学:$ echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles' &gt;&gt; ~/.bash_profile$ source ~/.bash_profile# 应用生效:$ brew update 重置 Homebrew 源1234567# 重置brew.git:$ cd "$(brew --repo)"$ git remote set-url origin https://github.com/Homebrew/brew.git# 重置homebrew-core.git:$ cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"$ git remote set-url origin https://github.com/Homebrew/homebrew-core.git 至于homebrew-bottles，推荐直接去修改.bash_profile文件删除 HOMEBREW_BOTTLE_DOMAIN 那一行。 Homebrew CaskHomebrew Cask 由社区进行维护，因此它有更多，更丰富的软件，我们可以通过Homebrew Cask 优雅、简单、快速的安装和管理 OS X 图形界面程序，比如 Google Chrome 和 Evernote。 安装 安装 Homebrew-cask 是如此的简单直接，运行以下命令即可完成： 1234$ brew tap caskroom/cask // 添加 Github 上的 caskroom/cask 库$ brew install brew-cask // 安装 brew-cask$ brew update &amp;&amp; brew upgrade brew-cask &amp;&amp; brew cleanup // 更新 $ brew cask install google-chrome // 安装 Google 浏览器 搜索 如果你想查看 cask 上是否存在你需要的 app，可以到 caskroom.io进行搜索。 文件预览插件 有些 插件 可以让 Mac 上的文件预览更有效，比如语法高亮、markdown 渲染、json 预览等等。 123456789$ brew cask install qlcolorcode$ brew cask install qlstephen$ brew cask install qlmarkdown$ brew cask install quicklook-json$ brew cask install qlprettypatch$ brew cask install quicklook-csv$ brew cask install betterzipql$ brew cask install webp-quicklook$ brew cask install suspicious-package OS X 图形界面程序 123456789$ brew cask install alfred$ brew cask install appcleaner$ brew cask install cheatsheet$ brew cask install dropbox$ brew cask install google-chrome$ brew cask install onepassword$ brew cask install sublime-text$ brew cask install totalfinder... CakebrewMac下Homebrew的图形化界面工具Cakebrew 安装 1$ brew cask install cakebrew 如果不能下载直接上官网下载dmg包进行安装]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>包管理工具</tag>
        <tag>Homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 必备设置和必装软件]]></title>
    <url>%2F2017%2F12%2F18%2FCentos7%20%E5%BF%85%E5%A4%87%E8%AE%BE%E7%BD%AE%E5%92%8C%E5%BF%85%E8%A3%85%E8%BD%AF%E4%BB%B6.html</url>
    <content type="text"><![CDATA[必备设置安全设置（可选） 创建用户并赋予sudo权限1234567# id root # 查看 root 用户所属 group# useradd -g 0 geekspeng # 新建用户，-g 指明所属group,与root保持一致# passwd geekspeng # 设置密码# visudo # 或者 vim /etc/sudoers 文件内容改变如下： root ALL=(ALL) ALL 已有行 geekspeng ALL=(ALL) ALL 新增行 限制远程登陆 123# vim /etc/ssh/sshd_config PermitRootLogin no # 禁用root用户登录# service sshd restart # 重启ssh服务以使更改生效 如果新用户设置了免密登录（参考下一节）也可以禁用密码登录（可选） 12# vim /etc/ssh/sshd_config PasswordAuthentication no # 禁用密码登录 基础设置 免密登录 1# ssh-copy-id -i ~/.ssh/id_rsa.pub user@host 修改 CentOS7 默认 yum 源 123# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup # 备份系统自带yum源配置文件# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo # 下载aliyun的yum源# yum makecache # 生成缓存 centos8curl -o /etc/yum.repos.d/CentOS-Base.repohttps://mirrors.aliyun.com/repo/Centos-8.repocentos7 arm 架构curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-altarch-7.repo -O /etc/yum.repos.d/CentOS-Base.repo centos镜像-centos下载地址-centos安装教程-阿里巴巴开源镜像站 (aliyun.com) 安装EPEL的yum源123# yum -y install epel-release # 安装epel的yum源# cd /etc/yum.repo.d/ # 进入yum源配置文件所在的文件夹# ls # 安装完成后查看是否生成epel.repo和epel-testing.repo文件 epel.repo #正式版，所有的软件都是稳定可以信赖的epel-testing.repo #测试版，使用时需要慎重 修改EPEL的yum源123# mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backup # 备份EPEL的yum源配置文件# curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo # 下载aliyun EPEL的yum源# yum makecache # 生成缓存 centos8sed -i ‘s|^#baseurl=https://download.fedoraproject.org/pub|baseurl=https://mirrors.aliyun.com|‘ /etc/yum.repos.d/epelsed -i ‘s|^metalink|#metalink|’ /etc/yum.repos.d/epel 使用豆瓣pip源123456# mkdir -p ~/.pip# vim ~/.pip/pip.conf[global]index-url = https://pypi.doubanio.com/simple[install]trusted-host=pypi.doubanio.com 必装软件 net-tools、wget、vim、git 1# yum -y install net-tools wget vim git bash-completion 如果提示没有pip，需要安装pip 1# yum -y install python-pip]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网（二）：极路由配置Shadowsocks]]></title>
    <url>%2F2017%2F12%2F15%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E6%9E%81%E8%B7%AF%E7%94%B1%E9%85%8D%E7%BD%AEShadowsocks.html</url>
    <content type="text"><![CDATA[上一篇讲了如何在 AWS 云服务器上搭建 Shadowsocks服务器从而实现科学上网，这篇我们主要讲怎么在极路由上配置Shadowsocks，从而使连上这台路由器的设备都可以轻松地访问goolge等网站而不需在所有需要科学上网的设备上进行配置。 Shadowsocks客户端安装通过hiwifi-ss开源项目我们可以轻松的在极路由安装Shadowsocks客户端。 首先电脑WiFi连接到极路由，由于需要从网上下载Shadowsocks客户端，所以请确保极路由能连上网（插上网线或者作为无线中继）。 然后我们通过SSH登录到极路由的控制台，我使用的MAC默认带有SSH，如果没有SSH请自行百度安装，端口号默认使用的是1022，这里需要输入WiFi密码 12xuepengdeMBP:~ geekspeng$ ssh root@hiwifi.com -p 1022root@hiwifi.com&apos;s password: 登录成功后会显示下面的信息 123456789101112BusyBox v1.22.1 (2017-08-10 17:53:48 CST) built-in shell (ash)Enter &apos;help&apos; for a list of built-in commands.*********************************************************** __ __ _ _ ____ _ TM / / / / (_) _ __ (_) / __/ (_) / /_/ / / / | | /| / / / / / /_ / / / __ / / / | |/ |/ / / / / __/ / / /_/ /_/ /_/ |__/|__/ /_/ /_/ /_/ http://www.hiwifi.com/***********************************************************root@Hiwifi:~# 最后安装Shadowsocks客户端 1.新版hiwifi =&gt; 使用项目根目录下的 shadow.sh 脚本进行安装, 建议使用以下一键命令: 1cd /tmp &amp;&amp; curl -k -o shadow.sh https://raw.githubusercontent.com/qiwihui/hiwifi-ss/master/shadow.sh &amp;&amp; sh shadow.sh &amp;&amp; rm shadow.sh 2.hiwifi 1.2.5.15805s 1cd /tmp &amp;&amp; curl -k -o shadow.sh https://raw.githubusercontent.com/qiwihui/hiwifi-ss/master/shadow.sh &amp;&amp; sh shadow.sh 12515805s &amp;&amp; rm shadow.sh Shadowsocks账号设置在浏览器中登录极路由后台，完成配置后，点击开关开启即可，如果一切正常，下方状态会显示连接正常]]></content>
      <categories>
        <category>科学上网</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
        <tag>Shadowsocks</tag>
        <tag>极路由</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网（一）：在 AWS 云服务器上搭建 Shadowsocks]]></title>
    <url>%2F2017%2F12%2F14%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9C%A8%20AWS%20%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%90%AD%E5%BB%BA%20Shadowsocks.html</url>
    <content type="text"><![CDATA[身为程序员平时遇到问题当然需要上网查找资料，普通人首先想到的肯定是百度，但是百度上面给的答案良莠不齐质量不高，这个时候就要借助Goolge，但是由于某些我们都懂的原因在国内我们却访问不了Goolge，这时候我就需要自备梯子。网上虽然有很多免费的服务器可以使用，但是通常质量不会很高，极不稳定，速度也非常慢，所谓一分钱一分货，想不花钱就能用上优质的服务，几乎是不可能。xhay1122在他的博客中分享了自己利用廉价的vps搭建的shadowsocks服务器，质量还是不错的比较稳定，但是毕竟是分享给大家用的而且流量有限不敢敞开用，所以最后我选择自己动手，丰衣足食，利用AWS 云服务器搭建Shadowsocks服务器。 Shadowsocks 原理 Shadowsocks(ss) 是由 Clowwindy 开发的一款软件，其作用本来是加密传输资料。当然，也正因为它加密传输资料的特性，使得 GFW 没法将由它传输的资料和其他普通资料区分开来（上图），也就不能干扰我们访问那些「不存在」的网站了。 创建 AWS 云服务器先去亚马逊AWS上面注册一个账号：https://amazonaws-china.com/cn/， 只要有信用卡可以免费使用一年AWS的部分服务 注册AWS 点击注册进入注册页面 填写邮件地址，密码，账户名称 这里选择个人就好了，然后填写个人信息 填写信用卡信息绑定完信用卡之后，信用卡会扣取1美元的费用，网上看的教程说后面会退还. 电话验证填写完信息后让系统拨打你的电话，然后页面上会显示出一个PIN码，在电话上输入即可 创建 AWS 实例 点击右上角切换服务器机房，建议选择亚太地区的服务器，因为亚太地区的服务器相对于北美的服务器延迟要低一些，这里我选择 东京 点击左上角的服务选择 EC2 点击 启动实例 在 AWS Marketplace 搜索 centos6 ,然后点击 选择 点击 continue 这里我们就直接选用免费的就可以了，然后点击 下一步 后面我们都使用默认配置，都直接点击下一步，直到 配置安全组 的时候，我们将类型改成 所有流量，然后点击 审核和启动 点击右下角的 启动 会弹出一个密钥窗口选择 创建新密钥对 ，接着填写密钥名称，点击 下载密钥 ，最后点击 启动实例 接着初始化主机，初始化完成后出现下面的这个界面，点击右下角的 查看实例 连接 AWS 实例 点击 连接 按照提示我们直接通过ssh连接，首先打开SSH客户端，我用的MAC自带SSH，所以直接打开终端（Windows可以根据提示使用PuTTY连接），并将路径切换到之前保存密钥的路径下，然后根据提示修改密钥的权限，最后复制下面的示例并将root改为centos（我们安装的centos系统的用户名是centos） 1234567Last login: Tue Dec 19 09:01:19 on ttys002xuepengdeMacBook-Pro:~ geekspeng$ cd Downloads/xuepengdeMacBook-Pro:Downloads geekspeng$ lsshadowsock.pemxuepengdeMacBook-Pro:Downloads geekspeng$ chmod 400 shadowsock.pemxuepengdeMacBook-Pro:Downloads geekspeng$ ssh -i &quot;shadowsock.pem&quot; centos@ec2-13-115-236-100.ap-northeast-1.compute.amazonaws.com[centos@ip-172-31-22-183 ~]$ 部署 ShadowsocksShadowsocks 需要同时具备客户端和服务器端，所以它的部署也需要分两步 部署 Shadowsocks 服务器这里使用 teddysun 的一键安装脚本。 可使用 sudo passwd root 先修改root密码，然后切换到root用户 12345678[centos@ip-172-31-22-183 ~]$ sudo passwd rootChanging password for user root.New password:Retype new password:passwd: all authentication tokens updated successfully.[centos@ip-172-31-22-183 ~]$ su rootPassword:[root@ip-172-31-22-183 centos]# 这里需要安装 wget，后面需要用到，需要确认的地方都输入y就可以了 1[root@ip-172-31-22-183 centos]# yum install wget 然后执行以下是3条命令，每次输入一行、回车，等待屏幕上的操作完成后再输入下一条。 123wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.shchmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 上面最后一步输完，按照提示输入进行设置，设置完过后按任意键开始部署 Shadowsocks。这时你什么都不用做，只需要静静地等它运行完就好。结束后就会看到你所部署的 Shadowsocks 的配置信息。 12345678Congratulations, Shadowsocks-python server install completed!Your Server IP : 13.115.236.100Your Server Port : 8989Your Password : ********Your Encryption Method: aes-256-cfbWelcome to visit:https://teddysun.com/342.htmlEnjoy it! 复制服务器 IP、服务器端口、你设的密码和加密方式。你就可以在自己任意的设备上进行登录使用了。 安装 Shadowsocks 客户端根据操作系统下载相应的客户端。Mac 版客户端下载Win 版客户端下载 打开客户端，在「服务器设定」里新增服务器。然后依次填入服务器 IP、服务器端口、你设的密码和加密方式。 Mac 版客户端 Win 版客户端 然后启用代理，就可以实现科学上网了 Mac 版客户端，点击打开Shadowsocks Win 版客户端，点击”启用系统代理”，选择PAC模式，在PAC中选择从xxx更新本地PAC 提升Shadowsocks服务器速度实际上你已经可以在自己的任意设备上进行使用了。但是为了更好的连接速度，你还需要多做几步。 TCP Fast Open编辑 /etc/rc.local 文件，按照下面的步骤操作 1） 首先打开rc.local文件 1vi /etc/rc.local 2） 然后按 i键 进入编辑模式，通过 ↑ ↓ ← →按键移动光标，在最后增加如下内容：echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 123456789101112131415161718192021222324#!/bin/sh## This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don&apos;t# want to do the full Sys V style init stuff.touch /var/lock/subsys/local# set a random pass on first bootif [ -f /root/firstrun ]; then dd if=/dev/urandom count=50|md5sum|passwd --stdin root passwd -l root rm /root/firstrunfiif [ ! -d /root/.ssh ]; then mkdir -m 0700 -p /root/.ssh restorecon /root/.sshfiecho 3 &gt; /proc/sys/net/ipv4/tcp_fastopen~~~~ 3）编辑完过后首先按ESC键，再输入:wq即可以保存退出了 然后按照同样的方法修改 /etc/sysctl.conf，在最后增加如下内容： 1net.ipv4.tcp_fastopen = 3 再打开一个 Shadowsocks 配置文件，编辑 /etc/shadowsocks.json，把其中 “fast_open” 一项的 false 替换成 true 修改如下： 1&quot;fast_open&quot;:true 最后，输入以下命令重启 Shadowsocks： 1/etc/init.d/shadowsocks restart 开启锐速锐速 ServerSpeeder 是一个 TCP 加速软件，对 Shadowsocks 客户端和服务器端间的传输速度有显著提升。 不同于 FinalSpeed 或 Kcptun 等需要客户端的工具，「锐速」的一大优势是只需要在服务器端单边部署就行了。另外，「锐速」虽然已经停止注册和安装了，不过网上还是有不少「破解版」可用 锐速破解版一键安装： 1wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.sh &amp;&amp; bash serverspeeder.sh 安装上面官网的的安装步骤执行一键安装脚本会出现如下的错误信息： 12345678910111213141516171819202122232425前面的省略...===============System Info=======================CentOS2.6.32-696.1.1.el6.x86_64x64=================================================--2017-12-19 14:14:49-- https://raw.githubusercontent.com/91yun/serverspeeder/test/serverspeederbin.txtResolving raw.githubusercontent.com... 151.101.72.133Connecting to raw.githubusercontent.com|151.101.72.133|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 96179 (94K) [text/plain]Saving to: “serverspeederbin.txt”100%[======================================&gt;] 96,179 --.-K/s in 0.006s2017-12-19 14:14:49 (16.5 MB/s) - “serverspeederbin.txt” saved [96179/96179]&gt;&gt;&gt;This kernel is not supported. Trying fuzzy matching...Serverspeeder is not supported on this kernel! View all supported systems and kernels here: https://www.91yun.org/serverspeeder91yun 监测VPS架构 1wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/code/master/vm_check.sh &amp;&amp; bash vm_check.sh 如果是kvm还是xen或者vmare则可以装锐速，如果是Openvz，则不可装锐速 改核适配锐速 CentOS 6支持安装锐速的内核：2.6.32–504.3.3.el6.x86_64 123456uname -r #查看当前内核版本rpm -ivh http://xz.wn789.com/CentOSkernel/kernel-firmware-2.6.32-504.3.3.el6.noarch.rpmrpm -ivh http://xz.wn789.com/CentOSkernel/kernel-2.6.32-504.3.3.el6.x86_64.rpm --forcerpm -qa | grep kernel #查看是否安装成功reboot #重启VPSuname -r #当前使用内核版本 部署锐速依然使用一键安装脚本，输入以下命令： 1wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh &amp;&amp; bash serverspeeder-all.sh 安装需要一段时间，等待一会。成功界面如下，看到license信息过期时间为”2034-12-31”就没问题了。 12345678910111213141516171819202122232425262728[Running Status]ServerSpeeder is running!version 3.10.61.0[License Information]License 763D1329B3D1824A (valid on current device)MaxSession unlimitedMaxTcpAccSession unlimitedMaxBandwidth(kbps) unlimitedExpireDate 2034-12-31[Connection Information]TotalFlow 1NumOfTcpFlows 1TotalAccTcpFlow 0TotalActiveTcpFlow 0[Running Configuration]accif eth0acc 1advacc 1advinacc 1wankbps 10000000waninkbps 10000000csvmode 0subnetAcc 0maxmode 1pcapEnable 0 至此，整个搭建过程就大功告成了！接下来，尽情地享受起飞的速度吧😄]]></content>
      <categories>
        <category>科学上网</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
        <tag>Shadowsocks</tag>
        <tag>AWS云服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Node.js 开发环境]]></title>
    <url>%2F2017%2F09%2F01%2F%E6%90%AD%E5%BB%BA%20Node.js%20%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83.html</url>
    <content type="text"><![CDATA[如果你想长期做 node 开发, 或者想快速更新 node 版本, 或者想快速切换 node 版本, 那么在非 Windows(如 osx, linux) 环境下, 请使用 nvm 来安装你的 node 开发环境, 保持系统的干净。如果你使用 Windows 做开发, 那么你可以使用 nvmw 来替代 nvm nvm 的全称是 Node Version Manager，之所以需要这个工具，是因为 Node.js 的各种特性都没有稳定下来，所以我们经常由于老项目或尝新的原因，需要切换各种版本 安装nvm1$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.30.2/install.sh | bash 查看nvm安装是否成功，输入nvm1234567891011121314151617181920212223242526272829303132333435363738394041$ nvmNode Version ManagerNote: &lt;version&gt; refers to any version-like string nvm understands. This includes: - full or partial version numbers, starting with an optional &quot;v&quot; (0.10, v0.1.2, v1) - default (built-in) aliases: node, stable, unstable, iojs, system - custom aliases you define with `nvm alias foo`Usage: nvm help Show this message nvm --version Print out the latest released version of nvm nvm install [-s] &lt;version&gt; Download and install a &lt;version&gt;, [-s] from source. Uses .nvmrc if available --reinstall-packages-from=&lt;version&gt; When installing, reinstall packages installed in &lt;node|iojs|node version number&gt; nvm uninstall &lt;version&gt; Uninstall a version nvm use [--silent] &lt;version&gt; Modify PATH to use &lt;version&gt;. Uses .nvmrc if available nvm exec [--silent] &lt;version&gt; [&lt;command&gt;] Run &lt;command&gt; on &lt;version&gt;. Uses .nvmrc if available nvm run [--silent] &lt;version&gt; [&lt;args&gt;] Run `node` on &lt;version&gt; with &lt;args&gt; as arguments. Uses .nvmrc if available nvm current Display currently activated version nvm ls List installed versions nvm ls &lt;version&gt; List versions matching a given description nvm ls-remote List remote versions available for install nvm version &lt;version&gt; Resolve the given description to a single local version nvm version-remote &lt;version&gt; Resolve the given description to a single remote version nvm deactivate Undo effects of `nvm` on current shell nvm alias [&lt;pattern&gt;] Show all aliases beginning with &lt;pattern&gt; nvm alias &lt;name&gt; &lt;version&gt; Set an alias named &lt;name&gt; pointing to &lt;version&gt; nvm unalias &lt;name&gt; Deletes the alias named &lt;name&gt; nvm reinstall-packages &lt;version&gt; Reinstall global `npm` packages contained in &lt;version&gt; to current version nvm unload Unload `nvm` from shell nvm which [&lt;version&gt;] Display path to installed node version. Uses .nvmrc if availableExample: nvm install v0.10.32 Install a specific version number nvm use 0.10 Use the latest available 0.10.x release nvm run 0.10.32 app.js Run app.js using node v0.10.32 nvm exec 0.10.32 node app.js Run `node app.js` with the PATH pointing to node v0.10.32 nvm alias default 0.10.32 Set default node version on a shellNote: to remove, delete, or uninstall nvm - just remove the `$NVM_DIR` folder (usually `~/.nvm`) 通过 nvm 安装任意版本的 node，可以指定版本号，或者用stable(稳定版)代替123456$ nvm install stableDownloading https://nodejs.org/dist/v8.4.0/node-v8.4.0-darwin-x64.tar.xz...######################################################################## 100.0%WARNING: checksums are currently disabled for node.js v4.0 and laternvm is not compatible with the npm config &quot;prefix&quot; option: currently set to &quot;/Users/geekspeng/npm-global&quot;Run `nvm use --delete-prefix v8.4.0` to unset it. 通过 nvm 安装任意版本的 iojs12345$ nvm install iojsDownloading https://iojs.org/dist/v3.3.1/iojs-v3.3.1-darwin-x64.tar.xz...######################################################################## 100.0%WARNING: checksums are currently disabled for io.jsNow using io.js v3.3.1 (npm v2.14.3) 查看安装的node，箭头指向的就是当前使用的node版本123456$ nvm ls-&gt; v8.4.0default -&gt; stable (-&gt; v8.4.0)node -&gt; stable (-&gt; v8.4.0) (default)stable -&gt; 8.4 (-&gt; v8.4.0) (default)iojs -&gt; N/A (default) nvm常用命令12345nvm install v0.10.32 Install a specific version numbernvm use 0.10 Use the latest available 0.10.x releasenvm run 0.10.32 app.js Run app.js using node v0.10.32nvm exec 0.10.32 node app.js Run `node app.js` with the PATH pointing to node v0.10.32nvm alias default 0.10.32 Set default node version on a shell 使用 cnpm 加速 npm同理 nvm , npm 默认是从国外的源获取和下载包信息, 所以可能会比较慢. 可以通过简单的 —registry 参数, 使用国内的镜像 http://registry.npm.taobao.org 1$ npm install koa --registry=http://registry.npm.taobao.org 毕竟镜像跟官方的 npm 源还是会有一个同步时间差异, 目前 cnpm 的默认同步时间间隔是 10 分钟. 如果你是模块发布者, 或者你想马上同步一个模块, 那么推荐你安装 cnpm cli 1$ npm install cnpm -g --registry=http://registry.npm.taobao.org 通过 cnpm 命令行, 你可以快速同步任意模块 1$ cnpm sync koa connect mocha 例如我想马上同步 koa, 直接打开浏览器: http://npm.taobao.org/sync/koa或者在命令行中通过 open 命令同步 1$ open http://npm.taobao.org/sync/koa 当开启一个新的 shell 窗口时，找不到 node 命令的情况这种情况一般来自两个原因1、shell 不知道 nvm 的存在 2、nvm 已经存在，但是没有 default 的 Node.js 版本可用。 解决方式1、检查 ~/.profile 或者 ~/.bash_profile 中有没有下面的语句，没有的话就通过vim添加进入 1234export NVM_DIR=&quot;/Users/geekspeng/.nvm&quot;[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; . &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm[ -s &quot;$NVM_DIR/bash_completion&quot; ] &amp;&amp; \. &quot;$NVM_DIR/bash_completion&quot; # This loads nvm bash_completion 注意： ~/.bashrc虽然有上面的语句但是每次新开命令行都要source ~/.bashrc，按理来说修改后source一次后面就不需要souce了 ~/.bashrc包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取） 2、 调用nvm ls 查看default 的指向 123456$ nvm ls -&gt; v8.4.0default -&gt; stable (-&gt; v8.4.0)node -&gt; stable (-&gt; v8.4.0) (default)stable -&gt; 8.4 (-&gt; v8.4.0) (default)iojs -&gt; N/A (default) 如果default没有指向的话，执行nvm alias default stable指定版本，执行完后再查看下 1$ nvm alias default stable]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>nvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 nrm 自由切换 npm 源]]></title>
    <url>%2F2017%2F09%2F01%2F%E9%80%9A%E8%BF%87%20nrm%20%E8%87%AA%E7%94%B1%E5%88%87%E6%8D%A2%20npm%20%E6%BA%90.html</url>
    <content type="text"><![CDATA[nrm可以快速地切换不同的npm registries，包括：npm，cnpm，taobao，nj（nodejitsu），rednpm 安装1$ npm install -g nrm 例子- nrm ls星号表示当前使用的 registry 123456789$ nrm ls* npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/ - nrm use123$ nrm use cnpm //switch registry to cnpm Registry has been set to: http://r.cnpmjs.org/ 用法12345678910111213141516Usage: nrm [options] [command] Commands: ls List all the registries use &lt;registry&gt; Change registry to registry add &lt;registry&gt; &lt;url&gt; [home] Add one custom registry del &lt;registry&gt; Delete one custom registry home &lt;registry&gt; [browser] Open the homepage of registry with optional browser test [registry] Show the response time for one or all registries help Print this help Options: -h, --help output usage information -V, --version output the version number npm registries npm cnpm nodejitsu taobao rednpm 注意当您使用其他registry时，不能使用publish命令]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>nrm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm 模块全局安装的权限问题]]></title>
    <url>%2F2017%2F09%2F01%2Fnpm%20%E6%A8%A1%E5%9D%97%E5%85%A8%E5%B1%80%E5%AE%89%E8%A3%85%E7%9A%84%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[安装全局 npm 模块报 EACCES 错误的问题，例如： 1$ npm install -g coffee-script 因为缺省的 npm 全局安装目录(/usr/local/node_modules)没有给当前登录用户以写权限。当然可以在前面加上 sudo 来提升用户权限，但其实还有更好的方法 你可以通过以下三种方式的任意一种解决这个问题: 修改npm默认安装目录的权限 修改npm默认安装目录 借助第三方工具安装node，比如brew 修改npm默认目录的权限1$ sudo chown -R $(whoami) $(npm config get prefix)/&#123;lib/node_modules,bin,share&#125; 修改npm默认安装目录创建一个用于全局安装的目录1mkdir ~/.npm-global 修改npm默认安装目录1npm config set prefix &apos;~/.npm-global&apos; 打开或者创建 ~/.profile 文件并且添加下面的语句:1export PATH=~/.npm-global/bin:$PATH 更新系统变量1source ~/.profile 测试1npm install -g jshint 从此以后 npm install -g 安装的模块就都会到该用户名字下面的 ~/.npm-global 目录中，这样就做到了用户隔离。 借助第三方工具安装node如果是Mac OS系统，则可以使用Homebrew软件包管理器完全避免此问题 1brew install node 引用：https://docs.npmjs.com/getting-started/fixing-npm-permissions]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用指南]]></title>
    <url>%2F2017%2F09%2F01%2FHexo%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.html</url>
    <content type="text"><![CDATA[安装 Hexo1$ npm install -g hexo-cli 建站安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 新建完成后，指定文件夹的目录如下： 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes scaffolds模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source资源文件夹是存放用户资源的地方。除 posts 文件夹之外，开头命名为 (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 themes主题 文件夹。Hexo 会根据主题来生成静态页面。 publichexo generate 生成的静态网页 常用命令三部曲 123$ hexo clean$ hexo generate$ hexo deploy init1$ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new1$ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate1$ hexo generate 生成静态文件。 123选项 描述-d, --deploy 文件生成后立即部署网站-w, --watch 监视文件变动 该命令可以简写为 1$ hexo g publish1$ hexo publish [layout] &lt;filename&gt; 发表草稿。 server1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 1234选项 描述-p, --port 重设端口-s, --static 只使用静态文件-l, --log 启动日记记录，使用覆盖记录格式 deploy1$ hexo deploy 部署网站。 12参数 描述-g, --generate 部署之前预先生成静态文件 该命令可以简写为： 1$ hexo d clean1$ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 render1$ hexo render &lt;file1&gt; [file2] ... 渲染文件。 12参数 描述-o, --output 设置输出路径 migrate1$ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 list1$ hexo list &lt;type&gt; 列出网站资料。 version1$ hexo version 显示 Hexo 版本。 主题创建 Hexo 主题非常容易，您只要在 themes 文件夹内，新增一个任意名称的文件夹，并修改 _config.yml 内的 theme 设定，即可切换主题，当然也可以直接下载主题放到themes 文件夹内。一个主题可能会有以下的结构： 123456.├── _config.yml├── languages├── layout├── scripts└── source 打开 站点配置文件， 找到 theme 字段，并将其值更改为 next 1theme: next]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 下的分类和表签无法显示]]></title>
    <url>%2F2017%2F09%2F01%2Fhexo%20%E4%B8%8B%E7%9A%84%E5%88%86%E7%B1%BB%E5%92%8C%E8%A1%A8%E7%AD%BE%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA.html</url>
    <content type="text"><![CDATA[在命令行中输入hexo new page tags1$ hexo new page tags 这时会在在sources/tags里面有个index.md的文件，打开这个文件编辑12345---title: tagsdate: 2017-08-28 08:33:46type: &quot;tags&quot;--- type: 改成tags 在主题配置文件中，在menu项下，要把tags页打开如123456menu: home: / archives: /archives tags: /tags //确保标签页已打开 categories: /categories about: /about 在你要发布的文章中添加标签123456---title: hexo 下的分类和表签无法显示date: 2017-08-28 08:33:46tags: [hexo]categories: [hexo]--- 所有冒号后面都有个空格]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac OSX 完全卸载node.js]]></title>
    <url>%2F2017%2F09%2F01%2FMac%20OSX%20%E5%AE%8C%E5%85%A8%E5%8D%B8%E8%BD%BDnode.js.html</url>
    <content type="text"><![CDATA[删除/usr/local/lib中的所有node和node_modules的文件夹123$ cd /usr/local/lib$ sudo rm -rf node$ sudo rm -rf node_modules 如果是从brew安装的, 运行brew uninstall node检查~/中所有的local，lib或者include文件夹, 删除里面所有node和node_modules1234567891011$ cd ~/local$ sudo rm -rf node$ sudo rm -rf node_modules$ cd ~/lib$ sudo rm -rf node$ sudo rm -rf node_modules$ cd ~/include$ sudo rm -rf node$ sudo rm -rf node_modules 在/usr/local/bin中, 删除所有node的可执行文件123$ cd /usr/local/bin$ sudo rm -rf node$ sudo rm -rf node_modules 最后运行以下代码:12345678$ sudo rm /usr/local/bin/npm$ sudo rm /usr/local/share/man/man1/node.1$ sudo rm /usr/local/lib/dtrace/node.d$ sudo rm -rf ~/.npm$ sudo rm -rf ~/.node-gyp$ sudo rm /opt/local/bin/node$ sudo rm /opt/local/include/node$ sudo rm -rf /opt/local/lib/node_modules]]></content>
      <categories>
        <category>node</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>mac</tag>
      </tags>
  </entry>
</search>
